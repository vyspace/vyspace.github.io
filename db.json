{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next-n.png","path":"images/apple-touch-icon-next-n.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next-n.png","path":"images/favicon-16x16-next-n.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next-n.png","path":"images/favicon-32x32-next-n.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/profile.jpg","path":"images/profile.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo-n.svg","path":"images/logo-n.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/base.js","path":"js/src/base.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/gitmint/default.css","path":"lib/gitmint/default.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/gitment/default.css","path":"lib/gitment/default.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp12.jpg","path":"images/post/ai/hdp12.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp13.png","path":"images/post/ai/hdp13.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp17.png","path":"images/post/ai/hdp17.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/gitmint/gitmint.browser.js","path":"lib/gitmint/gitmint.browser.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/gitment/gitment.browser.js","path":"lib/gitment/gitment.browser.js","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp10.png","path":"images/post/ai/hdp10.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp11.png","path":"images/post/ai/hdp11.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp15.png","path":"images/post/ai/hdp15.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp16.png","path":"images/post/ai/hdp16.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp18.png","path":"images/post/ai/hdp18.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp19.png","path":"images/post/ai/hdp19.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp20.png","path":"images/post/ai/hdp20.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp14.png","path":"images/post/ai/hdp14.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp8.png","path":"images/post/ai/hdp8.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp9.png","path":"images/post/ai/hdp9.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp2.png","path":"images/post/ai/hdp2.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp1.png","path":"images/post/ai/hdp1.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp5.png","path":"images/post/ai/hdp5.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp4.png","path":"images/post/ai/hdp4.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp3.png","path":"images/post/ai/hdp3.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp6.png","path":"images/post/ai/hdp6.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp7.png","path":"images/post/ai/hdp7.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/other/oth1.png","path":"images/post/other/oth1.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp21.png","path":"images/post/ai/hdp21.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/post/ai/hdp22.png","path":"images/post/ai/hdp22.png","modified":1,"renderable":1}],"Cache":[{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1514748788000},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1514748788000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1514748788000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1514748788000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1514748788000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1514748788000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1514748788000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1514748788000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1514748788000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1514748788000},{"_id":"themes/next/README.cn.md","hash":"58ffe752bc4b7f0069fcd6304bbc2d5ff7b80f89","modified":1514748788000},{"_id":"themes/next/README.md","hash":"898213e66d34a46c3cf8446bf693bd50db0d3269","modified":1514748788000},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1514748788000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1514748788000},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1514748788000},{"_id":"themes/next/_config.yml","hash":"bb7a3fdd6fd0a80fc835ef33c0d1900fbacfe0fe","modified":1522229015000},{"_id":"source/_posts/hadoop-add.md","hash":"77e9dac65ebe5702344230a6a89965c60182e958","modified":1522728577000},{"_id":"source/_posts/hadoop-dfs.md","hash":"a55cbf3ab18c334303fe99945d7aa899f09dd8c1","modified":1522728577000},{"_id":"source/_posts/hadoop-jpt.md","hash":"226a2ee260de8d698203d020ceea01e90aa4a21b","modified":1522728577000},{"_id":"source/_posts/hadoop-hbs.md","hash":"b429b53d8e0e194f7f4aee8948204a440bc2d45b","modified":1522728577000},{"_id":"source/_posts/hadoop-planning.md","hash":"370f6d8ef75bb9c3290a3462b3b88b2ddfcac430","modified":1522662978000},{"_id":"source/_posts/hadoop-servers.md","hash":"8736a7f5d821cf5107163b5de2349ecffbe617a9","modified":1522229015000},{"_id":"source/_posts/hadoop-start.md","hash":"f1dbc55352926a088573bdfadf22d303ac59fe77","modified":1522728577000},{"_id":"source/_posts/hadoop-thr.md","hash":"fc9b0201516e3be60c319fe36768de5449f6eece","modified":1522728577000},{"_id":"source/_drafts/dl-hware.md","hash":"5314ffe8c215f5058c0c1b16ce0504093c6ee3c6","modified":1522403531000},{"_id":"source/_posts/hadoop-spk.md","hash":"1bcea23446e5ca82de18ba55d23d9323d96cf8e5","modified":1522403531000},{"_id":"source/_posts/hadoop-use.md","hash":"b7c3e64fdfc273c0acea7b74ff03e79170af9c31","modified":1522747952000},{"_id":"source/_posts/hadoop-wct.md","hash":"ecfa4d6585bb1bb487ec7d61f4db97a5d9bfa8d2","modified":1522747851000},{"_id":"source/_posts/hadoop-tutorial.md","hash":"c685b5b85d29c6def10741bbab55c26a5497defb","modified":1522403531000},{"_id":"source/_drafts/info-md.md","hash":"975051c951a99aee07ff469d0217fe6d05764309","modified":1522403531000},{"_id":"source/_posts/hadoop-yrn.md","hash":"1e7caa277a0d7b5a91fe862edb097ae4bcd5f926","modified":1522403531000},{"_id":"source/_posts/hadoop-zkp.md","hash":"f5844d4b279431d10458783bf1d1e49f08c7ca6c","modified":1522229015000},{"_id":"source/_posts/linux-info.md","hash":"aeb03a84fe2ae115383cfb6bfa0688bbb353083a","modified":1522403531000},{"_id":"source/_posts/linux-monitor.md","hash":"43ecbad58ef5516a7f204daf6a5da779948f7cab","modified":1522403531000},{"_id":"source/_posts/koa-start.md","hash":"34598a923c8377bff8d5232408b4d7d4951a89aa","modified":1521533591000},{"_id":"source/_posts/reactjs-start.md","hash":"c646763a7dbfafb06101b8cfd9559f955a8e315f","modified":1522229015000},{"_id":"source/categories/index.md","hash":"e0767bea45f37115a05bb1b5ecc80afdba61bc45","modified":1521178533000},{"_id":"source/_posts/nbatis-start.md","hash":"fadc5728266552ef9f02aef5768efd02eef7e4e5","modified":1521533591000},{"_id":"source/_posts/rn-start.md","hash":"439104de9881baa8c6013846454fe5ad8b9c7158","modified":1522229015000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1514748788000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"352093a1b210c72136687fd2eee649244cee402c","modified":1514748788000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1514748788000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1514748788000},{"_id":"source/about/index.md","hash":"382aeb3adc2ae5862754c82bbcb87733d847d9a6","modified":1521602183000},{"_id":"themes/next/languages/en.yml","hash":"652a55583c1f9040c1e3e6831f12cb7cb804006c","modified":1522229015000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1514748788000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1514748788000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1514748788000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1514748788000},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1514748788000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1514748788000},{"_id":"source/tags/index.md","hash":"ecfefafdb9243016f82be17518a1b70d539815ac","modified":1521016244000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1514748788000},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1514748788000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1514748788000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1514748788000},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1514748788000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1514748788000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"f2b39d89e61643003fd005b5a4a8ddb172bb5574","modified":1522229015000},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1514748788000},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1514748788000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1514748788000},{"_id":"themes/next/layout/category.swig","hash":"f33bc3d7a57377b5f2d9856bc06c7aa30b566089","modified":1522229015000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1514748788000},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1514748788000},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1514748788000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1514748788000},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1514748788000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1514748788000},{"_id":"themes/next/layout/_layout.swig","hash":"c82a7b6f283a67019c1ea75eb14609cc49916d4b","modified":1521021646000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1514748788000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514748788000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1514748788000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1514748788000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1514748788000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1514748788000},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1514748788000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1514748788000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1514748788000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1514748788000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"c0e3ca9cff35398600d3a7d2f48a453191716001","modified":1521454388000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1521169129000},{"_id":"themes/next/layout/_partials/head.swig","hash":"3f27b48e6b1fcb2fd98b563a7451e1ea3cd35ce0","modified":1521018392000},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1514748788000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1514748788000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1514748788000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1514748788000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1514748788000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1514748788000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1514748788000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1514748788000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1514748788000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1514748788000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1514748788000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1514748788000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1514748788000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1514748788000},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1514748788000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1514748788000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1514748788000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1514748788000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1514748788000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1514748788000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1514748788000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1514748788000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1514748788000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1514748788000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1514748788000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1514748788000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1521169564000},{"_id":"themes/next/source/images/.DS_Store","hash":"91ce375455f82a6ae6e32670670c71dfa876c9ba","modified":1521704924000},{"_id":"themes/next/source/images/apple-touch-icon-next-n.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1521602183000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"ed6aff16a52dd474b7a2769d321330778e2b7946","modified":1521602183000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1514748788000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1514748788000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1514748788000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1514748788000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1514748788000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1514748788000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1514748788000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"395a88ab3b696a82dec41f166c7a9cf5a99c7538","modified":1521602183000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1514748788000},{"_id":"themes/next/source/images/favicon-16x16-next-n.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1521602183000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0b9a6c2dec499abd5f3d5487dd74c43ef71741de","modified":1521602183000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1514748788000},{"_id":"themes/next/source/images/favicon-32x32-next-n.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1521602183000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1514748788000},{"_id":"themes/next/source/images/profile.jpg","hash":"07f4c4f7a3ac940ef291b3a63f56f2e908606511","modified":1521187443000},{"_id":"themes/next/source/images/logo-n.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1521602183000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1514748788000},{"_id":"themes/next/source/images/logo.svg","hash":"3ea7fa94baca34d8d2bf3b1716441965993b6d24","modified":1521602183000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1514748788000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1514748788000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1514748788000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514748788000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514748788000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514748788000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514748788000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514748788000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514748788000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1514748788000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"fbe88f8b41283a95a170c166a9b5f3d07f1e8310","modified":1521019345000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1514748788000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1514748788000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1514748788000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1514748788000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1514748788000},{"_id":"themes/next/source/lib/.DS_Store","hash":"cdc44abd5497edba0709cabe0a20f6b03d5e175b","modified":1521189399000},{"_id":"themes/next/layout/_scripts/pages/base.swig","hash":"d44d6c001e3dd3768871fa832c95f4daddd2cc7f","modified":1521020874000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1514748788000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1514748788000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1514748788000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1514748788000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1514748788000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1514748788000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1514748788000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"fbb4aac353a141ce7aff3b6c6f64d970cbcc83f8","modified":1521454388000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1514748788000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1514748788000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1514748788000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1514748788000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1514748788000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1514748788000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1514748788000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1514748788000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1514748788000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1514748788000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1514748788000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1514748788000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1514748788000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1514748788000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1514748788000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"eaad826f53de1b4727171dc9d671207c7552d50b","modified":1521105721000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1514748788000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1514748788000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1514748788000},{"_id":"themes/next/source/js/src/base.js","hash":"db03a4dba2cbf3f467520b25652b06b63ff9a6ca","modified":1521105500000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1514748788000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1514748788000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1514748788000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1514748788000},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1514748788000},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1514748788000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1514748788000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1514748788000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1514748788000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1514748788000},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1514748788000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1514748788000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1514748788000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1514748788000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1514748788000},{"_id":"themes/next/source/images/post/.DS_Store","hash":"15eff512bde7832b7b0433f52f4578b3d0f95b5f","modified":1521798674000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1514748788000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1514748788000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1514748788000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1514748788000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1514748788000},{"_id":"themes/next/source/lib/gitmint/default.css","hash":"7fbb18b73b44ed11193739c55fce53a6f173cf68","modified":1521454388000},{"_id":"themes/next/source/lib/gitment/default.css","hash":"7fbb18b73b44ed11193739c55fce53a6f173cf68","modified":1521189338000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1514748788000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1514748788000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1514748788000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1514748788000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1514748788000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1514748788000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1514748788000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1514748788000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1514748788000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"75e52ab4c6dbde4cb90f49de753894509e868820","modified":1521105790000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1521105467000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1514748788000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1514748788000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1514748788000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1514748788000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1514748788000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1514748788000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1514748788000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1514748788000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1514748788000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1514748788000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1514748788000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1514748788000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1514748788000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1514748788000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1514748788000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1514748788000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1514748788000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1514748788000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1514748788000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"02fb8fa6b6c252b6bed469539cd057716606a787","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1514748788000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1514748788000},{"_id":"themes/next/source/images/post/ai/hdp12.jpg","hash":"ecf6a38ec3b2e8e6eca458e27d5c0acb9d429173","modified":1522662978000},{"_id":"themes/next/source/images/post/ai/hdp13.png","hash":"0b421cafa9b6f89bfacd84c3f731d54bc3df5f23","modified":1522229015000},{"_id":"themes/next/source/images/post/ai/hdp17.png","hash":"d4edcb8d17bc1ac5fa5a8c7f7520c41926469303","modified":1522728577000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1514748788000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1514748788000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1514748788000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1514748788000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1514748788000},{"_id":"themes/next/source/lib/gitmint/gitmint.browser.js","hash":"bb132e9817fe98bf4b0a7d327f0433bb1d51b876","modified":1521454388000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1514748788000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1514748788000},{"_id":"themes/next/source/lib/gitment/gitment.browser.js","hash":"376446d9c5930576016f97dd63e5e6616c94d8d4","modified":1521428779000},{"_id":"themes/next/source/images/post/ai/hdp10.png","hash":"022dc90a9391947faa83520238f2f71561d4743c","modified":1522229015000},{"_id":"themes/next/source/images/post/ai/hdp11.png","hash":"db2b4b43c604286d9eb6ceadf4d79d1fd493cbf4","modified":1522229015000},{"_id":"themes/next/source/images/post/ai/hdp15.png","hash":"6f2bafd5097b23bc967d94387d39b864634dd97c","modified":1522728577000},{"_id":"themes/next/source/images/post/ai/hdp16.png","hash":"c7ab46a20993fc5ffb1fe30349a6711bf71650ac","modified":1522728577000},{"_id":"themes/next/source/images/post/ai/hdp18.png","hash":"7570a4ed36f7cf70828132ecb77709975c79e3c9","modified":1522728577000},{"_id":"themes/next/source/images/post/ai/hdp19.png","hash":"ec9c8a99af2967de203d8e91c249aaa21985d3c5","modified":1522728577000},{"_id":"themes/next/source/images/post/ai/hdp20.png","hash":"4258ba4b96099ca55881bad013bfa868d064bc25","modified":1522746421000},{"_id":"themes/next/source/images/post/ai/hdp14.png","hash":"acc81a0fd89cea02610ecc226248e23dbd39420a","modified":1522229015000},{"_id":"themes/next/source/images/post/ai/hdp8.png","hash":"352ed42505d74537e6307b3cd3240b8725807b3a","modified":1522229015000},{"_id":"themes/next/source/images/post/ai/hdp9.png","hash":"2200bb30ec69e3ad74f019fcc5bbb7c2b18d1834","modified":1522229015000},{"_id":"themes/next/source/images/post/ai/hdp2.png","hash":"97554c363c907e5c091634576d4a8a330024dbed","modified":1522229015000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1514748788000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1514748788000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1514748788000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1514748788000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1514748788000},{"_id":"themes/next/source/images/post/ai/hdp1.png","hash":"72036b99b75d4b0e4e62dc1e94a56f76d10d4537","modified":1522229015000},{"_id":"themes/next/source/images/post/ai/hdp5.png","hash":"e76a94c8d7f349c445cc60a9ef742fd150390ce2","modified":1522229015000},{"_id":"themes/next/source/images/post/ai/hdp4.png","hash":"04c554e659248721d1935c33842ca86d107137cf","modified":1522229015000},{"_id":"themes/next/source/images/post/ai/hdp3.png","hash":"353759604625d4eea5381b1ec301cb112a023738","modified":1522229015000},{"_id":"themes/next/source/images/post/ai/hdp6.png","hash":"11363880068fd3903cc8d97ea380c448d9982a99","modified":1522229015000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1514748788000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1514748788000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1514748788000},{"_id":"themes/next/source/images/post/ai/hdp7.png","hash":"2de3a285982c0294175bf1057946210eb17d3d42","modified":1522229015000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1514748788000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1514748788000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1514748788000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1514748788000},{"_id":"themes/next/source/images/post/other/oth1.png","hash":"8eadf32c9d4e588daf607770f77240a05c560652","modified":1522229015000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1514748788000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1514748788000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1514748788000},{"_id":"themes/next/source/images/post/ai/hdp21.png","hash":"3a3e74d9927bb0e532ef8974a9738714c5b8f220","modified":1522807652000}],"Category":[{"name":"ai","_id":"cjfjgup7y00023kna09399afb"},{"name":"other","_id":"cjfjgupdo001i3knay2o8msfv"},{"name":"koa","_id":"cjfjgupdt001v3kna5iusuqof"},{"name":"react","_id":"cjfjgupdu00203knahembqlb3"},{"name":"nbatis","_id":"cjfjgupdv00233knan9o46xws"}],"Data":[],"Page":[{"title":"categories","date":"2018-03-14T08:33:51.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-03-14 16:33:51\ntype: \"categories\"\ncomments: false\n---\n","updated":"2018-03-16T05:35:33.000Z","path":"categories/index.html","layout":"page","_id":"cjfjgupdk001f3kna1w2eynit","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"关于","date":"2018-03-16T03:39:04.000Z","type":"about","comments":0,"_content":"\n<center>Version 1.0.1</center>\n<center><font color=#999>联系我们 :</font> vyspace@yeah.net</center>\n<center>EvanZ是一个以个人技术发布为主的网站。本网站使用了Hexo框架及NexT主题，个人觉的很好用，可以让作者专注于内容制作本身，感兴趣的童鞋快快用起来，特此感谢！</center>\n<center><font color=#999>Hexo官网 :</font> [https://hexo.io/](https://hexo.io/)</center>\n<center><font color=#999>NexT官网 :</font> [http://theme-next.iissnan.com/](http://theme-next.iissnan.com/)</center>","source":"about/index.md","raw":"---\ntitle: 关于\ndate: 2018-03-16 11:39:04\ntype: \"about\"\ncomments: false\n---\n\n<center>Version 1.0.1</center>\n<center><font color=#999>联系我们 :</font> vyspace@yeah.net</center>\n<center>EvanZ是一个以个人技术发布为主的网站。本网站使用了Hexo框架及NexT主题，个人觉的很好用，可以让作者专注于内容制作本身，感兴趣的童鞋快快用起来，特此感谢！</center>\n<center><font color=#999>Hexo官网 :</font> [https://hexo.io/](https://hexo.io/)</center>\n<center><font color=#999>NexT官网 :</font> [http://theme-next.iissnan.com/](http://theme-next.iissnan.com/)</center>","updated":"2018-03-21T03:16:23.000Z","path":"about/index.html","layout":"page","_id":"cjfjgupdm001h3knaftw3tee3","content":"<center>Version 1.0.1</center><br><center><font color=\"#999\">联系我们 :</font> <a href=\"mailto:vyspace@yeah.net\" target=\"_blank\" rel=\"noopener\">vyspace@yeah.net</a></center><br><center>EvanZ是一个以个人技术发布为主的网站。本网站使用了Hexo框架及NexT主题，个人觉的很好用，可以让作者专注于内容制作本身，感兴趣的童鞋快快用起来，特此感谢！</center><br><center><font color=\"#999\">Hexo官网 :</font> <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">https://hexo.io/</a></center><br><center><font color=\"#999\">NexT官网 :</font> <a href=\"http://theme-next.iissnan.com/\" target=\"_blank\" rel=\"noopener\">http://theme-next.iissnan.com/</a></center>","site":{"data":{}},"excerpt":"","more":"<center>Version 1.0.1</center><br><center><font color=\"#999\">联系我们 :</font> <a href=\"mailto:vyspace@yeah.net\" target=\"_blank\" rel=\"noopener\">vyspace@yeah.net</a></center><br><center>EvanZ是一个以个人技术发布为主的网站。本网站使用了Hexo框架及NexT主题，个人觉的很好用，可以让作者专注于内容制作本身，感兴趣的童鞋快快用起来，特此感谢！</center><br><center><font color=\"#999\">Hexo官网 :</font> <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">https://hexo.io/</a></center><br><center><font color=\"#999\">NexT官网 :</font> <a href=\"http://theme-next.iissnan.com/\" target=\"_blank\" rel=\"noopener\">http://theme-next.iissnan.com/</a></center>"},{"title":"标签","date":"2018-03-14T08:18:28.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2018-03-14 16:18:28\ntype: \"tags\"\ncomments: false\n---\n","updated":"2018-03-14T08:30:44.000Z","path":"tags/index.html","layout":"page","_id":"cjfjgupdo001l3knam4y5jahf","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"HDFS 部署","date":"2018-03-20T02:18:18.000Z","_content":"这篇文章我们将按照规划方案配置HDFS，从4台中任一选择一台进行配置，本文选择node0。\n\n# Quick Start\n\n## <font color=#c00>下载及Java配置</font>\n\n登陆[官方网站](http://hadoop.apache.org/releases.html)，下载hadoop.tar.gz文件，本文所使用的版本为2.7.4，下载完成后解压并进入该文件夹，修改etc/hadoop/hadoop-env.sh文件\n\n``` bash\nJAVA_HOME=/opt/jdk1.8.0_65\n```\n\n<!--more-->\n\n<font color=#c00>注：因为Hadoop相关的工具比较多，可以把所有工具统一放在相同文件路径下，即使在不同服务器中也可以方便查找，本文将统一放在/opt路径下</font>\n\n![path](/images/post/ai/hdp13.png)\n\n## <font color=#c00>HDFS配置</font>\n\n配置etc/hadoop/hdfs-site.xml，将下面的XML标签项添加在&lt;configuration&gt;标签内。\n\n<font color=#c00>注：配置项中需要填写IP地址的地方，强烈推荐填写IP地址，不要使用主机名。（在访问页面时，方便大家在不做hosts文件修改时，正常跳转）</font>\n\n### 服务名\n\n``` xml\n<property>\n  <name>dfs.nameservices</name>\n  <value>mycluster</value>\n</property>\n```\n\n### NameNode服务的名字\n\n``` xml\n<property>\n  <name>dfs.ha.namenodes.mycluster</name>\n  <value>nn1,nn2</value>\n</property>\n```\n\n### NameNode的RPC协议与端口\n\n配置该项后，可以通过程序调用8020接口，RPC协议主要用于系统内部通信以及用户编程访问。\n\n``` xml\n<property>\n  <name>dfs.namenode.rpc-address.mycluster.nn1</name>\n  <value>node0的IP:8020</value>\n</property>\n<property>\n  <name>dfs.namenode.rpc-address.mycluster.nn2</name>\n  <value>node1的IP:8020</value>\n</property>\n```\n\n### NameNode的HTTP协议与端口\n\n配置该项后，可以通过浏览器访问50070接口\n\n``` xml\n<property>\n  <name>dfs.namenode.http-address.mycluster.nn1</name>\n  <value>node0的IP:50070</value>\n</property>\n<property>\n  <name>dfs.namenode.http-address.mycluster.nn2</name>\n  <value>node1的IP:50070</value>\n</property>\n```\n\n### 固定配置，客户端通过该类找到active的NameNode\n\n``` xml\n<property>\n  <name>dfs.client.failover.proxy.provider.mycluster</name>\n  <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n</property>\n```\n\n### SSH安全\n\n``` xml\n<property>\n  <name>dfs.ha.fencing.methods</name>\n  <value>sshfence</value>\n</property>\n<property>\n  <name>dfs.ha.fencing.ssh.private-key-files</name>\n  <value>/home/.ssh/id_rsa</value>\n</property>\n```\n\n### JournalNode的地址与端口\n\n``` xml\n<property>\n  <name>dfs.namenode.shared.edits.dir</name>\n  <value>qjournal://node1的IP:8485;node2的IP:8485;node3的IP:8485/mycluster</value>\n</property>\n```\n\n### JournalNode的工作目录\n\n``` xml\n<property>\n  <name>dfs.journalnode.edits.dir</name>\n  <value>此处填写你希望保存的路径即可，本文放在 /opt/hadoop-2.7.4/journalnode.edits</value>\n</property>\n```\n\n### ZKFC自动切换\n\n``` xml\n<property>\n   <name>dfs.ha.automatic-failover.enabled</name>\n   <value>true</value>\n</property>\n```\n\n### 打开权限控制\n\n``` xml\n<property>\n   <name>dfs.permissions</name>\n   <value>false</value>\n</property>\n```\n\n### slaves文件配置方式\n\n配置datanode时，如果不是使用了主机名加DNS解析或者hosts文件解析的方式，而是直接使用ip地址去配置slaves文件\n\n``` xml\n<property>\n   <name>dfs.namenode.datanode.registration.ip-hostname-check</name>\n   <value>false</value>\n</property>\n```\n\n## <font color=#c00>CORE配置</font>\n\n配置etc/hadoop/core-site.xml，将下面的XML标签项添加在&lt;configuration&gt;标签内。\n\n### NameNode入口\n\n``` xml\n<property>\n  <name>fs.defaultFS</name>\n  <value>hdfs://mycluster</value>\n</property>\n```\n\n### ZooKeeper地址与端口\n\n``` xml\n<property>\n  <name>ha.zookeeper.quorum</name>\n  <value>node0:2181,node2:2181,node3:2181</value>\n</property>\n```\n\n### NameNode原数据存储目录\n\n``` xml\n<property>\n  <name>hadoop.tmp.dir</name>\n  <value>可自定义设置，本文存储路径 /opt/hadoop-2.7.4/tmp</value>\n</property>\n```\n\n## <font color=#c00>其他配置项</font>\n\n### 指定DataNode地址\n\n在etc/hadoop文件下，创建slaves文件，内容如下：\n\n<font color=#c00>注：此处可以填写IP地址，也可填写主机名，推荐IP地址，保持配置一致性</font>\n\n``` bash\nnode1的IP\nnode2的IP\nnode3的IP\n```\n\n### 分发工具\n\n因为Hadoop会使用到所有的服务器，所以你必须将它分发到你所有的机器节点上，本教程一共4台服务器，所以将Hadoop文件夹分发到其他3台。\n\n``` bash\nscp -r /opt/hadoop-2.7.4 root@node1:/opt\nscp -r /opt/hadoop-2.7.4 root@node2:/opt\nscp -r /opt/hadoop-2.7.4 root@node3:/opt\n```\n\n\n### 启动JournalNode\n\n按照规划我们并没有把JournalNode服务部署在所有服务器节点上，所以，这里需要分别启动node1，node2，node3上的JournalNode进程。\n\n``` bash\nsbin/hadoop-daemon.sh start journalnode\n```\n\n使用<font color=#c00>jps</font>命令查看是否启动成功，显示PID JournalNode则为成功。\n\n### 格式化NameNode\n\n就像我们新装windows操作系统一样，需要磁盘格式化，从而建立该系统的元数据。\n\n在node0与node1之间，选择任一选择（这里选择node0），运行如下命令：\n\n``` bash\nbin/hdfs namenode -format\n```\n\n格式化成功后会在tmp/dfs/name/current/目录下生成fsimage元数据\n\n### 启动NameNode服务\n\n<font color=#c00>注：启动node0节点上的NameNode服务，目的是拷贝刚刚格式化好的元数据到node1中。</font>\n\n``` bash\nsbin/hadoop-daemon.sh start namenode\n```\n\n<font color=#c00>注：如果启动失败，可以删除之前生成的元数据，重新格式化。</font>\n\n### 拷贝元数据\n\n将node0中的NameNode服务正常启动后，就可以拷贝元数据到node1中了。\n\n<font color=#c00>注：下面这条命令必须在node1中执行。</font>\n\n``` bash\nbin/hdfs namenode -bootstrapStandby\n```\n\n查看拷贝是否成功。可在node1中tmp/dfs/name/current/目录下查看是否生成fsimage元数据。\n\n<font color=#c00>注：如果格式化NameNode与拷贝元数据这几步中依然出现莫名的错误，可以删除2个节点上的元数据，重新选择另一台机器（这里选择node1）从格式化NameNode步骤开始，再做一遍。（笔者之前就遇到过此类莫名其妙的问题- -!）</font>\n\n### 格式化DFSZKFailoverController\n\n1. 进行此步之前，需要关闭所有dfs服务：\n  ``` bash\n  sbin/stop-dfs.sh\n  ```\n\n2. 格式化ZKFC:\n  ``` bash\n  bin/hdfs zkfc -formatZK\n  ```\n\n### 启动HDFS服务\n\n完成以上步骤后，就可以启动HDFS服务了，在4台节点中，任一选择一台键入命令，都可以启动所有节点的服务。这里推荐使用node0。\n\n``` bash\nsbin/start-dfs.sh\n```\n\n## <font color=#c00>访问与测试</font>\n\n正常启动HDFS服务后，再node1中使用jps命令看到NameNode，JournalNode，DFSZKFailoverController，DataNode服务。\n\n### HTTP访问HDFS服务\n\n通过IP地址:50070接口，在浏览器中正常访问到HDFS。\n![hdfsweb](/images/post/ai/hdp14.png)\n\n<font color=#c00>注：node0与node1中，一台是active状态，一台是standby状态，由ZooKeeper服务投票决定。</font>\n\n### 手动切换\n\n如果启动HDFS时，两个NameNode都处于standby状态，我们也可以手动指定一台节点为激活状态。本文指定nn2<font color=#999>（这里使用配置项中的NameNode服务名）</font>\n\n``` bash\nbin/hdfs haadmin -transitionToActive --forcemanual nn2\n```\n\n<font color=#999>active状态：transitionToActive，standby状态：transitionToStandby</font>\n\n### HTTP访问计算引擎\n\n通过IP地址:8088接口，在浏览器中正常访问到计算引擎。\n![jsyq](/images/post/ai/hdp18.png)\n\n### 测试\n\n1. 创建test目录\n  ``` bash\n  bin/hdfs dfs -mkdir -p /test\n  ```\n\n2. 上传hello.txt文件到test目录\n  ``` bash\n  bin/hdfs dfs -put hello.txt /test/\n  ```\n\n3. 此时可以在web页面中，查看刚刚创建的文件夹\n  在Utilities -> Browse the file system下查看\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://zookeeper.apache.org/doc/r3.4.10/)，文档版本3.4.10\n\n## <font color=#c00>小结</font>\n\n完成上述配置后，HDFS可以正常访问了，HDFS很多操作能够正常使用，MapReduce是必不可少的。随着HDFS的配置完成，说明MapReduce也配置完成。下篇文件我们开始[《YARN 部署》](/ai/hadoop-yrn/)\n\n本系列文章[《目录》](/ai/hadoop-start/)\n\n\n\n\n","source":"_posts/hadoop-dfs.md","raw":"---\ntitle: HDFS 部署\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-03-20 10:18:18\n---\n这篇文章我们将按照规划方案配置HDFS，从4台中任一选择一台进行配置，本文选择node0。\n\n# Quick Start\n\n## <font color=#c00>下载及Java配置</font>\n\n登陆[官方网站](http://hadoop.apache.org/releases.html)，下载hadoop.tar.gz文件，本文所使用的版本为2.7.4，下载完成后解压并进入该文件夹，修改etc/hadoop/hadoop-env.sh文件\n\n``` bash\nJAVA_HOME=/opt/jdk1.8.0_65\n```\n\n<!--more-->\n\n<font color=#c00>注：因为Hadoop相关的工具比较多，可以把所有工具统一放在相同文件路径下，即使在不同服务器中也可以方便查找，本文将统一放在/opt路径下</font>\n\n![path](/images/post/ai/hdp13.png)\n\n## <font color=#c00>HDFS配置</font>\n\n配置etc/hadoop/hdfs-site.xml，将下面的XML标签项添加在&lt;configuration&gt;标签内。\n\n<font color=#c00>注：配置项中需要填写IP地址的地方，强烈推荐填写IP地址，不要使用主机名。（在访问页面时，方便大家在不做hosts文件修改时，正常跳转）</font>\n\n### 服务名\n\n``` xml\n<property>\n  <name>dfs.nameservices</name>\n  <value>mycluster</value>\n</property>\n```\n\n### NameNode服务的名字\n\n``` xml\n<property>\n  <name>dfs.ha.namenodes.mycluster</name>\n  <value>nn1,nn2</value>\n</property>\n```\n\n### NameNode的RPC协议与端口\n\n配置该项后，可以通过程序调用8020接口，RPC协议主要用于系统内部通信以及用户编程访问。\n\n``` xml\n<property>\n  <name>dfs.namenode.rpc-address.mycluster.nn1</name>\n  <value>node0的IP:8020</value>\n</property>\n<property>\n  <name>dfs.namenode.rpc-address.mycluster.nn2</name>\n  <value>node1的IP:8020</value>\n</property>\n```\n\n### NameNode的HTTP协议与端口\n\n配置该项后，可以通过浏览器访问50070接口\n\n``` xml\n<property>\n  <name>dfs.namenode.http-address.mycluster.nn1</name>\n  <value>node0的IP:50070</value>\n</property>\n<property>\n  <name>dfs.namenode.http-address.mycluster.nn2</name>\n  <value>node1的IP:50070</value>\n</property>\n```\n\n### 固定配置，客户端通过该类找到active的NameNode\n\n``` xml\n<property>\n  <name>dfs.client.failover.proxy.provider.mycluster</name>\n  <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n</property>\n```\n\n### SSH安全\n\n``` xml\n<property>\n  <name>dfs.ha.fencing.methods</name>\n  <value>sshfence</value>\n</property>\n<property>\n  <name>dfs.ha.fencing.ssh.private-key-files</name>\n  <value>/home/.ssh/id_rsa</value>\n</property>\n```\n\n### JournalNode的地址与端口\n\n``` xml\n<property>\n  <name>dfs.namenode.shared.edits.dir</name>\n  <value>qjournal://node1的IP:8485;node2的IP:8485;node3的IP:8485/mycluster</value>\n</property>\n```\n\n### JournalNode的工作目录\n\n``` xml\n<property>\n  <name>dfs.journalnode.edits.dir</name>\n  <value>此处填写你希望保存的路径即可，本文放在 /opt/hadoop-2.7.4/journalnode.edits</value>\n</property>\n```\n\n### ZKFC自动切换\n\n``` xml\n<property>\n   <name>dfs.ha.automatic-failover.enabled</name>\n   <value>true</value>\n</property>\n```\n\n### 打开权限控制\n\n``` xml\n<property>\n   <name>dfs.permissions</name>\n   <value>false</value>\n</property>\n```\n\n### slaves文件配置方式\n\n配置datanode时，如果不是使用了主机名加DNS解析或者hosts文件解析的方式，而是直接使用ip地址去配置slaves文件\n\n``` xml\n<property>\n   <name>dfs.namenode.datanode.registration.ip-hostname-check</name>\n   <value>false</value>\n</property>\n```\n\n## <font color=#c00>CORE配置</font>\n\n配置etc/hadoop/core-site.xml，将下面的XML标签项添加在&lt;configuration&gt;标签内。\n\n### NameNode入口\n\n``` xml\n<property>\n  <name>fs.defaultFS</name>\n  <value>hdfs://mycluster</value>\n</property>\n```\n\n### ZooKeeper地址与端口\n\n``` xml\n<property>\n  <name>ha.zookeeper.quorum</name>\n  <value>node0:2181,node2:2181,node3:2181</value>\n</property>\n```\n\n### NameNode原数据存储目录\n\n``` xml\n<property>\n  <name>hadoop.tmp.dir</name>\n  <value>可自定义设置，本文存储路径 /opt/hadoop-2.7.4/tmp</value>\n</property>\n```\n\n## <font color=#c00>其他配置项</font>\n\n### 指定DataNode地址\n\n在etc/hadoop文件下，创建slaves文件，内容如下：\n\n<font color=#c00>注：此处可以填写IP地址，也可填写主机名，推荐IP地址，保持配置一致性</font>\n\n``` bash\nnode1的IP\nnode2的IP\nnode3的IP\n```\n\n### 分发工具\n\n因为Hadoop会使用到所有的服务器，所以你必须将它分发到你所有的机器节点上，本教程一共4台服务器，所以将Hadoop文件夹分发到其他3台。\n\n``` bash\nscp -r /opt/hadoop-2.7.4 root@node1:/opt\nscp -r /opt/hadoop-2.7.4 root@node2:/opt\nscp -r /opt/hadoop-2.7.4 root@node3:/opt\n```\n\n\n### 启动JournalNode\n\n按照规划我们并没有把JournalNode服务部署在所有服务器节点上，所以，这里需要分别启动node1，node2，node3上的JournalNode进程。\n\n``` bash\nsbin/hadoop-daemon.sh start journalnode\n```\n\n使用<font color=#c00>jps</font>命令查看是否启动成功，显示PID JournalNode则为成功。\n\n### 格式化NameNode\n\n就像我们新装windows操作系统一样，需要磁盘格式化，从而建立该系统的元数据。\n\n在node0与node1之间，选择任一选择（这里选择node0），运行如下命令：\n\n``` bash\nbin/hdfs namenode -format\n```\n\n格式化成功后会在tmp/dfs/name/current/目录下生成fsimage元数据\n\n### 启动NameNode服务\n\n<font color=#c00>注：启动node0节点上的NameNode服务，目的是拷贝刚刚格式化好的元数据到node1中。</font>\n\n``` bash\nsbin/hadoop-daemon.sh start namenode\n```\n\n<font color=#c00>注：如果启动失败，可以删除之前生成的元数据，重新格式化。</font>\n\n### 拷贝元数据\n\n将node0中的NameNode服务正常启动后，就可以拷贝元数据到node1中了。\n\n<font color=#c00>注：下面这条命令必须在node1中执行。</font>\n\n``` bash\nbin/hdfs namenode -bootstrapStandby\n```\n\n查看拷贝是否成功。可在node1中tmp/dfs/name/current/目录下查看是否生成fsimage元数据。\n\n<font color=#c00>注：如果格式化NameNode与拷贝元数据这几步中依然出现莫名的错误，可以删除2个节点上的元数据，重新选择另一台机器（这里选择node1）从格式化NameNode步骤开始，再做一遍。（笔者之前就遇到过此类莫名其妙的问题- -!）</font>\n\n### 格式化DFSZKFailoverController\n\n1. 进行此步之前，需要关闭所有dfs服务：\n  ``` bash\n  sbin/stop-dfs.sh\n  ```\n\n2. 格式化ZKFC:\n  ``` bash\n  bin/hdfs zkfc -formatZK\n  ```\n\n### 启动HDFS服务\n\n完成以上步骤后，就可以启动HDFS服务了，在4台节点中，任一选择一台键入命令，都可以启动所有节点的服务。这里推荐使用node0。\n\n``` bash\nsbin/start-dfs.sh\n```\n\n## <font color=#c00>访问与测试</font>\n\n正常启动HDFS服务后，再node1中使用jps命令看到NameNode，JournalNode，DFSZKFailoverController，DataNode服务。\n\n### HTTP访问HDFS服务\n\n通过IP地址:50070接口，在浏览器中正常访问到HDFS。\n![hdfsweb](/images/post/ai/hdp14.png)\n\n<font color=#c00>注：node0与node1中，一台是active状态，一台是standby状态，由ZooKeeper服务投票决定。</font>\n\n### 手动切换\n\n如果启动HDFS时，两个NameNode都处于standby状态，我们也可以手动指定一台节点为激活状态。本文指定nn2<font color=#999>（这里使用配置项中的NameNode服务名）</font>\n\n``` bash\nbin/hdfs haadmin -transitionToActive --forcemanual nn2\n```\n\n<font color=#999>active状态：transitionToActive，standby状态：transitionToStandby</font>\n\n### HTTP访问计算引擎\n\n通过IP地址:8088接口，在浏览器中正常访问到计算引擎。\n![jsyq](/images/post/ai/hdp18.png)\n\n### 测试\n\n1. 创建test目录\n  ``` bash\n  bin/hdfs dfs -mkdir -p /test\n  ```\n\n2. 上传hello.txt文件到test目录\n  ``` bash\n  bin/hdfs dfs -put hello.txt /test/\n  ```\n\n3. 此时可以在web页面中，查看刚刚创建的文件夹\n  在Utilities -> Browse the file system下查看\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://zookeeper.apache.org/doc/r3.4.10/)，文档版本3.4.10\n\n## <font color=#c00>小结</font>\n\n完成上述配置后，HDFS可以正常访问了，HDFS很多操作能够正常使用，MapReduce是必不可少的。随着HDFS的配置完成，说明MapReduce也配置完成。下篇文件我们开始[《YARN 部署》](/ai/hadoop-yrn/)\n\n本系列文章[《目录》](/ai/hadoop-start/)\n\n\n\n\n","slug":"hadoop-dfs","published":1,"updated":"2018-04-03T04:09:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup7t00003kna46j6fv12","content":"<p>这篇文章我们将按照规划方案配置HDFS，从4台中任一选择一台进行配置，本文选择node0。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"下载及Java配置\"><a href=\"#下载及Java配置\" class=\"headerlink\" title=\"下载及Java配置\"></a><font color=\"#c00\">下载及Java配置</font></h2><p>登陆<a href=\"http://hadoop.apache.org/releases.html\" target=\"_blank\" rel=\"noopener\">官方网站</a>，下载hadoop.tar.gz文件，本文所使用的版本为2.7.4，下载完成后解压并进入该文件夹，修改etc/hadoop/hadoop-env.sh文件</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JAVA_HOME=/opt/jdk1.8.0_65</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<font color=\"#c00\">注：因为Hadoop相关的工具比较多，可以把所有工具统一放在相同文件路径下，即使在不同服务器中也可以方便查找，本文将统一放在/opt路径下</font>\n\n<p><img src=\"/images/post/ai/hdp13.png\" alt=\"path\"></p>\n<h2 id=\"HDFS配置\"><a href=\"#HDFS配置\" class=\"headerlink\" title=\"HDFS配置\"></a><font color=\"#c00\">HDFS配置</font></h2><p>配置etc/hadoop/hdfs-site.xml，将下面的XML标签项添加在&lt;configuration&gt;标签内。</p>\n<font color=\"#c00\">注：配置项中需要填写IP地址的地方，强烈推荐填写IP地址，不要使用主机名。（在访问页面时，方便大家在不做hosts文件修改时，正常跳转）</font>\n\n<h3 id=\"服务名\"><a href=\"#服务名\" class=\"headerlink\" title=\"服务名\"></a>服务名</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.nameservices<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>mycluster<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"NameNode服务的名字\"><a href=\"#NameNode服务的名字\" class=\"headerlink\" title=\"NameNode服务的名字\"></a>NameNode服务的名字</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>nn1,nn2<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"NameNode的RPC协议与端口\"><a href=\"#NameNode的RPC协议与端口\" class=\"headerlink\" title=\"NameNode的RPC协议与端口\"></a>NameNode的RPC协议与端口</h3><p>配置该项后，可以通过程序调用8020接口，RPC协议主要用于系统内部通信以及用户编程访问。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node0的IP:8020<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node1的IP:8020<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"NameNode的HTTP协议与端口\"><a href=\"#NameNode的HTTP协议与端口\" class=\"headerlink\" title=\"NameNode的HTTP协议与端口\"></a>NameNode的HTTP协议与端口</h3><p>配置该项后，可以通过浏览器访问50070接口</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node0的IP:50070<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node1的IP:50070<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"固定配置，客户端通过该类找到active的NameNode\"><a href=\"#固定配置，客户端通过该类找到active的NameNode\" class=\"headerlink\" title=\"固定配置，客户端通过该类找到active的NameNode\"></a>固定配置，客户端通过该类找到active的NameNode</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"SSH安全\"><a href=\"#SSH安全\" class=\"headerlink\" title=\"SSH安全\"></a>SSH安全</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.ha.fencing.methods<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>sshfence<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>/home/.ssh/id_rsa<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"JournalNode的地址与端口\"><a href=\"#JournalNode的地址与端口\" class=\"headerlink\" title=\"JournalNode的地址与端口\"></a>JournalNode的地址与端口</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>qjournal://node1的IP:8485;node2的IP:8485;node3的IP:8485/mycluster<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"JournalNode的工作目录\"><a href=\"#JournalNode的工作目录\" class=\"headerlink\" title=\"JournalNode的工作目录\"></a>JournalNode的工作目录</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.journalnode.edits.dir<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>此处填写你希望保存的路径即可，本文放在 /opt/hadoop-2.7.4/journalnode.edits<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"ZKFC自动切换\"><a href=\"#ZKFC自动切换\" class=\"headerlink\" title=\"ZKFC自动切换\"></a>ZKFC自动切换</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"打开权限控制\"><a href=\"#打开权限控制\" class=\"headerlink\" title=\"打开权限控制\"></a>打开权限控制</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.permissions<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"slaves文件配置方式\"><a href=\"#slaves文件配置方式\" class=\"headerlink\" title=\"slaves文件配置方式\"></a>slaves文件配置方式</h3><p>配置datanode时，如果不是使用了主机名加DNS解析或者hosts文件解析的方式，而是直接使用ip地址去配置slaves文件</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.datanode.registration.ip-hostname-check<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"CORE配置\"><a href=\"#CORE配置\" class=\"headerlink\" title=\"CORE配置\"></a><font color=\"#c00\">CORE配置</font></h2><p>配置etc/hadoop/core-site.xml，将下面的XML标签项添加在&lt;configuration&gt;标签内。</p>\n<h3 id=\"NameNode入口\"><a href=\"#NameNode入口\" class=\"headerlink\" title=\"NameNode入口\"></a>NameNode入口</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>fs.defaultFS<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>hdfs://mycluster<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"ZooKeeper地址与端口\"><a href=\"#ZooKeeper地址与端口\" class=\"headerlink\" title=\"ZooKeeper地址与端口\"></a>ZooKeeper地址与端口</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>ha.zookeeper.quorum<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node0:2181,node2:2181,node3:2181<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"NameNode原数据存储目录\"><a href=\"#NameNode原数据存储目录\" class=\"headerlink\" title=\"NameNode原数据存储目录\"></a>NameNode原数据存储目录</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>hadoop.tmp.dir<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>可自定义设置，本文存储路径 /opt/hadoop-2.7.4/tmp<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"其他配置项\"><a href=\"#其他配置项\" class=\"headerlink\" title=\"其他配置项\"></a><font color=\"#c00\">其他配置项</font></h2><h3 id=\"指定DataNode地址\"><a href=\"#指定DataNode地址\" class=\"headerlink\" title=\"指定DataNode地址\"></a>指定DataNode地址</h3><p>在etc/hadoop文件下，创建slaves文件，内容如下：</p>\n<font color=\"#c00\">注：此处可以填写IP地址，也可填写主机名，推荐IP地址，保持配置一致性</font>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node1的IP</span><br><span class=\"line\">node2的IP</span><br><span class=\"line\">node3的IP</span><br></pre></td></tr></table></figure>\n<h3 id=\"分发工具\"><a href=\"#分发工具\" class=\"headerlink\" title=\"分发工具\"></a>分发工具</h3><p>因为Hadoop会使用到所有的服务器，所以你必须将它分发到你所有的机器节点上，本教程一共4台服务器，所以将Hadoop文件夹分发到其他3台。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp -r /opt/hadoop-2.7.4 root@node1:/opt</span><br><span class=\"line\">scp -r /opt/hadoop-2.7.4 root@node2:/opt</span><br><span class=\"line\">scp -r /opt/hadoop-2.7.4 root@node3:/opt</span><br></pre></td></tr></table></figure>\n<h3 id=\"启动JournalNode\"><a href=\"#启动JournalNode\" class=\"headerlink\" title=\"启动JournalNode\"></a>启动JournalNode</h3><p>按照规划我们并没有把JournalNode服务部署在所有服务器节点上，所以，这里需要分别启动node1，node2，node3上的JournalNode进程。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure>\n<p>使用<font color=\"#c00\">jps</font>命令查看是否启动成功，显示PID JournalNode则为成功。</p>\n<h3 id=\"格式化NameNode\"><a href=\"#格式化NameNode\" class=\"headerlink\" title=\"格式化NameNode\"></a>格式化NameNode</h3><p>就像我们新装windows操作系统一样，需要磁盘格式化，从而建立该系统的元数据。</p>\n<p>在node0与node1之间，选择任一选择（这里选择node0），运行如下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>\n<p>格式化成功后会在tmp/dfs/name/current/目录下生成fsimage元数据</p>\n<h3 id=\"启动NameNode服务\"><a href=\"#启动NameNode服务\" class=\"headerlink\" title=\"启动NameNode服务\"></a>启动NameNode服务</h3><font color=\"#c00\">注：启动node0节点上的NameNode服务，目的是拷贝刚刚格式化好的元数据到node1中。</font>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>\n<font color=\"#c00\">注：如果启动失败，可以删除之前生成的元数据，重新格式化。</font>\n\n<h3 id=\"拷贝元数据\"><a href=\"#拷贝元数据\" class=\"headerlink\" title=\"拷贝元数据\"></a>拷贝元数据</h3><p>将node0中的NameNode服务正常启动后，就可以拷贝元数据到node1中了。</p>\n<font color=\"#c00\">注：下面这条命令必须在node1中执行。</font>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure>\n<p>查看拷贝是否成功。可在node1中tmp/dfs/name/current/目录下查看是否生成fsimage元数据。</p>\n<font color=\"#c00\">注：如果格式化NameNode与拷贝元数据这几步中依然出现莫名的错误，可以删除2个节点上的元数据，重新选择另一台机器（这里选择node1）从格式化NameNode步骤开始，再做一遍。（笔者之前就遇到过此类莫名其妙的问题- -!）</font>\n\n<h3 id=\"格式化DFSZKFailoverController\"><a href=\"#格式化DFSZKFailoverController\" class=\"headerlink\" title=\"格式化DFSZKFailoverController\"></a>格式化DFSZKFailoverController</h3><ol>\n<li><p>进行此步之前，需要关闭所有dfs服务：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>格式化ZKFC:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"启动HDFS服务\"><a href=\"#启动HDFS服务\" class=\"headerlink\" title=\"启动HDFS服务\"></a>启动HDFS服务</h3><p>完成以上步骤后，就可以启动HDFS服务了，在4台节点中，任一选择一台键入命令，都可以启动所有节点的服务。这里推荐使用node0。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>\n<h2 id=\"访问与测试\"><a href=\"#访问与测试\" class=\"headerlink\" title=\"访问与测试\"></a><font color=\"#c00\">访问与测试</font></h2><p>正常启动HDFS服务后，再node1中使用jps命令看到NameNode，JournalNode，DFSZKFailoverController，DataNode服务。</p>\n<h3 id=\"HTTP访问HDFS服务\"><a href=\"#HTTP访问HDFS服务\" class=\"headerlink\" title=\"HTTP访问HDFS服务\"></a>HTTP访问HDFS服务</h3><p>通过IP地址:50070接口，在浏览器中正常访问到HDFS。<br><img src=\"/images/post/ai/hdp14.png\" alt=\"hdfsweb\"></p>\n<font color=\"#c00\">注：node0与node1中，一台是active状态，一台是standby状态，由ZooKeeper服务投票决定。</font>\n\n<h3 id=\"手动切换\"><a href=\"#手动切换\" class=\"headerlink\" title=\"手动切换\"></a>手动切换</h3><p>如果启动HDFS时，两个NameNode都处于standby状态，我们也可以手动指定一台节点为激活状态。本文指定nn2<font color=\"#999\">（这里使用配置项中的NameNode服务名）</font></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs haadmin -transitionToActive --forcemanual nn2</span><br></pre></td></tr></table></figure>\n<font color=\"#999\">active状态：transitionToActive，standby状态：transitionToStandby</font>\n\n<h3 id=\"HTTP访问计算引擎\"><a href=\"#HTTP访问计算引擎\" class=\"headerlink\" title=\"HTTP访问计算引擎\"></a>HTTP访问计算引擎</h3><p>通过IP地址:8088接口，在浏览器中正常访问到计算引擎。<br><img src=\"/images/post/ai/hdp18.png\" alt=\"jsyq\"></p>\n<h3 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h3><ol>\n<li><p>创建test目录</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs dfs -mkdir -p /<span class=\"built_in\">test</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>上传hello.txt文件到test目录</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs dfs -put hello.txt /<span class=\"built_in\">test</span>/</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>此时可以在web页面中，查看刚刚创建的文件夹<br>在Utilities -&gt; Browse the file system下查看</p>\n</li>\n</ol>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://zookeeper.apache.org/doc/r3.4.10/\" target=\"_blank\" rel=\"noopener\">官方文档</a>，文档版本3.4.10</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成上述配置后，HDFS可以正常访问了，HDFS很多操作能够正常使用，MapReduce是必不可少的。随着HDFS的配置完成，说明MapReduce也配置完成。下篇文件我们开始<a href=\"/ai/hadoop-yrn/\">《YARN 部署》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>\n","site":{"data":{}},"excerpt":"<p>这篇文章我们将按照规划方案配置HDFS，从4台中任一选择一台进行配置，本文选择node0。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"下载及Java配置\"><a href=\"#下载及Java配置\" class=\"headerlink\" title=\"下载及Java配置\"></a><font color=\"#c00\">下载及Java配置</font></h2><p>登陆<a href=\"http://hadoop.apache.org/releases.html\" target=\"_blank\" rel=\"noopener\">官方网站</a>，下载hadoop.tar.gz文件，本文所使用的版本为2.7.4，下载完成后解压并进入该文件夹，修改etc/hadoop/hadoop-env.sh文件</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JAVA_HOME=/opt/jdk1.8.0_65</span><br></pre></td></tr></table></figure>","more":"<font color=\"#c00\">注：因为Hadoop相关的工具比较多，可以把所有工具统一放在相同文件路径下，即使在不同服务器中也可以方便查找，本文将统一放在/opt路径下</font>\n\n<p><img src=\"/images/post/ai/hdp13.png\" alt=\"path\"></p>\n<h2 id=\"HDFS配置\"><a href=\"#HDFS配置\" class=\"headerlink\" title=\"HDFS配置\"></a><font color=\"#c00\">HDFS配置</font></h2><p>配置etc/hadoop/hdfs-site.xml，将下面的XML标签项添加在&lt;configuration&gt;标签内。</p>\n<font color=\"#c00\">注：配置项中需要填写IP地址的地方，强烈推荐填写IP地址，不要使用主机名。（在访问页面时，方便大家在不做hosts文件修改时，正常跳转）</font>\n\n<h3 id=\"服务名\"><a href=\"#服务名\" class=\"headerlink\" title=\"服务名\"></a>服务名</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.nameservices<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>mycluster<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"NameNode服务的名字\"><a href=\"#NameNode服务的名字\" class=\"headerlink\" title=\"NameNode服务的名字\"></a>NameNode服务的名字</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>nn1,nn2<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"NameNode的RPC协议与端口\"><a href=\"#NameNode的RPC协议与端口\" class=\"headerlink\" title=\"NameNode的RPC协议与端口\"></a>NameNode的RPC协议与端口</h3><p>配置该项后，可以通过程序调用8020接口，RPC协议主要用于系统内部通信以及用户编程访问。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node0的IP:8020<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node1的IP:8020<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"NameNode的HTTP协议与端口\"><a href=\"#NameNode的HTTP协议与端口\" class=\"headerlink\" title=\"NameNode的HTTP协议与端口\"></a>NameNode的HTTP协议与端口</h3><p>配置该项后，可以通过浏览器访问50070接口</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node0的IP:50070<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node1的IP:50070<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"固定配置，客户端通过该类找到active的NameNode\"><a href=\"#固定配置，客户端通过该类找到active的NameNode\" class=\"headerlink\" title=\"固定配置，客户端通过该类找到active的NameNode\"></a>固定配置，客户端通过该类找到active的NameNode</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"SSH安全\"><a href=\"#SSH安全\" class=\"headerlink\" title=\"SSH安全\"></a>SSH安全</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.ha.fencing.methods<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>sshfence<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>/home/.ssh/id_rsa<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"JournalNode的地址与端口\"><a href=\"#JournalNode的地址与端口\" class=\"headerlink\" title=\"JournalNode的地址与端口\"></a>JournalNode的地址与端口</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>qjournal://node1的IP:8485;node2的IP:8485;node3的IP:8485/mycluster<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"JournalNode的工作目录\"><a href=\"#JournalNode的工作目录\" class=\"headerlink\" title=\"JournalNode的工作目录\"></a>JournalNode的工作目录</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.journalnode.edits.dir<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>此处填写你希望保存的路径即可，本文放在 /opt/hadoop-2.7.4/journalnode.edits<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"ZKFC自动切换\"><a href=\"#ZKFC自动切换\" class=\"headerlink\" title=\"ZKFC自动切换\"></a>ZKFC自动切换</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"打开权限控制\"><a href=\"#打开权限控制\" class=\"headerlink\" title=\"打开权限控制\"></a>打开权限控制</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.permissions<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"slaves文件配置方式\"><a href=\"#slaves文件配置方式\" class=\"headerlink\" title=\"slaves文件配置方式\"></a>slaves文件配置方式</h3><p>配置datanode时，如果不是使用了主机名加DNS解析或者hosts文件解析的方式，而是直接使用ip地址去配置slaves文件</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>dfs.namenode.datanode.registration.ip-hostname-check<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"CORE配置\"><a href=\"#CORE配置\" class=\"headerlink\" title=\"CORE配置\"></a><font color=\"#c00\">CORE配置</font></h2><p>配置etc/hadoop/core-site.xml，将下面的XML标签项添加在&lt;configuration&gt;标签内。</p>\n<h3 id=\"NameNode入口\"><a href=\"#NameNode入口\" class=\"headerlink\" title=\"NameNode入口\"></a>NameNode入口</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>fs.defaultFS<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>hdfs://mycluster<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"ZooKeeper地址与端口\"><a href=\"#ZooKeeper地址与端口\" class=\"headerlink\" title=\"ZooKeeper地址与端口\"></a>ZooKeeper地址与端口</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>ha.zookeeper.quorum<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node0:2181,node2:2181,node3:2181<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"NameNode原数据存储目录\"><a href=\"#NameNode原数据存储目录\" class=\"headerlink\" title=\"NameNode原数据存储目录\"></a>NameNode原数据存储目录</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>hadoop.tmp.dir<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>可自定义设置，本文存储路径 /opt/hadoop-2.7.4/tmp<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"其他配置项\"><a href=\"#其他配置项\" class=\"headerlink\" title=\"其他配置项\"></a><font color=\"#c00\">其他配置项</font></h2><h3 id=\"指定DataNode地址\"><a href=\"#指定DataNode地址\" class=\"headerlink\" title=\"指定DataNode地址\"></a>指定DataNode地址</h3><p>在etc/hadoop文件下，创建slaves文件，内容如下：</p>\n<font color=\"#c00\">注：此处可以填写IP地址，也可填写主机名，推荐IP地址，保持配置一致性</font>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node1的IP</span><br><span class=\"line\">node2的IP</span><br><span class=\"line\">node3的IP</span><br></pre></td></tr></table></figure>\n<h3 id=\"分发工具\"><a href=\"#分发工具\" class=\"headerlink\" title=\"分发工具\"></a>分发工具</h3><p>因为Hadoop会使用到所有的服务器，所以你必须将它分发到你所有的机器节点上，本教程一共4台服务器，所以将Hadoop文件夹分发到其他3台。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp -r /opt/hadoop-2.7.4 root@node1:/opt</span><br><span class=\"line\">scp -r /opt/hadoop-2.7.4 root@node2:/opt</span><br><span class=\"line\">scp -r /opt/hadoop-2.7.4 root@node3:/opt</span><br></pre></td></tr></table></figure>\n<h3 id=\"启动JournalNode\"><a href=\"#启动JournalNode\" class=\"headerlink\" title=\"启动JournalNode\"></a>启动JournalNode</h3><p>按照规划我们并没有把JournalNode服务部署在所有服务器节点上，所以，这里需要分别启动node1，node2，node3上的JournalNode进程。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure>\n<p>使用<font color=\"#c00\">jps</font>命令查看是否启动成功，显示PID JournalNode则为成功。</p>\n<h3 id=\"格式化NameNode\"><a href=\"#格式化NameNode\" class=\"headerlink\" title=\"格式化NameNode\"></a>格式化NameNode</h3><p>就像我们新装windows操作系统一样，需要磁盘格式化，从而建立该系统的元数据。</p>\n<p>在node0与node1之间，选择任一选择（这里选择node0），运行如下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>\n<p>格式化成功后会在tmp/dfs/name/current/目录下生成fsimage元数据</p>\n<h3 id=\"启动NameNode服务\"><a href=\"#启动NameNode服务\" class=\"headerlink\" title=\"启动NameNode服务\"></a>启动NameNode服务</h3><font color=\"#c00\">注：启动node0节点上的NameNode服务，目的是拷贝刚刚格式化好的元数据到node1中。</font>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>\n<font color=\"#c00\">注：如果启动失败，可以删除之前生成的元数据，重新格式化。</font>\n\n<h3 id=\"拷贝元数据\"><a href=\"#拷贝元数据\" class=\"headerlink\" title=\"拷贝元数据\"></a>拷贝元数据</h3><p>将node0中的NameNode服务正常启动后，就可以拷贝元数据到node1中了。</p>\n<font color=\"#c00\">注：下面这条命令必须在node1中执行。</font>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure>\n<p>查看拷贝是否成功。可在node1中tmp/dfs/name/current/目录下查看是否生成fsimage元数据。</p>\n<font color=\"#c00\">注：如果格式化NameNode与拷贝元数据这几步中依然出现莫名的错误，可以删除2个节点上的元数据，重新选择另一台机器（这里选择node1）从格式化NameNode步骤开始，再做一遍。（笔者之前就遇到过此类莫名其妙的问题- -!）</font>\n\n<h3 id=\"格式化DFSZKFailoverController\"><a href=\"#格式化DFSZKFailoverController\" class=\"headerlink\" title=\"格式化DFSZKFailoverController\"></a>格式化DFSZKFailoverController</h3><ol>\n<li><p>进行此步之前，需要关闭所有dfs服务：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>格式化ZKFC:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"启动HDFS服务\"><a href=\"#启动HDFS服务\" class=\"headerlink\" title=\"启动HDFS服务\"></a>启动HDFS服务</h3><p>完成以上步骤后，就可以启动HDFS服务了，在4台节点中，任一选择一台键入命令，都可以启动所有节点的服务。这里推荐使用node0。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>\n<h2 id=\"访问与测试\"><a href=\"#访问与测试\" class=\"headerlink\" title=\"访问与测试\"></a><font color=\"#c00\">访问与测试</font></h2><p>正常启动HDFS服务后，再node1中使用jps命令看到NameNode，JournalNode，DFSZKFailoverController，DataNode服务。</p>\n<h3 id=\"HTTP访问HDFS服务\"><a href=\"#HTTP访问HDFS服务\" class=\"headerlink\" title=\"HTTP访问HDFS服务\"></a>HTTP访问HDFS服务</h3><p>通过IP地址:50070接口，在浏览器中正常访问到HDFS。<br><img src=\"/images/post/ai/hdp14.png\" alt=\"hdfsweb\"></p>\n<font color=\"#c00\">注：node0与node1中，一台是active状态，一台是standby状态，由ZooKeeper服务投票决定。</font>\n\n<h3 id=\"手动切换\"><a href=\"#手动切换\" class=\"headerlink\" title=\"手动切换\"></a>手动切换</h3><p>如果启动HDFS时，两个NameNode都处于standby状态，我们也可以手动指定一台节点为激活状态。本文指定nn2<font color=\"#999\">（这里使用配置项中的NameNode服务名）</font></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs haadmin -transitionToActive --forcemanual nn2</span><br></pre></td></tr></table></figure>\n<font color=\"#999\">active状态：transitionToActive，standby状态：transitionToStandby</font>\n\n<h3 id=\"HTTP访问计算引擎\"><a href=\"#HTTP访问计算引擎\" class=\"headerlink\" title=\"HTTP访问计算引擎\"></a>HTTP访问计算引擎</h3><p>通过IP地址:8088接口，在浏览器中正常访问到计算引擎。<br><img src=\"/images/post/ai/hdp18.png\" alt=\"jsyq\"></p>\n<h3 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h3><ol>\n<li><p>创建test目录</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs dfs -mkdir -p /<span class=\"built_in\">test</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>上传hello.txt文件到test目录</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hdfs dfs -put hello.txt /<span class=\"built_in\">test</span>/</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>此时可以在web页面中，查看刚刚创建的文件夹<br>在Utilities -&gt; Browse the file system下查看</p>\n</li>\n</ol>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://zookeeper.apache.org/doc/r3.4.10/\" target=\"_blank\" rel=\"noopener\">官方文档</a>，文档版本3.4.10</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成上述配置后，HDFS可以正常访问了，HDFS很多操作能够正常使用，MapReduce是必不可少的。随着HDFS的配置完成，说明MapReduce也配置完成。下篇文件我们开始<a href=\"/ai/hadoop-yrn/\">《YARN 部署》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>"},{"title":"Hadoop 附录","date":"2018-04-03T04:56:20.000Z","_content":"\n# Quick Start\n\n## <font color=#c00>环境变量</font>\n\n以下是各个节点的环境变量配置（/etc/profile）\n\n### 节点node0\n\n``` bash\nexport JAVA_HOME=/opt/jdk1.8.0_65\nexport JRE_HOME=$JAVA_HOME/jre\nexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib\nexport PATH=$JAVA_HOME/bin:$PATH\nexport ANACONDA2_HOME=/opt/anaconda2\nexport PATH=$ANACONDA2_HOME/bin:$PATH\nexport SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7\nexport PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$PYTHONPATH\nexport XDG_RUNTIME_DIR=\"/home/test/.jupyter\"\nexport HBASE_HOME=/opt/hbase-1.3.1\nexport HADOOP_HOME=/opt/hadoop-2.7.4\nexport JN_HOME=/home/test/jupyter_notebook\nexport LD_LIBRARY_PATH=/opt/xgboost_packages/libhdfs\n```\n\n<!--more-->\n\n### 其他节点\n\n``` bash\nexport JAVA_HOME=/opt/jdk1.8.0_65\nexport JRE_HOME=$JAVA_HOME/jre\nexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib\nexport PATH=$JAVA_HOME/bin:$PATH\nexport ANACONDA2_HOME=/opt/anaconda2\nexport PATH=$ANACONDA2_HOME/bin:$PATH\nexport SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7\nexport PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$PYTHONPATH\nexport XDG_RUNTIME_DIR=\"/home/test/.jupyter\"\n```","source":"_posts/hadoop-add.md","raw":"---\ntitle: Hadoop 附录\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-04-03 12:56:20\n---\n\n# Quick Start\n\n## <font color=#c00>环境变量</font>\n\n以下是各个节点的环境变量配置（/etc/profile）\n\n### 节点node0\n\n``` bash\nexport JAVA_HOME=/opt/jdk1.8.0_65\nexport JRE_HOME=$JAVA_HOME/jre\nexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib\nexport PATH=$JAVA_HOME/bin:$PATH\nexport ANACONDA2_HOME=/opt/anaconda2\nexport PATH=$ANACONDA2_HOME/bin:$PATH\nexport SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7\nexport PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$PYTHONPATH\nexport XDG_RUNTIME_DIR=\"/home/test/.jupyter\"\nexport HBASE_HOME=/opt/hbase-1.3.1\nexport HADOOP_HOME=/opt/hadoop-2.7.4\nexport JN_HOME=/home/test/jupyter_notebook\nexport LD_LIBRARY_PATH=/opt/xgboost_packages/libhdfs\n```\n\n<!--more-->\n\n### 其他节点\n\n``` bash\nexport JAVA_HOME=/opt/jdk1.8.0_65\nexport JRE_HOME=$JAVA_HOME/jre\nexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib\nexport PATH=$JAVA_HOME/bin:$PATH\nexport ANACONDA2_HOME=/opt/anaconda2\nexport PATH=$ANACONDA2_HOME/bin:$PATH\nexport SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7\nexport PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$PYTHONPATH\nexport XDG_RUNTIME_DIR=\"/home/test/.jupyter\"\n```","slug":"hadoop-add","published":1,"updated":"2018-04-03T04:09:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup7x00013knau1y3mjhz","content":"<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"环境变量\"><a href=\"#环境变量\" class=\"headerlink\" title=\"环境变量\"></a><font color=\"#c00\">环境变量</font></h2><p>以下是各个节点的环境变量配置（/etc/profile）</p>\n<h3 id=\"节点node0\"><a href=\"#节点node0\" class=\"headerlink\" title=\"节点node0\"></a>节点node0</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/opt/jdk1.8.0_65</span><br><span class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</span><br><span class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib:<span class=\"variable\">$JRE_HOME</span>/lib</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> ANACONDA2_HOME=/opt/anaconda2</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$ANACONDA2_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7</span><br><span class=\"line\"><span class=\"built_in\">export</span> PYTHONPATH=<span class=\"variable\">$SPARK_HOME</span>/python:<span class=\"variable\">$SPARK_HOME</span>/python/lib/py4j-0.10.4-src.zip:<span class=\"variable\">$PYTHONPATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> XDG_RUNTIME_DIR=<span class=\"string\">\"/home/test/.jupyter\"</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> HBASE_HOME=/opt/hbase-1.3.1</span><br><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_HOME=/opt/hadoop-2.7.4</span><br><span class=\"line\"><span class=\"built_in\">export</span> JN_HOME=/home/<span class=\"built_in\">test</span>/jupyter_notebook</span><br><span class=\"line\"><span class=\"built_in\">export</span> LD_LIBRARY_PATH=/opt/xgboost_packages/libhdfs</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<h3 id=\"其他节点\"><a href=\"#其他节点\" class=\"headerlink\" title=\"其他节点\"></a>其他节点</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/opt/jdk1.8.0_65</span><br><span class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</span><br><span class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib:<span class=\"variable\">$JRE_HOME</span>/lib</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> ANACONDA2_HOME=/opt/anaconda2</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$ANACONDA2_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7</span><br><span class=\"line\"><span class=\"built_in\">export</span> PYTHONPATH=<span class=\"variable\">$SPARK_HOME</span>/python:<span class=\"variable\">$SPARK_HOME</span>/python/lib/py4j-0.10.4-src.zip:<span class=\"variable\">$PYTHONPATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> XDG_RUNTIME_DIR=<span class=\"string\">\"/home/test/.jupyter\"</span></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"环境变量\"><a href=\"#环境变量\" class=\"headerlink\" title=\"环境变量\"></a><font color=\"#c00\">环境变量</font></h2><p>以下是各个节点的环境变量配置（/etc/profile）</p>\n<h3 id=\"节点node0\"><a href=\"#节点node0\" class=\"headerlink\" title=\"节点node0\"></a>节点node0</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/opt/jdk1.8.0_65</span><br><span class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</span><br><span class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib:<span class=\"variable\">$JRE_HOME</span>/lib</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> ANACONDA2_HOME=/opt/anaconda2</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$ANACONDA2_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7</span><br><span class=\"line\"><span class=\"built_in\">export</span> PYTHONPATH=<span class=\"variable\">$SPARK_HOME</span>/python:<span class=\"variable\">$SPARK_HOME</span>/python/lib/py4j-0.10.4-src.zip:<span class=\"variable\">$PYTHONPATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> XDG_RUNTIME_DIR=<span class=\"string\">\"/home/test/.jupyter\"</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> HBASE_HOME=/opt/hbase-1.3.1</span><br><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_HOME=/opt/hadoop-2.7.4</span><br><span class=\"line\"><span class=\"built_in\">export</span> JN_HOME=/home/<span class=\"built_in\">test</span>/jupyter_notebook</span><br><span class=\"line\"><span class=\"built_in\">export</span> LD_LIBRARY_PATH=/opt/xgboost_packages/libhdfs</span><br></pre></td></tr></table></figure>","more":"<h3 id=\"其他节点\"><a href=\"#其他节点\" class=\"headerlink\" title=\"其他节点\"></a>其他节点</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/opt/jdk1.8.0_65</span><br><span class=\"line\"><span class=\"built_in\">export</span> JRE_HOME=<span class=\"variable\">$JAVA_HOME</span>/jre</span><br><span class=\"line\"><span class=\"built_in\">export</span> CLASSPATH=.:<span class=\"variable\">$JAVA_HOME</span>/lib:<span class=\"variable\">$JRE_HOME</span>/lib</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> ANACONDA2_HOME=/opt/anaconda2</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$ANACONDA2_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7</span><br><span class=\"line\"><span class=\"built_in\">export</span> PYTHONPATH=<span class=\"variable\">$SPARK_HOME</span>/python:<span class=\"variable\">$SPARK_HOME</span>/python/lib/py4j-0.10.4-src.zip:<span class=\"variable\">$PYTHONPATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> XDG_RUNTIME_DIR=<span class=\"string\">\"/home/test/.jupyter\"</span></span><br></pre></td></tr></table></figure>"},{"title":"Jupyter 部署","date":"2018-04-02T08:56:20.000Z","_content":"Jupyter Notebook 是一个Python在线编辑器，在机器学习领域很流行，调试代码也很方便。当然你可以选择其他编辑器。因为后面的示例会有一部分使用Python完成，所以这篇我们来部署Jupyter。\n\n# Quick Start\n\n## <font color=#c00>Anaconda</font>\n\n### 安装\n\nAnaconda是Python的版本管理工具，登陆[官方网站](https://www.anaconda.com/)下载安装包，其安装文件分为Python3.x与Python2.7版本。\n\n<!--more-->\n\n首先选择一个主要Python版本，这里选择2.7，所以我们下载Anaconda(py2)，下载可直接运行sh文件进行安装。安装完成后可运行如下指令查看conda的信息：\n\n``` bash\nconda info\n```\n\n### 切换Python3\n\n运行如下命令，安装Python3\n\n``` bash\nconda create -n py3 python=3\n```\n\n### 版本切换\n\n回到py2\n\n``` bash\nsource deactivate py3\n```\n\n进入py3\n\n``` bash\nsource activate py3\n```\n\n除了Anaconda，你也可以安装它的mini版，Miniconda。\n\nAnaconda包内已经包含了Jupyter，在装完anaconda应该会自动安装了Jupyter，下面就可以直接启动Jupyter服务了。\n\n## <font color=#c00>Jupyter</font>\n\n<font color=#c00>注：启动Jupyter服务建议不要使用root账户，原因后面会说到，所以我们切换到其他账户，这里我切换到test账户：</font>\n\n``` bash\nsu test\n```\n\n### 生成配置文件\n\n``` bash\njupyter notebook --generate-config\n```\n\n生成后的文件会在~/.jupyter中\n\n### 自动生成密钥\n\n因为服务开放后，所有人都可以访问，所以需要配置密码（此步也是必须的）。\n\n``` bash\njupyter notebook password\n```\n\n运行此命令后，可输入两次密码，完成后会在~/.jupyter/upyter_notebook_config.json文件中生成一串token。\n\n### 配置HTTP服务\n\n打开~/.jupyter/jupyter_notebook_config.py文件，修改如下配置项：\n\n``` bash\n# 容许所有IP可访问\nc.NotebookApp.ip = '*'\n\n# 初始化notebook工作区根目录，我在test帐户下，新建jupyter_notebook文件夹作为根目录\nc.NotebookApp.notebook_dir = u'/home/test/jupyter_notebook'\n\n＃ 是否打开浏览器立即启动\nc.NotebookApp.open_browser = False\n\n＃ 之前生成的token\nc.NotebookApp.password ＝ u'sha1:xxx'\n\n＃ 端口配置\nc.NotebookApp.port = 8888\n```\n\n### 运行服务\n\n新建.jupyter_out文件夹，将所有log日志记录在jupyter.log文件中。\n\n``` bash\nnohup jupyter notebook >/home/test/.jupyter_out/jupyter.log 2>&1 &\n```\n\n<font color=#c00>注：jupyter服务不是jps服务，所以需要使用ps命令查看</font>\n\n## <font color=#c00>HTTP访问</font>\n\n启动完成后，浏览器访问8888端口，就可以正常打开Jupyter了，\n\n<font color=#c00>注：第一次登陆需要填写密码</font>\n\n![jupyter](/images/post/ai/hdp17.png)\n\n<font color=#c00>注：之前有提到启动Jupyter服务，我建议切换到非root账户，原因是在Jupyter Notebook中用户可以新建命令行终端，你用什么账户启动服务，这里新建的终端将会以什么账户登录。所以为了控制用户权限及系统安全的考虑，不建议使用root账户去启动服务。</font>\n\n![noroot](/images/post/ai/hdp19.png)\n\n因为我们用test账户启动Jupyter服务，所以下图可以看到命令行窗口默认test用户登录。\n\n![cmd](/images/post/ai/hdp21.png)\n\n## <font color=#c00>Spark集群配置</font>\n\n为了让我们的jupyter可以访问Sprak集群去计算任务，我们还需要配置PySpark，[请点击此处查看](http://blog.cloudera.com/blog/2014/08/how-to-use-ipython-notebook-with-apache-spark/)具体配置教程\n\n因为配置过后时间隔的太久，记得不是很清楚了，可以试试如下命令，启动集群\n\n``` bash\nnohup jupyter notebook --profile=pyspark >/home/test/.jupyter_out/jupyter.log 2>&1 &\n```\n\n如果使用root账户启动，命令中加 --allow-root\n\n``` bash\nnohup jupyter notebook --profile=pyspark --allow-root >/home/test/.jupyter_out/jupyter.log 2>&1 &\n```\n\n到这里Jupyter服务已部署完毕。\n\n## <font color=#c00>小结</font>\n\n完成上述配置后，我们的IDE也部署完成了，不过还有一些小缺陷，就是Jupyter无法访问HBase。下篇文件我们开始[《Thrift 部署》](/ai/hadoop-thr/)\n\n本系列文章[《目录》](/ai/hadoop-start/)","source":"_posts/hadoop-jpt.md","raw":"---\ntitle: Jupyter 部署\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-04-02 16:56:20\n---\nJupyter Notebook 是一个Python在线编辑器，在机器学习领域很流行，调试代码也很方便。当然你可以选择其他编辑器。因为后面的示例会有一部分使用Python完成，所以这篇我们来部署Jupyter。\n\n# Quick Start\n\n## <font color=#c00>Anaconda</font>\n\n### 安装\n\nAnaconda是Python的版本管理工具，登陆[官方网站](https://www.anaconda.com/)下载安装包，其安装文件分为Python3.x与Python2.7版本。\n\n<!--more-->\n\n首先选择一个主要Python版本，这里选择2.7，所以我们下载Anaconda(py2)，下载可直接运行sh文件进行安装。安装完成后可运行如下指令查看conda的信息：\n\n``` bash\nconda info\n```\n\n### 切换Python3\n\n运行如下命令，安装Python3\n\n``` bash\nconda create -n py3 python=3\n```\n\n### 版本切换\n\n回到py2\n\n``` bash\nsource deactivate py3\n```\n\n进入py3\n\n``` bash\nsource activate py3\n```\n\n除了Anaconda，你也可以安装它的mini版，Miniconda。\n\nAnaconda包内已经包含了Jupyter，在装完anaconda应该会自动安装了Jupyter，下面就可以直接启动Jupyter服务了。\n\n## <font color=#c00>Jupyter</font>\n\n<font color=#c00>注：启动Jupyter服务建议不要使用root账户，原因后面会说到，所以我们切换到其他账户，这里我切换到test账户：</font>\n\n``` bash\nsu test\n```\n\n### 生成配置文件\n\n``` bash\njupyter notebook --generate-config\n```\n\n生成后的文件会在~/.jupyter中\n\n### 自动生成密钥\n\n因为服务开放后，所有人都可以访问，所以需要配置密码（此步也是必须的）。\n\n``` bash\njupyter notebook password\n```\n\n运行此命令后，可输入两次密码，完成后会在~/.jupyter/upyter_notebook_config.json文件中生成一串token。\n\n### 配置HTTP服务\n\n打开~/.jupyter/jupyter_notebook_config.py文件，修改如下配置项：\n\n``` bash\n# 容许所有IP可访问\nc.NotebookApp.ip = '*'\n\n# 初始化notebook工作区根目录，我在test帐户下，新建jupyter_notebook文件夹作为根目录\nc.NotebookApp.notebook_dir = u'/home/test/jupyter_notebook'\n\n＃ 是否打开浏览器立即启动\nc.NotebookApp.open_browser = False\n\n＃ 之前生成的token\nc.NotebookApp.password ＝ u'sha1:xxx'\n\n＃ 端口配置\nc.NotebookApp.port = 8888\n```\n\n### 运行服务\n\n新建.jupyter_out文件夹，将所有log日志记录在jupyter.log文件中。\n\n``` bash\nnohup jupyter notebook >/home/test/.jupyter_out/jupyter.log 2>&1 &\n```\n\n<font color=#c00>注：jupyter服务不是jps服务，所以需要使用ps命令查看</font>\n\n## <font color=#c00>HTTP访问</font>\n\n启动完成后，浏览器访问8888端口，就可以正常打开Jupyter了，\n\n<font color=#c00>注：第一次登陆需要填写密码</font>\n\n![jupyter](/images/post/ai/hdp17.png)\n\n<font color=#c00>注：之前有提到启动Jupyter服务，我建议切换到非root账户，原因是在Jupyter Notebook中用户可以新建命令行终端，你用什么账户启动服务，这里新建的终端将会以什么账户登录。所以为了控制用户权限及系统安全的考虑，不建议使用root账户去启动服务。</font>\n\n![noroot](/images/post/ai/hdp19.png)\n\n因为我们用test账户启动Jupyter服务，所以下图可以看到命令行窗口默认test用户登录。\n\n![cmd](/images/post/ai/hdp21.png)\n\n## <font color=#c00>Spark集群配置</font>\n\n为了让我们的jupyter可以访问Sprak集群去计算任务，我们还需要配置PySpark，[请点击此处查看](http://blog.cloudera.com/blog/2014/08/how-to-use-ipython-notebook-with-apache-spark/)具体配置教程\n\n因为配置过后时间隔的太久，记得不是很清楚了，可以试试如下命令，启动集群\n\n``` bash\nnohup jupyter notebook --profile=pyspark >/home/test/.jupyter_out/jupyter.log 2>&1 &\n```\n\n如果使用root账户启动，命令中加 --allow-root\n\n``` bash\nnohup jupyter notebook --profile=pyspark --allow-root >/home/test/.jupyter_out/jupyter.log 2>&1 &\n```\n\n到这里Jupyter服务已部署完毕。\n\n## <font color=#c00>小结</font>\n\n完成上述配置后，我们的IDE也部署完成了，不过还有一些小缺陷，就是Jupyter无法访问HBase。下篇文件我们开始[《Thrift 部署》](/ai/hadoop-thr/)\n\n本系列文章[《目录》](/ai/hadoop-start/)","slug":"hadoop-jpt","published":1,"updated":"2018-04-04T02:12:48.000Z","_id":"cjfjgup8000043knaw1ri86rf","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Jupyter Notebook 是一个Python在线编辑器，在机器学习领域很流行，调试代码也很方便。当然你可以选择其他编辑器。因为后面的示例会有一部分使用Python完成，所以这篇我们来部署Jupyter。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"Anaconda\"><a href=\"#Anaconda\" class=\"headerlink\" title=\"Anaconda\"></a><font color=\"#c00\">Anaconda</font></h2><h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>Anaconda是Python的版本管理工具，登陆<a href=\"https://www.anaconda.com/\" target=\"_blank\" rel=\"noopener\">官方网站</a>下载安装包，其安装文件分为Python3.x与Python2.7版本。</p>\n<a id=\"more\"></a>\n<p>首先选择一个主要Python版本，这里选择2.7，所以我们下载Anaconda(py2)，下载可直接运行sh文件进行安装。安装完成后可运行如下指令查看conda的信息：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda info</span><br></pre></td></tr></table></figure>\n<h3 id=\"切换Python3\"><a href=\"#切换Python3\" class=\"headerlink\" title=\"切换Python3\"></a>切换Python3</h3><p>运行如下命令，安装Python3</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n py3 python=3</span><br></pre></td></tr></table></figure>\n<h3 id=\"版本切换\"><a href=\"#版本切换\" class=\"headerlink\" title=\"版本切换\"></a>版本切换</h3><p>回到py2</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">source</span> deactivate py3</span><br></pre></td></tr></table></figure>\n<p>进入py3</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">source</span> activate py3</span><br></pre></td></tr></table></figure>\n<p>除了Anaconda，你也可以安装它的mini版，Miniconda。</p>\n<p>Anaconda包内已经包含了Jupyter，在装完anaconda应该会自动安装了Jupyter，下面就可以直接启动Jupyter服务了。</p>\n<h2 id=\"Jupyter\"><a href=\"#Jupyter\" class=\"headerlink\" title=\"Jupyter\"></a><font color=\"#c00\">Jupyter</font></h2><font color=\"#c00\">注：启动Jupyter服务建议不要使用root账户，原因后面会说到，所以我们切换到其他账户，这里我切换到test账户：</font>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">su <span class=\"built_in\">test</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"生成配置文件\"><a href=\"#生成配置文件\" class=\"headerlink\" title=\"生成配置文件\"></a>生成配置文件</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure>\n<p>生成后的文件会在~/.jupyter中</p>\n<h3 id=\"自动生成密钥\"><a href=\"#自动生成密钥\" class=\"headerlink\" title=\"自动生成密钥\"></a>自动生成密钥</h3><p>因为服务开放后，所有人都可以访问，所以需要配置密码（此步也是必须的）。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter notebook password</span><br></pre></td></tr></table></figure>\n<p>运行此命令后，可输入两次密码，完成后会在~/.jupyter/upyter_notebook_config.json文件中生成一串token。</p>\n<h3 id=\"配置HTTP服务\"><a href=\"#配置HTTP服务\" class=\"headerlink\" title=\"配置HTTP服务\"></a>配置HTTP服务</h3><p>打开~/.jupyter/jupyter_notebook_config.py文件，修改如下配置项：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 容许所有IP可访问</span></span><br><span class=\"line\">c.NotebookApp.ip = <span class=\"string\">'*'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 初始化notebook工作区根目录，我在test帐户下，新建jupyter_notebook文件夹作为根目录</span></span><br><span class=\"line\">c.NotebookApp.notebook_dir = u<span class=\"string\">'/home/test/jupyter_notebook'</span></span><br><span class=\"line\"></span><br><span class=\"line\">＃ 是否打开浏览器立即启动</span><br><span class=\"line\">c.NotebookApp.open_browser = False</span><br><span class=\"line\"></span><br><span class=\"line\">＃ 之前生成的token</span><br><span class=\"line\">c.NotebookApp.password ＝ u<span class=\"string\">'sha1:xxx'</span></span><br><span class=\"line\"></span><br><span class=\"line\">＃ 端口配置</span><br><span class=\"line\">c.NotebookApp.port = 8888</span><br></pre></td></tr></table></figure>\n<h3 id=\"运行服务\"><a href=\"#运行服务\" class=\"headerlink\" title=\"运行服务\"></a>运行服务</h3><p>新建.jupyter_out文件夹，将所有log日志记录在jupyter.log文件中。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nohup jupyter notebook &gt;/home/<span class=\"built_in\">test</span>/.jupyter_out/jupyter.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n<font color=\"#c00\">注：jupyter服务不是jps服务，所以需要使用ps命令查看</font>\n\n<h2 id=\"HTTP访问\"><a href=\"#HTTP访问\" class=\"headerlink\" title=\"HTTP访问\"></a><font color=\"#c00\">HTTP访问</font></h2><p>启动完成后，浏览器访问8888端口，就可以正常打开Jupyter了，</p>\n<font color=\"#c00\">注：第一次登陆需要填写密码</font>\n\n<p><img src=\"/images/post/ai/hdp17.png\" alt=\"jupyter\"></p>\n<font color=\"#c00\">注：之前有提到启动Jupyter服务，我建议切换到非root账户，原因是在Jupyter Notebook中用户可以新建命令行终端，你用什么账户启动服务，这里新建的终端将会以什么账户登录。所以为了控制用户权限及系统安全的考虑，不建议使用root账户去启动服务。</font>\n\n<p><img src=\"/images/post/ai/hdp19.png\" alt=\"noroot\"></p>\n<p>因为我们用test账户启动Jupyter服务，所以下图可以看到命令行窗口默认test用户登录。</p>\n<p><img src=\"/images/post/ai/hdp21.png\" alt=\"cmd\"></p>\n<h2 id=\"Spark集群配置\"><a href=\"#Spark集群配置\" class=\"headerlink\" title=\"Spark集群配置\"></a><font color=\"#c00\">Spark集群配置</font></h2><p>为了让我们的jupyter可以访问Sprak集群去计算任务，我们还需要配置PySpark，<a href=\"http://blog.cloudera.com/blog/2014/08/how-to-use-ipython-notebook-with-apache-spark/\" target=\"_blank\" rel=\"noopener\">请点击此处查看</a>具体配置教程</p>\n<p>因为配置过后时间隔的太久，记得不是很清楚了，可以试试如下命令，启动集群</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nohup jupyter notebook --profile=pyspark &gt;/home/<span class=\"built_in\">test</span>/.jupyter_out/jupyter.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n<p>如果使用root账户启动，命令中加 –allow-root</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nohup jupyter notebook --profile=pyspark --allow-root &gt;/home/<span class=\"built_in\">test</span>/.jupyter_out/jupyter.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n<p>到这里Jupyter服务已部署完毕。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成上述配置后，我们的IDE也部署完成了，不过还有一些小缺陷，就是Jupyter无法访问HBase。下篇文件我们开始<a href=\"/ai/hadoop-thr/\">《Thrift 部署》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>\n","site":{"data":{}},"excerpt":"<p>Jupyter Notebook 是一个Python在线编辑器，在机器学习领域很流行，调试代码也很方便。当然你可以选择其他编辑器。因为后面的示例会有一部分使用Python完成，所以这篇我们来部署Jupyter。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"Anaconda\"><a href=\"#Anaconda\" class=\"headerlink\" title=\"Anaconda\"></a><font color=\"#c00\">Anaconda</font></h2><h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>Anaconda是Python的版本管理工具，登陆<a href=\"https://www.anaconda.com/\" target=\"_blank\" rel=\"noopener\">官方网站</a>下载安装包，其安装文件分为Python3.x与Python2.7版本。</p>","more":"<p>首先选择一个主要Python版本，这里选择2.7，所以我们下载Anaconda(py2)，下载可直接运行sh文件进行安装。安装完成后可运行如下指令查看conda的信息：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda info</span><br></pre></td></tr></table></figure>\n<h3 id=\"切换Python3\"><a href=\"#切换Python3\" class=\"headerlink\" title=\"切换Python3\"></a>切换Python3</h3><p>运行如下命令，安装Python3</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n py3 python=3</span><br></pre></td></tr></table></figure>\n<h3 id=\"版本切换\"><a href=\"#版本切换\" class=\"headerlink\" title=\"版本切换\"></a>版本切换</h3><p>回到py2</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">source</span> deactivate py3</span><br></pre></td></tr></table></figure>\n<p>进入py3</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">source</span> activate py3</span><br></pre></td></tr></table></figure>\n<p>除了Anaconda，你也可以安装它的mini版，Miniconda。</p>\n<p>Anaconda包内已经包含了Jupyter，在装完anaconda应该会自动安装了Jupyter，下面就可以直接启动Jupyter服务了。</p>\n<h2 id=\"Jupyter\"><a href=\"#Jupyter\" class=\"headerlink\" title=\"Jupyter\"></a><font color=\"#c00\">Jupyter</font></h2><font color=\"#c00\">注：启动Jupyter服务建议不要使用root账户，原因后面会说到，所以我们切换到其他账户，这里我切换到test账户：</font>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">su <span class=\"built_in\">test</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"生成配置文件\"><a href=\"#生成配置文件\" class=\"headerlink\" title=\"生成配置文件\"></a>生成配置文件</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure>\n<p>生成后的文件会在~/.jupyter中</p>\n<h3 id=\"自动生成密钥\"><a href=\"#自动生成密钥\" class=\"headerlink\" title=\"自动生成密钥\"></a>自动生成密钥</h3><p>因为服务开放后，所有人都可以访问，所以需要配置密码（此步也是必须的）。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jupyter notebook password</span><br></pre></td></tr></table></figure>\n<p>运行此命令后，可输入两次密码，完成后会在~/.jupyter/upyter_notebook_config.json文件中生成一串token。</p>\n<h3 id=\"配置HTTP服务\"><a href=\"#配置HTTP服务\" class=\"headerlink\" title=\"配置HTTP服务\"></a>配置HTTP服务</h3><p>打开~/.jupyter/jupyter_notebook_config.py文件，修改如下配置项：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 容许所有IP可访问</span></span><br><span class=\"line\">c.NotebookApp.ip = <span class=\"string\">'*'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 初始化notebook工作区根目录，我在test帐户下，新建jupyter_notebook文件夹作为根目录</span></span><br><span class=\"line\">c.NotebookApp.notebook_dir = u<span class=\"string\">'/home/test/jupyter_notebook'</span></span><br><span class=\"line\"></span><br><span class=\"line\">＃ 是否打开浏览器立即启动</span><br><span class=\"line\">c.NotebookApp.open_browser = False</span><br><span class=\"line\"></span><br><span class=\"line\">＃ 之前生成的token</span><br><span class=\"line\">c.NotebookApp.password ＝ u<span class=\"string\">'sha1:xxx'</span></span><br><span class=\"line\"></span><br><span class=\"line\">＃ 端口配置</span><br><span class=\"line\">c.NotebookApp.port = 8888</span><br></pre></td></tr></table></figure>\n<h3 id=\"运行服务\"><a href=\"#运行服务\" class=\"headerlink\" title=\"运行服务\"></a>运行服务</h3><p>新建.jupyter_out文件夹，将所有log日志记录在jupyter.log文件中。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nohup jupyter notebook &gt;/home/<span class=\"built_in\">test</span>/.jupyter_out/jupyter.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n<font color=\"#c00\">注：jupyter服务不是jps服务，所以需要使用ps命令查看</font>\n\n<h2 id=\"HTTP访问\"><a href=\"#HTTP访问\" class=\"headerlink\" title=\"HTTP访问\"></a><font color=\"#c00\">HTTP访问</font></h2><p>启动完成后，浏览器访问8888端口，就可以正常打开Jupyter了，</p>\n<font color=\"#c00\">注：第一次登陆需要填写密码</font>\n\n<p><img src=\"/images/post/ai/hdp17.png\" alt=\"jupyter\"></p>\n<font color=\"#c00\">注：之前有提到启动Jupyter服务，我建议切换到非root账户，原因是在Jupyter Notebook中用户可以新建命令行终端，你用什么账户启动服务，这里新建的终端将会以什么账户登录。所以为了控制用户权限及系统安全的考虑，不建议使用root账户去启动服务。</font>\n\n<p><img src=\"/images/post/ai/hdp19.png\" alt=\"noroot\"></p>\n<p>因为我们用test账户启动Jupyter服务，所以下图可以看到命令行窗口默认test用户登录。</p>\n<p><img src=\"/images/post/ai/hdp21.png\" alt=\"cmd\"></p>\n<h2 id=\"Spark集群配置\"><a href=\"#Spark集群配置\" class=\"headerlink\" title=\"Spark集群配置\"></a><font color=\"#c00\">Spark集群配置</font></h2><p>为了让我们的jupyter可以访问Sprak集群去计算任务，我们还需要配置PySpark，<a href=\"http://blog.cloudera.com/blog/2014/08/how-to-use-ipython-notebook-with-apache-spark/\" target=\"_blank\" rel=\"noopener\">请点击此处查看</a>具体配置教程</p>\n<p>因为配置过后时间隔的太久，记得不是很清楚了，可以试试如下命令，启动集群</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nohup jupyter notebook --profile=pyspark &gt;/home/<span class=\"built_in\">test</span>/.jupyter_out/jupyter.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n<p>如果使用root账户启动，命令中加 –allow-root</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nohup jupyter notebook --profile=pyspark --allow-root &gt;/home/<span class=\"built_in\">test</span>/.jupyter_out/jupyter.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n<p>到这里Jupyter服务已部署完毕。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成上述配置后，我们的IDE也部署完成了，不过还有一些小缺陷，就是Jupyter无法访问HBase。下篇文件我们开始<a href=\"/ai/hadoop-thr/\">《Thrift 部署》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>"},{"title":"HBase 部署","date":"2018-04-02T03:36:18.000Z","_content":"完成之前的章节，我们已经将Hadoop集群与Spark计算引擎成功部署在4个节点中了。你可以使用Java或者Scala语言（这里推荐Scala）进行开发，并可以用Spark正常进行数据挖掘了。这章我们讲HBase的部署，基本与数据存储有关。\n\n# Quick Start\n\n## <font color=#c00>下载安装</font>\n\n按照之前的规划表，我们会在node3中启动HBase的主进程，在node2中启动备用进程，所以在这篇文章我们选择在node3中进行配置。\n\n登陆node3节点，并下载HBase安装包，版本1.3.1，下载完成后解压（文件目录还是统一放在/opt路径下）并进入该文件夹。\n\n<!--more-->\n\n## <font color=#c00>基础配置</font>\n\n打开conf/hbase-site.xml文件，在configuration标签中添加如下配置项：\n\n### 启动集群模式\n\n``` xml\n<property>\n   <name>hbase.cluster.distributed</name>\n   <value>true</value>\n</property>\n```\n\n### HDFS中设置HBase主目录\n\n``` xml\n<property>\n   <name>hbase.rootdir</name>\n   <value>hdfs://mycluster/hbase</value>\n</property>\n```\n\n### ZooKeeper集群地址\n\n``` xml\n<property>\n   <name>hbase.zookeeper.quorum</name>\n   <value>node0的IP, node2的IP, node3的IP</value>\n</property>\n```\n\n### ZooKeeper快照存储位置\n\n<font color=#c00>注：此项与zoo.conf中dataDir路径相同。</font>\n\n``` xml\n<property>\n   <name>hbase.zookeeper.property.dataDir</name>\n   <value>/opt/zookeeper-3.4.10/zk_data</value>\n</property>\n```\n\n## <font color=#c00>配置元数据存储节点</font>\n\nHBase中的数据分为元数据（文件索引）与文件本身数据，文件数据由DataNode负责存取，元数据则由HRegionServer负责。按照规划表，我们会把元数据分布在4台节点中，所以我们需要在所有节点中部署HRegionServer，配置方法如下：\n\n在conf文件夹中打开regionservers文件（如果未找到，新建即可）。添加如下内容：\n\n``` bash\nnode0的IP\nnode1的IP\nnode2的IP\nnode3的IP\n```\n\n## <font color=#c00>配置环境变量</font>\n\n``` bash\n# Java环境变量是必不可少的。\nexport JAVA_HOME=/opt/jdk1.8.0_65\n\n# 因为HBase自身就带有一个ZooKeeper，非集群模式时，我们可以用它自己带的就好，集群模式下关闭它，防止启动多个ZooKeeper\nexport HBASE_MANAGES_ZK=false\n\n# 让HBase可以找到Hadoop的配置文件hdfs-site.xml，这里配置目录路径就好。\nexport HBASE_CLASSPATH=/opt/hadoop-2.7.4/etc/hadoop\n\n# HBase工作目录路径（tmp文件夹是我自己创建的，你也可以指定到别的路径下）\nexport HBASE_PID_DIR=/opt/hbase-1.3.1/tmp\n```\n\n## <font color=#c00>分发安装包</font>\n\n将配置好的HBase文件夹拷贝到所有节点中\n\n``` bash\nscp -r /opt/hbase-1.3.1 root@node0:/opt\nscp -r /opt/hbase-1.3.1 root@node1:/opt\nscp -r /opt/hbase-1.3.1 root@node2:/opt\n```\n\n## <font color=#c00>启动服务</font>\n\n在node3上执行如下命令：\n\n``` bash\nbin/start-hbase.sh\n```\n\n执行完成后使用jps命令进行查看，node3中会有HMaster和HRegionServer服务\n\n## <font color=#c00>HA</font>\n\n为了达到高可用，我们需要启动一个备用进程，按照规划图，在node2中运行如下命令：\n\n``` bash\nbin/hbase-daemon.sh start master\n```\n\n## <font color=#c00>Web 访问</font>\n\n在浏览其中输入地址可以访问HMaster\n![master](/images/post/ai/hdp15.png)\n\n访问HRegionServer\n![regionserver](/images/post/ai/hdp16.png)\n\n## <font color=#c00>测试</font>\n\n### SHELL\n\n在命令行中输入如下命令，进入hbase shell界面后，可执行一些基础操作。\n\n``` bash\nbin/hbase shell\n```\n\n<font color=#c00>注：HBase的命令与其它数据库（例如：MySql）不同，命令行结束后不能加分号，名称（表名）要加引号（双引号或单引号）</font>\n\n### 创建表\n\n``` bash\ncreate '表名', '列族'\n```\n\n### 查看所有表\n\n``` bash\nlist\n```\n\n### 查看表属性\n\n``` bash\ndescribe '表名'\n```\n\n### 插入数据\n\n``` bash\nput '表名', 'rowkey', '列族:列', '值'\n```\n\n### 查看表中所有数据\n\n``` bash\nscan '表名'\n```\n\n以上是一些基础命令的测试，如果你对HBase的shell操作有更多的兴趣，请点击下方官方文档进行查阅。\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://hbase.apache.org/book.html)\n\n## <font color=#c00>小结</font>\n\n完成上述配置后，HBase可以正常访问了，基础的存储与计算都配置完成。下篇文件我们开始[《Jupyter 部署》](/ai/hadoop-jpt/)\n\n本系列文章[《目录》](/ai/hadoop-start/)\n","source":"_posts/hadoop-hbs.md","raw":"---\ntitle: HBase 部署\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-04-02 11:36:18\n---\n完成之前的章节，我们已经将Hadoop集群与Spark计算引擎成功部署在4个节点中了。你可以使用Java或者Scala语言（这里推荐Scala）进行开发，并可以用Spark正常进行数据挖掘了。这章我们讲HBase的部署，基本与数据存储有关。\n\n# Quick Start\n\n## <font color=#c00>下载安装</font>\n\n按照之前的规划表，我们会在node3中启动HBase的主进程，在node2中启动备用进程，所以在这篇文章我们选择在node3中进行配置。\n\n登陆node3节点，并下载HBase安装包，版本1.3.1，下载完成后解压（文件目录还是统一放在/opt路径下）并进入该文件夹。\n\n<!--more-->\n\n## <font color=#c00>基础配置</font>\n\n打开conf/hbase-site.xml文件，在configuration标签中添加如下配置项：\n\n### 启动集群模式\n\n``` xml\n<property>\n   <name>hbase.cluster.distributed</name>\n   <value>true</value>\n</property>\n```\n\n### HDFS中设置HBase主目录\n\n``` xml\n<property>\n   <name>hbase.rootdir</name>\n   <value>hdfs://mycluster/hbase</value>\n</property>\n```\n\n### ZooKeeper集群地址\n\n``` xml\n<property>\n   <name>hbase.zookeeper.quorum</name>\n   <value>node0的IP, node2的IP, node3的IP</value>\n</property>\n```\n\n### ZooKeeper快照存储位置\n\n<font color=#c00>注：此项与zoo.conf中dataDir路径相同。</font>\n\n``` xml\n<property>\n   <name>hbase.zookeeper.property.dataDir</name>\n   <value>/opt/zookeeper-3.4.10/zk_data</value>\n</property>\n```\n\n## <font color=#c00>配置元数据存储节点</font>\n\nHBase中的数据分为元数据（文件索引）与文件本身数据，文件数据由DataNode负责存取，元数据则由HRegionServer负责。按照规划表，我们会把元数据分布在4台节点中，所以我们需要在所有节点中部署HRegionServer，配置方法如下：\n\n在conf文件夹中打开regionservers文件（如果未找到，新建即可）。添加如下内容：\n\n``` bash\nnode0的IP\nnode1的IP\nnode2的IP\nnode3的IP\n```\n\n## <font color=#c00>配置环境变量</font>\n\n``` bash\n# Java环境变量是必不可少的。\nexport JAVA_HOME=/opt/jdk1.8.0_65\n\n# 因为HBase自身就带有一个ZooKeeper，非集群模式时，我们可以用它自己带的就好，集群模式下关闭它，防止启动多个ZooKeeper\nexport HBASE_MANAGES_ZK=false\n\n# 让HBase可以找到Hadoop的配置文件hdfs-site.xml，这里配置目录路径就好。\nexport HBASE_CLASSPATH=/opt/hadoop-2.7.4/etc/hadoop\n\n# HBase工作目录路径（tmp文件夹是我自己创建的，你也可以指定到别的路径下）\nexport HBASE_PID_DIR=/opt/hbase-1.3.1/tmp\n```\n\n## <font color=#c00>分发安装包</font>\n\n将配置好的HBase文件夹拷贝到所有节点中\n\n``` bash\nscp -r /opt/hbase-1.3.1 root@node0:/opt\nscp -r /opt/hbase-1.3.1 root@node1:/opt\nscp -r /opt/hbase-1.3.1 root@node2:/opt\n```\n\n## <font color=#c00>启动服务</font>\n\n在node3上执行如下命令：\n\n``` bash\nbin/start-hbase.sh\n```\n\n执行完成后使用jps命令进行查看，node3中会有HMaster和HRegionServer服务\n\n## <font color=#c00>HA</font>\n\n为了达到高可用，我们需要启动一个备用进程，按照规划图，在node2中运行如下命令：\n\n``` bash\nbin/hbase-daemon.sh start master\n```\n\n## <font color=#c00>Web 访问</font>\n\n在浏览其中输入地址可以访问HMaster\n![master](/images/post/ai/hdp15.png)\n\n访问HRegionServer\n![regionserver](/images/post/ai/hdp16.png)\n\n## <font color=#c00>测试</font>\n\n### SHELL\n\n在命令行中输入如下命令，进入hbase shell界面后，可执行一些基础操作。\n\n``` bash\nbin/hbase shell\n```\n\n<font color=#c00>注：HBase的命令与其它数据库（例如：MySql）不同，命令行结束后不能加分号，名称（表名）要加引号（双引号或单引号）</font>\n\n### 创建表\n\n``` bash\ncreate '表名', '列族'\n```\n\n### 查看所有表\n\n``` bash\nlist\n```\n\n### 查看表属性\n\n``` bash\ndescribe '表名'\n```\n\n### 插入数据\n\n``` bash\nput '表名', 'rowkey', '列族:列', '值'\n```\n\n### 查看表中所有数据\n\n``` bash\nscan '表名'\n```\n\n以上是一些基础命令的测试，如果你对HBase的shell操作有更多的兴趣，请点击下方官方文档进行查阅。\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://hbase.apache.org/book.html)\n\n## <font color=#c00>小结</font>\n\n完成上述配置后，HBase可以正常访问了，基础的存储与计算都配置完成。下篇文件我们开始[《Jupyter 部署》](/ai/hadoop-jpt/)\n\n本系列文章[《目录》](/ai/hadoop-start/)\n","slug":"hadoop-hbs","published":1,"updated":"2018-04-03T04:09:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup8100053kna1tak3b6z","content":"<p>完成之前的章节，我们已经将Hadoop集群与Spark计算引擎成功部署在4个节点中了。你可以使用Java或者Scala语言（这里推荐Scala）进行开发，并可以用Spark正常进行数据挖掘了。这章我们讲HBase的部署，基本与数据存储有关。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"下载安装\"><a href=\"#下载安装\" class=\"headerlink\" title=\"下载安装\"></a><font color=\"#c00\">下载安装</font></h2><p>按照之前的规划表，我们会在node3中启动HBase的主进程，在node2中启动备用进程，所以在这篇文章我们选择在node3中进行配置。</p>\n<p>登陆node3节点，并下载HBase安装包，版本1.3.1，下载完成后解压（文件目录还是统一放在/opt路径下）并进入该文件夹。</p>\n<a id=\"more\"></a>\n<h2 id=\"基础配置\"><a href=\"#基础配置\" class=\"headerlink\" title=\"基础配置\"></a><font color=\"#c00\">基础配置</font></h2><p>打开conf/hbase-site.xml文件，在configuration标签中添加如下配置项：</p>\n<h3 id=\"启动集群模式\"><a href=\"#启动集群模式\" class=\"headerlink\" title=\"启动集群模式\"></a>启动集群模式</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>hbase.cluster.distributed<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"HDFS中设置HBase主目录\"><a href=\"#HDFS中设置HBase主目录\" class=\"headerlink\" title=\"HDFS中设置HBase主目录\"></a>HDFS中设置HBase主目录</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>hbase.rootdir<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>hdfs://mycluster/hbase<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"ZooKeeper集群地址\"><a href=\"#ZooKeeper集群地址\" class=\"headerlink\" title=\"ZooKeeper集群地址\"></a>ZooKeeper集群地址</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>hbase.zookeeper.quorum<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node0的IP, node2的IP, node3的IP<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"ZooKeeper快照存储位置\"><a href=\"#ZooKeeper快照存储位置\" class=\"headerlink\" title=\"ZooKeeper快照存储位置\"></a>ZooKeeper快照存储位置</h3><font color=\"#c00\">注：此项与zoo.conf中dataDir路径相同。</font>\n\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>/opt/zookeeper-3.4.10/zk_data<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"配置元数据存储节点\"><a href=\"#配置元数据存储节点\" class=\"headerlink\" title=\"配置元数据存储节点\"></a><font color=\"#c00\">配置元数据存储节点</font></h2><p>HBase中的数据分为元数据（文件索引）与文件本身数据，文件数据由DataNode负责存取，元数据则由HRegionServer负责。按照规划表，我们会把元数据分布在4台节点中，所以我们需要在所有节点中部署HRegionServer，配置方法如下：</p>\n<p>在conf文件夹中打开regionservers文件（如果未找到，新建即可）。添加如下内容：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node0的IP</span><br><span class=\"line\">node1的IP</span><br><span class=\"line\">node2的IP</span><br><span class=\"line\">node3的IP</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置环境变量\"><a href=\"#配置环境变量\" class=\"headerlink\" title=\"配置环境变量\"></a><font color=\"#c00\">配置环境变量</font></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Java环境变量是必不可少的。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/opt/jdk1.8.0_65</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为HBase自身就带有一个ZooKeeper，非集群模式时，我们可以用它自己带的就好，集群模式下关闭它，防止启动多个ZooKeeper</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> HBASE_MANAGES_ZK=<span class=\"literal\">false</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 让HBase可以找到Hadoop的配置文件hdfs-site.xml，这里配置目录路径就好。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> HBASE_CLASSPATH=/opt/hadoop-2.7.4/etc/hadoop</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># HBase工作目录路径（tmp文件夹是我自己创建的，你也可以指定到别的路径下）</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> HBASE_PID_DIR=/opt/hbase-1.3.1/tmp</span><br></pre></td></tr></table></figure>\n<h2 id=\"分发安装包\"><a href=\"#分发安装包\" class=\"headerlink\" title=\"分发安装包\"></a><font color=\"#c00\">分发安装包</font></h2><p>将配置好的HBase文件夹拷贝到所有节点中</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp -r /opt/hbase-1.3.1 root@node0:/opt</span><br><span class=\"line\">scp -r /opt/hbase-1.3.1 root@node1:/opt</span><br><span class=\"line\">scp -r /opt/hbase-1.3.1 root@node2:/opt</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动服务\"><a href=\"#启动服务\" class=\"headerlink\" title=\"启动服务\"></a><font color=\"#c00\">启动服务</font></h2><p>在node3上执行如下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/start-hbase.sh</span><br></pre></td></tr></table></figure>\n<p>执行完成后使用jps命令进行查看，node3中会有HMaster和HRegionServer服务</p>\n<h2 id=\"HA\"><a href=\"#HA\" class=\"headerlink\" title=\"HA\"></a><font color=\"#c00\">HA</font></h2><p>为了达到高可用，我们需要启动一个备用进程，按照规划图，在node2中运行如下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hbase-daemon.sh start master</span><br></pre></td></tr></table></figure>\n<h2 id=\"Web-访问\"><a href=\"#Web-访问\" class=\"headerlink\" title=\"Web 访问\"></a><font color=\"#c00\">Web 访问</font></h2><p>在浏览其中输入地址可以访问HMaster<br><img src=\"/images/post/ai/hdp15.png\" alt=\"master\"></p>\n<p>访问HRegionServer<br><img src=\"/images/post/ai/hdp16.png\" alt=\"regionserver\"></p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a><font color=\"#c00\">测试</font></h2><h3 id=\"SHELL\"><a href=\"#SHELL\" class=\"headerlink\" title=\"SHELL\"></a>SHELL</h3><p>在命令行中输入如下命令，进入hbase shell界面后，可执行一些基础操作。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hbase shell</span><br></pre></td></tr></table></figure>\n<font color=\"#c00\">注：HBase的命令与其它数据库（例如：MySql）不同，命令行结束后不能加分号，名称（表名）要加引号（双引号或单引号）</font>\n\n<h3 id=\"创建表\"><a href=\"#创建表\" class=\"headerlink\" title=\"创建表\"></a>创建表</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">create <span class=\"string\">'表名'</span>, <span class=\"string\">'列族'</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"查看所有表\"><a href=\"#查看所有表\" class=\"headerlink\" title=\"查看所有表\"></a>查看所有表</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">list</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看表属性\"><a href=\"#查看表属性\" class=\"headerlink\" title=\"查看表属性\"></a>查看表属性</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">describe <span class=\"string\">'表名'</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"插入数据\"><a href=\"#插入数据\" class=\"headerlink\" title=\"插入数据\"></a>插入数据</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">put <span class=\"string\">'表名'</span>, <span class=\"string\">'rowkey'</span>, <span class=\"string\">'列族:列'</span>, <span class=\"string\">'值'</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"查看表中所有数据\"><a href=\"#查看表中所有数据\" class=\"headerlink\" title=\"查看表中所有数据\"></a>查看表中所有数据</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scan <span class=\"string\">'表名'</span></span><br></pre></td></tr></table></figure>\n<p>以上是一些基础命令的测试，如果你对HBase的shell操作有更多的兴趣，请点击下方官方文档进行查阅。</p>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://hbase.apache.org/book.html\" target=\"_blank\" rel=\"noopener\">官方文档</a></p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成上述配置后，HBase可以正常访问了，基础的存储与计算都配置完成。下篇文件我们开始<a href=\"/ai/hadoop-jpt/\">《Jupyter 部署》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>\n","site":{"data":{}},"excerpt":"<p>完成之前的章节，我们已经将Hadoop集群与Spark计算引擎成功部署在4个节点中了。你可以使用Java或者Scala语言（这里推荐Scala）进行开发，并可以用Spark正常进行数据挖掘了。这章我们讲HBase的部署，基本与数据存储有关。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"下载安装\"><a href=\"#下载安装\" class=\"headerlink\" title=\"下载安装\"></a><font color=\"#c00\">下载安装</font></h2><p>按照之前的规划表，我们会在node3中启动HBase的主进程，在node2中启动备用进程，所以在这篇文章我们选择在node3中进行配置。</p>\n<p>登陆node3节点，并下载HBase安装包，版本1.3.1，下载完成后解压（文件目录还是统一放在/opt路径下）并进入该文件夹。</p>","more":"<h2 id=\"基础配置\"><a href=\"#基础配置\" class=\"headerlink\" title=\"基础配置\"></a><font color=\"#c00\">基础配置</font></h2><p>打开conf/hbase-site.xml文件，在configuration标签中添加如下配置项：</p>\n<h3 id=\"启动集群模式\"><a href=\"#启动集群模式\" class=\"headerlink\" title=\"启动集群模式\"></a>启动集群模式</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>hbase.cluster.distributed<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"HDFS中设置HBase主目录\"><a href=\"#HDFS中设置HBase主目录\" class=\"headerlink\" title=\"HDFS中设置HBase主目录\"></a>HDFS中设置HBase主目录</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>hbase.rootdir<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>hdfs://mycluster/hbase<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"ZooKeeper集群地址\"><a href=\"#ZooKeeper集群地址\" class=\"headerlink\" title=\"ZooKeeper集群地址\"></a>ZooKeeper集群地址</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>hbase.zookeeper.quorum<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node0的IP, node2的IP, node3的IP<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"ZooKeeper快照存储位置\"><a href=\"#ZooKeeper快照存储位置\" class=\"headerlink\" title=\"ZooKeeper快照存储位置\"></a>ZooKeeper快照存储位置</h3><font color=\"#c00\">注：此项与zoo.conf中dataDir路径相同。</font>\n\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>/opt/zookeeper-3.4.10/zk_data<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"配置元数据存储节点\"><a href=\"#配置元数据存储节点\" class=\"headerlink\" title=\"配置元数据存储节点\"></a><font color=\"#c00\">配置元数据存储节点</font></h2><p>HBase中的数据分为元数据（文件索引）与文件本身数据，文件数据由DataNode负责存取，元数据则由HRegionServer负责。按照规划表，我们会把元数据分布在4台节点中，所以我们需要在所有节点中部署HRegionServer，配置方法如下：</p>\n<p>在conf文件夹中打开regionservers文件（如果未找到，新建即可）。添加如下内容：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node0的IP</span><br><span class=\"line\">node1的IP</span><br><span class=\"line\">node2的IP</span><br><span class=\"line\">node3的IP</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置环境变量\"><a href=\"#配置环境变量\" class=\"headerlink\" title=\"配置环境变量\"></a><font color=\"#c00\">配置环境变量</font></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Java环境变量是必不可少的。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/opt/jdk1.8.0_65</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为HBase自身就带有一个ZooKeeper，非集群模式时，我们可以用它自己带的就好，集群模式下关闭它，防止启动多个ZooKeeper</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> HBASE_MANAGES_ZK=<span class=\"literal\">false</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 让HBase可以找到Hadoop的配置文件hdfs-site.xml，这里配置目录路径就好。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> HBASE_CLASSPATH=/opt/hadoop-2.7.4/etc/hadoop</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># HBase工作目录路径（tmp文件夹是我自己创建的，你也可以指定到别的路径下）</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> HBASE_PID_DIR=/opt/hbase-1.3.1/tmp</span><br></pre></td></tr></table></figure>\n<h2 id=\"分发安装包\"><a href=\"#分发安装包\" class=\"headerlink\" title=\"分发安装包\"></a><font color=\"#c00\">分发安装包</font></h2><p>将配置好的HBase文件夹拷贝到所有节点中</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp -r /opt/hbase-1.3.1 root@node0:/opt</span><br><span class=\"line\">scp -r /opt/hbase-1.3.1 root@node1:/opt</span><br><span class=\"line\">scp -r /opt/hbase-1.3.1 root@node2:/opt</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动服务\"><a href=\"#启动服务\" class=\"headerlink\" title=\"启动服务\"></a><font color=\"#c00\">启动服务</font></h2><p>在node3上执行如下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/start-hbase.sh</span><br></pre></td></tr></table></figure>\n<p>执行完成后使用jps命令进行查看，node3中会有HMaster和HRegionServer服务</p>\n<h2 id=\"HA\"><a href=\"#HA\" class=\"headerlink\" title=\"HA\"></a><font color=\"#c00\">HA</font></h2><p>为了达到高可用，我们需要启动一个备用进程，按照规划图，在node2中运行如下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hbase-daemon.sh start master</span><br></pre></td></tr></table></figure>\n<h2 id=\"Web-访问\"><a href=\"#Web-访问\" class=\"headerlink\" title=\"Web 访问\"></a><font color=\"#c00\">Web 访问</font></h2><p>在浏览其中输入地址可以访问HMaster<br><img src=\"/images/post/ai/hdp15.png\" alt=\"master\"></p>\n<p>访问HRegionServer<br><img src=\"/images/post/ai/hdp16.png\" alt=\"regionserver\"></p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a><font color=\"#c00\">测试</font></h2><h3 id=\"SHELL\"><a href=\"#SHELL\" class=\"headerlink\" title=\"SHELL\"></a>SHELL</h3><p>在命令行中输入如下命令，进入hbase shell界面后，可执行一些基础操作。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hbase shell</span><br></pre></td></tr></table></figure>\n<font color=\"#c00\">注：HBase的命令与其它数据库（例如：MySql）不同，命令行结束后不能加分号，名称（表名）要加引号（双引号或单引号）</font>\n\n<h3 id=\"创建表\"><a href=\"#创建表\" class=\"headerlink\" title=\"创建表\"></a>创建表</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">create <span class=\"string\">'表名'</span>, <span class=\"string\">'列族'</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"查看所有表\"><a href=\"#查看所有表\" class=\"headerlink\" title=\"查看所有表\"></a>查看所有表</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">list</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看表属性\"><a href=\"#查看表属性\" class=\"headerlink\" title=\"查看表属性\"></a>查看表属性</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">describe <span class=\"string\">'表名'</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"插入数据\"><a href=\"#插入数据\" class=\"headerlink\" title=\"插入数据\"></a>插入数据</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">put <span class=\"string\">'表名'</span>, <span class=\"string\">'rowkey'</span>, <span class=\"string\">'列族:列'</span>, <span class=\"string\">'值'</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"查看表中所有数据\"><a href=\"#查看表中所有数据\" class=\"headerlink\" title=\"查看表中所有数据\"></a>查看表中所有数据</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scan <span class=\"string\">'表名'</span></span><br></pre></td></tr></table></figure>\n<p>以上是一些基础命令的测试，如果你对HBase的shell操作有更多的兴趣，请点击下方官方文档进行查阅。</p>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://hbase.apache.org/book.html\" target=\"_blank\" rel=\"noopener\">官方文档</a></p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成上述配置后，HBase可以正常访问了，基础的存储与计算都配置完成。下篇文件我们开始<a href=\"/ai/hadoop-jpt/\">《Jupyter 部署》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>"},{"title":"分布式平台前期规划","date":"2018-03-17T03:08:12.000Z","_content":"完成上一篇文章[《服务器批量安装》](/ai/hadoop-servers/)的内容后，我们已经拥有了4台Linux服务器，且相互之间网络可以互通，并且正常运行[SHH服务](https://baike.baidu.com/item/ssh/10407?fr=aladdin)。硬件环境已经准备完成，这篇文章我们将开始讲述<font color=#c00>Hadoop前期规划</font>的准备工作。[Hadoop](https://baike.baidu.com/item/Hadoop/3526507?fr=aladdin)是一系列工具的集合，如何合理的规划这些工具以及分配服务器资源，<font color=#c00>是一个非常重要的工作</font>。\n\n# Quick Start\n\n## <font color=#c00>主机名配置</font>\n\n我将分别修改主机名为node0，node1，node2，node3。方便教程的讲述，也方便ssh中的操作。选择其中一台服务器，<font color=#c00>root用户</font>登陆。\n\n<!--more-->\n\n### 查看主机名\n\n``` bash\nhostname\n```\n\n### 修改主机名\n\n- 方法一：修改network文件，将HOSTNAME后面的值改为node0，重启后生效。\n\n\n``` bash\nvim /etc/sysconfig/network\n```\n\n- 方法二：修改当前的主机名，立即生效。\n\n\n``` bash\nhostname node0\n```\n\n### 配置hosts文件\n\n修改/etc/hosts文件，<font color=#c00>ip0为你自己机器的ip地址</font>\n\n``` bash\nip0 node0\nip1 node1\nip2 node2\nip3 node3 \n```\n\n### 分发hosts文件\n\n将hosts文件分发到其他3台机器中，以保证所有服务器识别主机名。\n\n``` bash\nscp /etc/hosts root@node1:/etc/\nscp /etc/hosts root@node2:/etc/\nscp /etc/hosts root@node3:/etc/\n```\n\n## <font color=#c00>批量管理工具推荐</font>\n\n如果你想更快，更省力的完成批量操作，有兴趣的童鞋可以安装[Linux集群批量管理工具parallel-ssh(PSSH)](http://www.theether.org/pssh/)，该工具需要<font color=#c00>Python环境</font>，[安装及操作点击此处链接](http://man.linuxde.net/pssh)，该教程中还是采用普通命令进行讲述。\n\n## <font color=#c00>配置免密码登录</font>\n\n之后的服务器命令都需要免密码才能正常操作，这是一个必须而重要的步骤。我以node0批量操作其他服务器为例。此步骤需要在所有服务器中完成一边，以方便任意两台机器可以互相登陆。\n\n### 创建本机的公钥与私钥\n\n``` bash\ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\nchmod 0600 ~/.ssh/authorized_keys\n```\n\n### 分发公钥到其他3台服务器\n\n我以node1为例\n\n``` bash\nscp ~/.ssh/id_rsa.pub root@node1:~/\n```\n\n### 公钥追加\n\n进入node1的root账户的home目录下，运行如下命令。完成后，就可以从node0免密码登录到node1了。\n\n``` bash\ncat id_rsa.pub >> ~/.ssh/authorized_keys\n```\n\n## <font color=#c00>安装Java环境</font>\n\nhadoop整套工具都以Java环境为基础，所以4台机器都需要安装。我们以node0为例。\n\n### 查看是否安装\n\n``` bash\nsyum list installed | grep java\n```\n\n### 查看yum库中的Java安装包\n\n``` bash\nyum -y list java*\n```\n\n### 安装Java\n\n我们以版本1.8.0为例\n\n``` bash\nyum -y install java-1.8.0-openjdk*\n```\n\n### 配置环境变量\n\n1. 将jdk文件夹移动到opt文件夹下\n2. 在/etc/profile文件中追加如下内容：\n\n``` bash\nexport JAVA_HOME=/opt/jdk1.8.0_65\nexport PATH=$JAVA_HOME/bin:$PATH\n```\n\n## <font color=#c00>JSP进程集</font>\n\n### 工具集介绍\n\n在此篇基础工具集的规划中，我们主要安装Hadoop, ZooKeeper, HBase, Spark, Jupiter, Thrift。之后的教程中还会讲到Hive，MySQL等。每种工具都对应着一些Java进程，我们将规划这些进程分别部署到哪个服务器上。（话说，分布式应用，总不能把所有的进程都安装在一台服务器中吧。。。 - -!）\n\n<font color=#c00>注：如果你对上述工具还不熟悉，请跳转到[《Hadoop 基础教程》](/ai/hadoop-tutorial/)</font>\n\n### JSP进程\n\n[JSP](https://www.cnblogs.com/wzyxidian/p/5314148.html)是Java Virtual Machine Process Status Tool的缩写，在[JVM](https://baike.baidu.com/item/JVM/2902369?fr=aladdin)中所有具有访问权限的Java进程的具体状态, 包括进程ID，进程启动的路径及启动参数等等，与Linux上的ps命令类似，只不过jps是用来显示java进程，可以把jps理解为ps的一个子集。\n\n| 工具             | JPS进程                              |\n| ---------------- | ------------------------------------ |\n| ZooKeeper        | QuorumPeerMain |\n| HDFS             | NameNode, DataNode, JournalNode, ZKFailoverController      |\n| MapReduce, Spark | ResourceManager, NodeManager         |\n| HBase            | HMaster,  HRegionServer              |\n| Thrift           | ThriftServer                         |\n\n### 系统进程\n\n| 工具 | 系统进程 |\n| ---- | -------- |\n| Jupyter     | jupyter-notebook |\n\n## <font color=#c00>进程规划</font>\n\n### 规划图\n\n根据上一篇的教程，我们准备了4台服务器，我们将把上面介绍的进程部署在这4台服务器中，方案如下：\n![planning](/images/post/ai/hdp12.jpg)\n\n图中勾选的位置对应着进程将部署在哪台服务器。\n\n### 缩写对照表\n\n\n| 缩写 | 进程全称             |\n| ---- | -------------------- |\n| NN   | NameNode             |\n| DN   | DataNode             |\n| ZK   | QuorumPeerMain       |\n| ZKFC | ZKFailoverController |\n| JN   | JournalNode          |\n| RM   | ResourceManager      |\n| NM   | NodeManager          |\n| HM   | HMaster              |\n| HR   | HRegionServer        |\n| TS   | ThriftServer         |\n\n## <font color=#c00>小结</font>\n\n此篇主要介绍平台安装前的准备工作，以及要部署的工具集与JSP进程的规划方案，当然这个规划方案是以4台服务器为基础，如果你的服务器数量超过4台（无论怎样要大于等于3台，原因可以在[《Hadoop 基础教程》](/ai/hadoop-tutorial/)中了解，此处不在赘述！）规划方案可以相应调整，下篇[《ZooKeeper 部署》](/ai/hadoop-zkp/)。\n\n本系列文章[《目录》](/ai/hadoop-start/)","source":"_posts/hadoop-planning.md","raw":"---\ntitle: 分布式平台前期规划\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-03-17 11:08:12\n---\n完成上一篇文章[《服务器批量安装》](/ai/hadoop-servers/)的内容后，我们已经拥有了4台Linux服务器，且相互之间网络可以互通，并且正常运行[SHH服务](https://baike.baidu.com/item/ssh/10407?fr=aladdin)。硬件环境已经准备完成，这篇文章我们将开始讲述<font color=#c00>Hadoop前期规划</font>的准备工作。[Hadoop](https://baike.baidu.com/item/Hadoop/3526507?fr=aladdin)是一系列工具的集合，如何合理的规划这些工具以及分配服务器资源，<font color=#c00>是一个非常重要的工作</font>。\n\n# Quick Start\n\n## <font color=#c00>主机名配置</font>\n\n我将分别修改主机名为node0，node1，node2，node3。方便教程的讲述，也方便ssh中的操作。选择其中一台服务器，<font color=#c00>root用户</font>登陆。\n\n<!--more-->\n\n### 查看主机名\n\n``` bash\nhostname\n```\n\n### 修改主机名\n\n- 方法一：修改network文件，将HOSTNAME后面的值改为node0，重启后生效。\n\n\n``` bash\nvim /etc/sysconfig/network\n```\n\n- 方法二：修改当前的主机名，立即生效。\n\n\n``` bash\nhostname node0\n```\n\n### 配置hosts文件\n\n修改/etc/hosts文件，<font color=#c00>ip0为你自己机器的ip地址</font>\n\n``` bash\nip0 node0\nip1 node1\nip2 node2\nip3 node3 \n```\n\n### 分发hosts文件\n\n将hosts文件分发到其他3台机器中，以保证所有服务器识别主机名。\n\n``` bash\nscp /etc/hosts root@node1:/etc/\nscp /etc/hosts root@node2:/etc/\nscp /etc/hosts root@node3:/etc/\n```\n\n## <font color=#c00>批量管理工具推荐</font>\n\n如果你想更快，更省力的完成批量操作，有兴趣的童鞋可以安装[Linux集群批量管理工具parallel-ssh(PSSH)](http://www.theether.org/pssh/)，该工具需要<font color=#c00>Python环境</font>，[安装及操作点击此处链接](http://man.linuxde.net/pssh)，该教程中还是采用普通命令进行讲述。\n\n## <font color=#c00>配置免密码登录</font>\n\n之后的服务器命令都需要免密码才能正常操作，这是一个必须而重要的步骤。我以node0批量操作其他服务器为例。此步骤需要在所有服务器中完成一边，以方便任意两台机器可以互相登陆。\n\n### 创建本机的公钥与私钥\n\n``` bash\ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\nchmod 0600 ~/.ssh/authorized_keys\n```\n\n### 分发公钥到其他3台服务器\n\n我以node1为例\n\n``` bash\nscp ~/.ssh/id_rsa.pub root@node1:~/\n```\n\n### 公钥追加\n\n进入node1的root账户的home目录下，运行如下命令。完成后，就可以从node0免密码登录到node1了。\n\n``` bash\ncat id_rsa.pub >> ~/.ssh/authorized_keys\n```\n\n## <font color=#c00>安装Java环境</font>\n\nhadoop整套工具都以Java环境为基础，所以4台机器都需要安装。我们以node0为例。\n\n### 查看是否安装\n\n``` bash\nsyum list installed | grep java\n```\n\n### 查看yum库中的Java安装包\n\n``` bash\nyum -y list java*\n```\n\n### 安装Java\n\n我们以版本1.8.0为例\n\n``` bash\nyum -y install java-1.8.0-openjdk*\n```\n\n### 配置环境变量\n\n1. 将jdk文件夹移动到opt文件夹下\n2. 在/etc/profile文件中追加如下内容：\n\n``` bash\nexport JAVA_HOME=/opt/jdk1.8.0_65\nexport PATH=$JAVA_HOME/bin:$PATH\n```\n\n## <font color=#c00>JSP进程集</font>\n\n### 工具集介绍\n\n在此篇基础工具集的规划中，我们主要安装Hadoop, ZooKeeper, HBase, Spark, Jupiter, Thrift。之后的教程中还会讲到Hive，MySQL等。每种工具都对应着一些Java进程，我们将规划这些进程分别部署到哪个服务器上。（话说，分布式应用，总不能把所有的进程都安装在一台服务器中吧。。。 - -!）\n\n<font color=#c00>注：如果你对上述工具还不熟悉，请跳转到[《Hadoop 基础教程》](/ai/hadoop-tutorial/)</font>\n\n### JSP进程\n\n[JSP](https://www.cnblogs.com/wzyxidian/p/5314148.html)是Java Virtual Machine Process Status Tool的缩写，在[JVM](https://baike.baidu.com/item/JVM/2902369?fr=aladdin)中所有具有访问权限的Java进程的具体状态, 包括进程ID，进程启动的路径及启动参数等等，与Linux上的ps命令类似，只不过jps是用来显示java进程，可以把jps理解为ps的一个子集。\n\n| 工具             | JPS进程                              |\n| ---------------- | ------------------------------------ |\n| ZooKeeper        | QuorumPeerMain |\n| HDFS             | NameNode, DataNode, JournalNode, ZKFailoverController      |\n| MapReduce, Spark | ResourceManager, NodeManager         |\n| HBase            | HMaster,  HRegionServer              |\n| Thrift           | ThriftServer                         |\n\n### 系统进程\n\n| 工具 | 系统进程 |\n| ---- | -------- |\n| Jupyter     | jupyter-notebook |\n\n## <font color=#c00>进程规划</font>\n\n### 规划图\n\n根据上一篇的教程，我们准备了4台服务器，我们将把上面介绍的进程部署在这4台服务器中，方案如下：\n![planning](/images/post/ai/hdp12.jpg)\n\n图中勾选的位置对应着进程将部署在哪台服务器。\n\n### 缩写对照表\n\n\n| 缩写 | 进程全称             |\n| ---- | -------------------- |\n| NN   | NameNode             |\n| DN   | DataNode             |\n| ZK   | QuorumPeerMain       |\n| ZKFC | ZKFailoverController |\n| JN   | JournalNode          |\n| RM   | ResourceManager      |\n| NM   | NodeManager          |\n| HM   | HMaster              |\n| HR   | HRegionServer        |\n| TS   | ThriftServer         |\n\n## <font color=#c00>小结</font>\n\n此篇主要介绍平台安装前的准备工作，以及要部署的工具集与JSP进程的规划方案，当然这个规划方案是以4台服务器为基础，如果你的服务器数量超过4台（无论怎样要大于等于3台，原因可以在[《Hadoop 基础教程》](/ai/hadoop-tutorial/)中了解，此处不在赘述！）规划方案可以相应调整，下篇[《ZooKeeper 部署》](/ai/hadoop-zkp/)。\n\n本系列文章[《目录》](/ai/hadoop-start/)","slug":"hadoop-planning","published":1,"updated":"2018-04-02T09:56:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup8200063knal8ockigx","content":"<p>完成上一篇文章<a href=\"/ai/hadoop-servers/\">《服务器批量安装》</a>的内容后，我们已经拥有了4台Linux服务器，且相互之间网络可以互通，并且正常运行<a href=\"https://baike.baidu.com/item/ssh/10407?fr=aladdin\" target=\"_blank\" rel=\"noopener\">SHH服务</a>。硬件环境已经准备完成，这篇文章我们将开始讲述<font color=\"#c00\">Hadoop前期规划</font>的准备工作。<a href=\"https://baike.baidu.com/item/Hadoop/3526507?fr=aladdin\" target=\"_blank\" rel=\"noopener\">Hadoop</a>是一系列工具的集合，如何合理的规划这些工具以及分配服务器资源，<font color=\"#c00\">是一个非常重要的工作</font>。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"主机名配置\"><a href=\"#主机名配置\" class=\"headerlink\" title=\"主机名配置\"></a><font color=\"#c00\">主机名配置</font></h2><p>我将分别修改主机名为node0，node1，node2，node3。方便教程的讲述，也方便ssh中的操作。选择其中一台服务器，<font color=\"#c00\">root用户</font>登陆。</p>\n<a id=\"more\"></a>\n<h3 id=\"查看主机名\"><a href=\"#查看主机名\" class=\"headerlink\" title=\"查看主机名\"></a>查看主机名</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostname</span><br></pre></td></tr></table></figure>\n<h3 id=\"修改主机名\"><a href=\"#修改主机名\" class=\"headerlink\" title=\"修改主机名\"></a>修改主机名</h3><ul>\n<li>方法一：修改network文件，将HOSTNAME后面的值改为node0，重启后生效。</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/sysconfig/network</span><br></pre></td></tr></table></figure>\n<ul>\n<li>方法二：修改当前的主机名，立即生效。</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostname node0</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置hosts文件\"><a href=\"#配置hosts文件\" class=\"headerlink\" title=\"配置hosts文件\"></a>配置hosts文件</h3><p>修改/etc/hosts文件，<font color=\"#c00\">ip0为你自己机器的ip地址</font></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ip0 node0</span><br><span class=\"line\">ip1 node1</span><br><span class=\"line\">ip2 node2</span><br><span class=\"line\">ip3 node3</span><br></pre></td></tr></table></figure>\n<h3 id=\"分发hosts文件\"><a href=\"#分发hosts文件\" class=\"headerlink\" title=\"分发hosts文件\"></a>分发hosts文件</h3><p>将hosts文件分发到其他3台机器中，以保证所有服务器识别主机名。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp /etc/hosts root@node1:/etc/</span><br><span class=\"line\">scp /etc/hosts root@node2:/etc/</span><br><span class=\"line\">scp /etc/hosts root@node3:/etc/</span><br></pre></td></tr></table></figure>\n<h2 id=\"批量管理工具推荐\"><a href=\"#批量管理工具推荐\" class=\"headerlink\" title=\"批量管理工具推荐\"></a><font color=\"#c00\">批量管理工具推荐</font></h2><p>如果你想更快，更省力的完成批量操作，有兴趣的童鞋可以安装<a href=\"http://www.theether.org/pssh/\" target=\"_blank\" rel=\"noopener\">Linux集群批量管理工具parallel-ssh(PSSH)</a>，该工具需要<font color=\"#c00\">Python环境</font>，<a href=\"http://man.linuxde.net/pssh\" target=\"_blank\" rel=\"noopener\">安装及操作点击此处链接</a>，该教程中还是采用普通命令进行讲述。</p>\n<h2 id=\"配置免密码登录\"><a href=\"#配置免密码登录\" class=\"headerlink\" title=\"配置免密码登录\"></a><font color=\"#c00\">配置免密码登录</font></h2><p>之后的服务器命令都需要免密码才能正常操作，这是一个必须而重要的步骤。我以node0批量操作其他服务器为例。此步骤需要在所有服务器中完成一边，以方便任意两台机器可以互相登陆。</p>\n<h3 id=\"创建本机的公钥与私钥\"><a href=\"#创建本机的公钥与私钥\" class=\"headerlink\" title=\"创建本机的公钥与私钥\"></a>创建本机的公钥与私钥</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class=\"line\">chmod 0600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>\n<h3 id=\"分发公钥到其他3台服务器\"><a href=\"#分发公钥到其他3台服务器\" class=\"headerlink\" title=\"分发公钥到其他3台服务器\"></a>分发公钥到其他3台服务器</h3><p>我以node1为例</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp ~/.ssh/id_rsa.pub root@node1:~/</span><br></pre></td></tr></table></figure>\n<h3 id=\"公钥追加\"><a href=\"#公钥追加\" class=\"headerlink\" title=\"公钥追加\"></a>公钥追加</h3><p>进入node1的root账户的home目录下，运行如下命令。完成后，就可以从node0免密码登录到node1了。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Java环境\"><a href=\"#安装Java环境\" class=\"headerlink\" title=\"安装Java环境\"></a><font color=\"#c00\">安装Java环境</font></h2><p>hadoop整套工具都以Java环境为基础，所以4台机器都需要安装。我们以node0为例。</p>\n<h3 id=\"查看是否安装\"><a href=\"#查看是否安装\" class=\"headerlink\" title=\"查看是否安装\"></a>查看是否安装</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">syum list installed | grep java</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看yum库中的Java安装包\"><a href=\"#查看yum库中的Java安装包\" class=\"headerlink\" title=\"查看yum库中的Java安装包\"></a>查看yum库中的Java安装包</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y list java*</span><br></pre></td></tr></table></figure>\n<h3 id=\"安装Java\"><a href=\"#安装Java\" class=\"headerlink\" title=\"安装Java\"></a>安装Java</h3><p>我们以版本1.8.0为例</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install java-1.8.0-openjdk*</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置环境变量\"><a href=\"#配置环境变量\" class=\"headerlink\" title=\"配置环境变量\"></a>配置环境变量</h3><ol>\n<li>将jdk文件夹移动到opt文件夹下</li>\n<li>在/etc/profile文件中追加如下内容：</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/opt/jdk1.8.0_65</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"JSP进程集\"><a href=\"#JSP进程集\" class=\"headerlink\" title=\"JSP进程集\"></a><font color=\"#c00\">JSP进程集</font></h2><h3 id=\"工具集介绍\"><a href=\"#工具集介绍\" class=\"headerlink\" title=\"工具集介绍\"></a>工具集介绍</h3><p>在此篇基础工具集的规划中，我们主要安装Hadoop, ZooKeeper, HBase, Spark, Jupiter, Thrift。之后的教程中还会讲到Hive，MySQL等。每种工具都对应着一些Java进程，我们将规划这些进程分别部署到哪个服务器上。（话说，分布式应用，总不能把所有的进程都安装在一台服务器中吧。。。 - -!）</p>\n<font color=\"#c00\">注：如果你对上述工具还不熟悉，请跳转到<a href=\"/ai/hadoop-tutorial/\">《Hadoop 基础教程》</a></font>\n\n<h3 id=\"JSP进程\"><a href=\"#JSP进程\" class=\"headerlink\" title=\"JSP进程\"></a>JSP进程</h3><p><a href=\"https://www.cnblogs.com/wzyxidian/p/5314148.html\" target=\"_blank\" rel=\"noopener\">JSP</a>是Java Virtual Machine Process Status Tool的缩写，在<a href=\"https://baike.baidu.com/item/JVM/2902369?fr=aladdin\" target=\"_blank\" rel=\"noopener\">JVM</a>中所有具有访问权限的Java进程的具体状态, 包括进程ID，进程启动的路径及启动参数等等，与Linux上的ps命令类似，只不过jps是用来显示java进程，可以把jps理解为ps的一个子集。</p>\n<table>\n<thead>\n<tr>\n<th>工具</th>\n<th>JPS进程</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ZooKeeper</td>\n<td>QuorumPeerMain</td>\n</tr>\n<tr>\n<td>HDFS</td>\n<td>NameNode, DataNode, JournalNode, ZKFailoverController</td>\n</tr>\n<tr>\n<td>MapReduce, Spark</td>\n<td>ResourceManager, NodeManager</td>\n</tr>\n<tr>\n<td>HBase</td>\n<td>HMaster,  HRegionServer</td>\n</tr>\n<tr>\n<td>Thrift</td>\n<td>ThriftServer</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"系统进程\"><a href=\"#系统进程\" class=\"headerlink\" title=\"系统进程\"></a>系统进程</h3><table>\n<thead>\n<tr>\n<th>工具</th>\n<th>系统进程</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jupyter</td>\n<td>jupyter-notebook</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"进程规划\"><a href=\"#进程规划\" class=\"headerlink\" title=\"进程规划\"></a><font color=\"#c00\">进程规划</font></h2><h3 id=\"规划图\"><a href=\"#规划图\" class=\"headerlink\" title=\"规划图\"></a>规划图</h3><p>根据上一篇的教程，我们准备了4台服务器，我们将把上面介绍的进程部署在这4台服务器中，方案如下：<br><img src=\"/images/post/ai/hdp12.jpg\" alt=\"planning\"></p>\n<p>图中勾选的位置对应着进程将部署在哪台服务器。</p>\n<h3 id=\"缩写对照表\"><a href=\"#缩写对照表\" class=\"headerlink\" title=\"缩写对照表\"></a>缩写对照表</h3><table>\n<thead>\n<tr>\n<th>缩写</th>\n<th>进程全称</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NN</td>\n<td>NameNode</td>\n</tr>\n<tr>\n<td>DN</td>\n<td>DataNode</td>\n</tr>\n<tr>\n<td>ZK</td>\n<td>QuorumPeerMain</td>\n</tr>\n<tr>\n<td>ZKFC</td>\n<td>ZKFailoverController</td>\n</tr>\n<tr>\n<td>JN</td>\n<td>JournalNode</td>\n</tr>\n<tr>\n<td>RM</td>\n<td>ResourceManager</td>\n</tr>\n<tr>\n<td>NM</td>\n<td>NodeManager</td>\n</tr>\n<tr>\n<td>HM</td>\n<td>HMaster</td>\n</tr>\n<tr>\n<td>HR</td>\n<td>HRegionServer</td>\n</tr>\n<tr>\n<td>TS</td>\n<td>ThriftServer</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>此篇主要介绍平台安装前的准备工作，以及要部署的工具集与JSP进程的规划方案，当然这个规划方案是以4台服务器为基础，如果你的服务器数量超过4台（无论怎样要大于等于3台，原因可以在<a href=\"/ai/hadoop-tutorial/\">《Hadoop 基础教程》</a>中了解，此处不在赘述！）规划方案可以相应调整，下篇<a href=\"/ai/hadoop-zkp/\">《ZooKeeper 部署》</a>。</p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>\n","site":{"data":{}},"excerpt":"<p>完成上一篇文章<a href=\"/ai/hadoop-servers/\">《服务器批量安装》</a>的内容后，我们已经拥有了4台Linux服务器，且相互之间网络可以互通，并且正常运行<a href=\"https://baike.baidu.com/item/ssh/10407?fr=aladdin\" target=\"_blank\" rel=\"noopener\">SHH服务</a>。硬件环境已经准备完成，这篇文章我们将开始讲述<font color=\"#c00\">Hadoop前期规划</font>的准备工作。<a href=\"https://baike.baidu.com/item/Hadoop/3526507?fr=aladdin\" target=\"_blank\" rel=\"noopener\">Hadoop</a>是一系列工具的集合，如何合理的规划这些工具以及分配服务器资源，<font color=\"#c00\">是一个非常重要的工作</font>。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"主机名配置\"><a href=\"#主机名配置\" class=\"headerlink\" title=\"主机名配置\"></a><font color=\"#c00\">主机名配置</font></h2><p>我将分别修改主机名为node0，node1，node2，node3。方便教程的讲述，也方便ssh中的操作。选择其中一台服务器，<font color=\"#c00\">root用户</font>登陆。</p>","more":"<h3 id=\"查看主机名\"><a href=\"#查看主机名\" class=\"headerlink\" title=\"查看主机名\"></a>查看主机名</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostname</span><br></pre></td></tr></table></figure>\n<h3 id=\"修改主机名\"><a href=\"#修改主机名\" class=\"headerlink\" title=\"修改主机名\"></a>修改主机名</h3><ul>\n<li>方法一：修改network文件，将HOSTNAME后面的值改为node0，重启后生效。</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/sysconfig/network</span><br></pre></td></tr></table></figure>\n<ul>\n<li>方法二：修改当前的主机名，立即生效。</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostname node0</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置hosts文件\"><a href=\"#配置hosts文件\" class=\"headerlink\" title=\"配置hosts文件\"></a>配置hosts文件</h3><p>修改/etc/hosts文件，<font color=\"#c00\">ip0为你自己机器的ip地址</font></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ip0 node0</span><br><span class=\"line\">ip1 node1</span><br><span class=\"line\">ip2 node2</span><br><span class=\"line\">ip3 node3</span><br></pre></td></tr></table></figure>\n<h3 id=\"分发hosts文件\"><a href=\"#分发hosts文件\" class=\"headerlink\" title=\"分发hosts文件\"></a>分发hosts文件</h3><p>将hosts文件分发到其他3台机器中，以保证所有服务器识别主机名。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp /etc/hosts root@node1:/etc/</span><br><span class=\"line\">scp /etc/hosts root@node2:/etc/</span><br><span class=\"line\">scp /etc/hosts root@node3:/etc/</span><br></pre></td></tr></table></figure>\n<h2 id=\"批量管理工具推荐\"><a href=\"#批量管理工具推荐\" class=\"headerlink\" title=\"批量管理工具推荐\"></a><font color=\"#c00\">批量管理工具推荐</font></h2><p>如果你想更快，更省力的完成批量操作，有兴趣的童鞋可以安装<a href=\"http://www.theether.org/pssh/\" target=\"_blank\" rel=\"noopener\">Linux集群批量管理工具parallel-ssh(PSSH)</a>，该工具需要<font color=\"#c00\">Python环境</font>，<a href=\"http://man.linuxde.net/pssh\" target=\"_blank\" rel=\"noopener\">安装及操作点击此处链接</a>，该教程中还是采用普通命令进行讲述。</p>\n<h2 id=\"配置免密码登录\"><a href=\"#配置免密码登录\" class=\"headerlink\" title=\"配置免密码登录\"></a><font color=\"#c00\">配置免密码登录</font></h2><p>之后的服务器命令都需要免密码才能正常操作，这是一个必须而重要的步骤。我以node0批量操作其他服务器为例。此步骤需要在所有服务器中完成一边，以方便任意两台机器可以互相登陆。</p>\n<h3 id=\"创建本机的公钥与私钥\"><a href=\"#创建本机的公钥与私钥\" class=\"headerlink\" title=\"创建本机的公钥与私钥\"></a>创建本机的公钥与私钥</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class=\"line\">chmod 0600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>\n<h3 id=\"分发公钥到其他3台服务器\"><a href=\"#分发公钥到其他3台服务器\" class=\"headerlink\" title=\"分发公钥到其他3台服务器\"></a>分发公钥到其他3台服务器</h3><p>我以node1为例</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp ~/.ssh/id_rsa.pub root@node1:~/</span><br></pre></td></tr></table></figure>\n<h3 id=\"公钥追加\"><a href=\"#公钥追加\" class=\"headerlink\" title=\"公钥追加\"></a>公钥追加</h3><p>进入node1的root账户的home目录下，运行如下命令。完成后，就可以从node0免密码登录到node1了。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Java环境\"><a href=\"#安装Java环境\" class=\"headerlink\" title=\"安装Java环境\"></a><font color=\"#c00\">安装Java环境</font></h2><p>hadoop整套工具都以Java环境为基础，所以4台机器都需要安装。我们以node0为例。</p>\n<h3 id=\"查看是否安装\"><a href=\"#查看是否安装\" class=\"headerlink\" title=\"查看是否安装\"></a>查看是否安装</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">syum list installed | grep java</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看yum库中的Java安装包\"><a href=\"#查看yum库中的Java安装包\" class=\"headerlink\" title=\"查看yum库中的Java安装包\"></a>查看yum库中的Java安装包</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y list java*</span><br></pre></td></tr></table></figure>\n<h3 id=\"安装Java\"><a href=\"#安装Java\" class=\"headerlink\" title=\"安装Java\"></a>安装Java</h3><p>我们以版本1.8.0为例</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install java-1.8.0-openjdk*</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置环境变量\"><a href=\"#配置环境变量\" class=\"headerlink\" title=\"配置环境变量\"></a>配置环境变量</h3><ol>\n<li>将jdk文件夹移动到opt文件夹下</li>\n<li>在/etc/profile文件中追加如下内容：</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/opt/jdk1.8.0_65</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$JAVA_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"JSP进程集\"><a href=\"#JSP进程集\" class=\"headerlink\" title=\"JSP进程集\"></a><font color=\"#c00\">JSP进程集</font></h2><h3 id=\"工具集介绍\"><a href=\"#工具集介绍\" class=\"headerlink\" title=\"工具集介绍\"></a>工具集介绍</h3><p>在此篇基础工具集的规划中，我们主要安装Hadoop, ZooKeeper, HBase, Spark, Jupiter, Thrift。之后的教程中还会讲到Hive，MySQL等。每种工具都对应着一些Java进程，我们将规划这些进程分别部署到哪个服务器上。（话说，分布式应用，总不能把所有的进程都安装在一台服务器中吧。。。 - -!）</p>\n<font color=\"#c00\">注：如果你对上述工具还不熟悉，请跳转到<a href=\"/ai/hadoop-tutorial/\">《Hadoop 基础教程》</a></font>\n\n<h3 id=\"JSP进程\"><a href=\"#JSP进程\" class=\"headerlink\" title=\"JSP进程\"></a>JSP进程</h3><p><a href=\"https://www.cnblogs.com/wzyxidian/p/5314148.html\" target=\"_blank\" rel=\"noopener\">JSP</a>是Java Virtual Machine Process Status Tool的缩写，在<a href=\"https://baike.baidu.com/item/JVM/2902369?fr=aladdin\" target=\"_blank\" rel=\"noopener\">JVM</a>中所有具有访问权限的Java进程的具体状态, 包括进程ID，进程启动的路径及启动参数等等，与Linux上的ps命令类似，只不过jps是用来显示java进程，可以把jps理解为ps的一个子集。</p>\n<table>\n<thead>\n<tr>\n<th>工具</th>\n<th>JPS进程</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ZooKeeper</td>\n<td>QuorumPeerMain</td>\n</tr>\n<tr>\n<td>HDFS</td>\n<td>NameNode, DataNode, JournalNode, ZKFailoverController</td>\n</tr>\n<tr>\n<td>MapReduce, Spark</td>\n<td>ResourceManager, NodeManager</td>\n</tr>\n<tr>\n<td>HBase</td>\n<td>HMaster,  HRegionServer</td>\n</tr>\n<tr>\n<td>Thrift</td>\n<td>ThriftServer</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"系统进程\"><a href=\"#系统进程\" class=\"headerlink\" title=\"系统进程\"></a>系统进程</h3><table>\n<thead>\n<tr>\n<th>工具</th>\n<th>系统进程</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Jupyter</td>\n<td>jupyter-notebook</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"进程规划\"><a href=\"#进程规划\" class=\"headerlink\" title=\"进程规划\"></a><font color=\"#c00\">进程规划</font></h2><h3 id=\"规划图\"><a href=\"#规划图\" class=\"headerlink\" title=\"规划图\"></a>规划图</h3><p>根据上一篇的教程，我们准备了4台服务器，我们将把上面介绍的进程部署在这4台服务器中，方案如下：<br><img src=\"/images/post/ai/hdp12.jpg\" alt=\"planning\"></p>\n<p>图中勾选的位置对应着进程将部署在哪台服务器。</p>\n<h3 id=\"缩写对照表\"><a href=\"#缩写对照表\" class=\"headerlink\" title=\"缩写对照表\"></a>缩写对照表</h3><table>\n<thead>\n<tr>\n<th>缩写</th>\n<th>进程全称</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NN</td>\n<td>NameNode</td>\n</tr>\n<tr>\n<td>DN</td>\n<td>DataNode</td>\n</tr>\n<tr>\n<td>ZK</td>\n<td>QuorumPeerMain</td>\n</tr>\n<tr>\n<td>ZKFC</td>\n<td>ZKFailoverController</td>\n</tr>\n<tr>\n<td>JN</td>\n<td>JournalNode</td>\n</tr>\n<tr>\n<td>RM</td>\n<td>ResourceManager</td>\n</tr>\n<tr>\n<td>NM</td>\n<td>NodeManager</td>\n</tr>\n<tr>\n<td>HM</td>\n<td>HMaster</td>\n</tr>\n<tr>\n<td>HR</td>\n<td>HRegionServer</td>\n</tr>\n<tr>\n<td>TS</td>\n<td>ThriftServer</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>此篇主要介绍平台安装前的准备工作，以及要部署的工具集与JSP进程的规划方案，当然这个规划方案是以4台服务器为基础，如果你的服务器数量超过4台（无论怎样要大于等于3台，原因可以在<a href=\"/ai/hadoop-tutorial/\">《Hadoop 基础教程》</a>中了解，此处不在赘述！）规划方案可以相应调整，下篇<a href=\"/ai/hadoop-zkp/\">《ZooKeeper 部署》</a>。</p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>"},{"title":"服务器批量安装","date":"2018-03-16T05:11:05.000Z","_content":"在安装Hadoop分布式系统之前，我们需要准备好服务器资源，如果采用云服务器，可以跳过此篇文章。批量无人值守安装操作系统，此次示例系统为<font color=#c00>CentOS7.x</font>且推荐安装<font color=#c00>X window用户界面</font>，后面会用到，服务器数量为<font color=#c00>4</font>台，当然你可以使用大于等于3台以上数量的机器。\n\n在4台机器中，随意选择1台安装服务。<font color=#c00>注：推荐直接使用实体机进行安装，或者非VMware的虚拟机，否则无人值守批量安装系统时可能会出错。</font>\n\n<!--more-->\n# Quick Start\n## <font color=#c00>安装FTP服务</font>\n\n### 安装[vsftp服务](https://baike.baidu.com/item/vsftpd/5254770?fr=aladdin)：\n\n``` bash\nyum -y install vsftpd \n```\n\n### 启动vsftp服务：\n\n``` bash\nsystemctl start vsftpd.service\n```\n\n### 将准备好的系统iso文件加载到光驱\n\n如果使用虚拟机，则加载iso文件，如果是实体机可使用光盘或U盘加载系统文件。\n\n### 将光驱文件挂在到ftp目录下：\n\n``` bash\nmount /dev/cdrom /var/ftp/pub\n```\n\n### 测试FTP服务是否可以匿名登录，命令如下：\n\n1. 如果系统提示[lftp服务](http://man.linuxde.net/lftp)未安装，安装lftp\n\n\t``` bash\n\tyum -y install lftp\n\t```\n\n2. 进入lftp模式后会看到pub文件夹，如果没有，请关闭防火墙和selinux\n\n   关闭防火墙：<font color=#999>systemctl stop firewalld.service</font>\n   查看selinux：<font color=#999>getenforce</font>\n   暂时关闭selinux：<font color=#999>setenforce 0</font>\n   永久关闭selinux：<font color=#999>修改/etc/selinux/config文件SELINUX=enforcing改为SELINUX=disabled，重启即可</font>\n\n3. 进入pub文件夹，如果有文件，测试正常\n\n\n## <font color=#c00>安装[PXE](https://baike.baidu.com/item/PXE/6107945?fr=aladdin)并生成pxelinux.0启动文件</font>\n\n### 安装syslinux服务：\n\n``` bash \nyum install -y syslinux\n```\n\n### 查询文件所在目录：\n\n``` bash\nrpm -ql syslinux | grep \"pxelinux.0\"\n```\n\n## <font color=#c00>安装TFTP服务</font>\n\n### 安装[tftp服务](https://baike.baidu.com/item/tftp/455170?fr=aladdin)：\n\n``` bash\nyum -y install tftp-server\n```\n\n### 修改配置文件：\n\n打开/etc/xinetd.d/tftp文件，修改disable=no\n\n### 启动tftp服务：\n\n``` bash\nsystemctl start xinetd.service\n```\n\n### 查看server_args的值找到tftpboot文件夹路径（通常为/var/lib/tftpboot）\n\n``` bash\nsystemctl start xinetd.service\n```\n\n### 拷贝文件\n\n在tftpboot文件夹下，新建文件夹pxelinux.cfg，并执行如下命令：\n``` bash\ncp /usr/share/syslinux/pxelinux.0 .\ncp /var/ftp/pub/isolinux/isolinux.cfg ./pxelinux.cfg/default\ncp /var/ftp/pbu/isolinux/vmlinuz .\ncp /var/ftp/pbu/isolinux/initrd.img .\n```\n\n### 设置权限\n设置./pxelinux.cfg/default的权限为644：\n\n``` bash\nchmod 644 default\n```\n\n## <font color=#c00>安装DHCP服务</font>\n\n### 安装[dhcp服务](https://baike.baidu.com/item/DHCP/218195?fr=aladdin) \n\n``` bash\nyum -y install dhcp\n```\n\n### 配置/etc/dhcp/dhcpd.conf：\n\n``` bash\nddns-update-style interim;\nallow booting;\nallow booting;\nnext-server 192.168.0.1;\nfilename \"pxelinux.0\";\ndefault-lease-time 1800;\nmax-lease-time 7200;\nping-check true;\noption domain-name-servers 192.168.0.1;\nsubnet 192.168.0.0 netmask 255.255.255.0\n{\n  range 192.168.0.100 192.168.0.220;\n  option routers 192.168.0.1;\n  option broadcast-address 192.168.0.255;\n}\n```\n\n### 启动HDCP： \n\n``` bash\nsystemctl start dhcpd.service\n```\n\n## <font color=#c00>安装Kickstart工具</font>\n\n### 安装:\n\n``` bash\nyum -y install system-config-kickstart\n```\n\n### 运行Kickstart并配置选项\n\n启动Kickstart Configurator界面<font color=#c00>（该软件需要系统安装X window）</font>\n``` bash\nsystem-config-kickstart\n```\n\n### 配置选项页Basic Configuration：\n\n1. Time Zone设置为Asia/Shanghai\n2. 勾选 Use UTC clock\n3. 设置Root Password与Confirm Password\n4. 勾选Reboot system after installation\n![Basic Configuration](/images/post/ai/hdp1.png)\n\n### 配置选项页Installation Method：\n\n1. 在Installation source选框中 点选 FTP\n2. 填写FTP Server： <font color=#999>192.168.0.1</font>\n3. 填写FTP Directory： <font color=#999>pub</font>\n![Basic Configuration](/images/post/ai/hdp2.png)\n\n### 配置选项页Boot Loader Options：\n\n1. 点选 Install new boot loader\n![Basic Configuration](/images/post/ai/hdp3.png)\n\n### 配置选项页Partition Information\n\n1. 勾选 Clear Master Boot Record\n2. 勾选 Remove all existing partitions\n3. 勾选 Initialize the disk label\n4. 点击Add 自定义分区\n![part](/images/post/ai/hdp4.png)\n\n### 创建分区\n\n1. 新增 /boot分区 文件系统类型xfs或者ext4 Fixed size: 200MB  \n![boot](/images/post/ai/hdp5.png)\n2. 新增 /swap分区(在File System Type中选择) Fixed size: 2048MB\n![swap](/images/post/ai/hdp6.png)\n3. 新增 / 分区 点选Fill all unused space on disk\n  ![other](/images/post/ai/hdp7.png)\n4. 创建完成后点击OK\n\n### 配置选项页Network COnfiguration：\n\n点击Add Network Device, 下拉菜单中选择DHCP, 如果Network Device为空，请填写自己的网卡设备\n![dhcp](/images/post/ai/hdp8.png)\n\n### 配置选项页Fireswall Configuration：\n\n1. SELinux下拉选项：<font color=#999>Disabled</font>\n2. Security level下拉选项：<font color=#999>Disable firewall</font>\n![selinux](/images/post/ai/hdp9.png)\n\n### 保存选项到文件\n\n完成配置并保存到/var/ftp/ks/ks.cfg\n![save](/images/post/ai/hdp10.png)\n\n### 修改启动引导文件\n\n文件路径为/var/lib/tftpboot/pxelinux.cfg/default\n\n``` bash\ntimeout 60 //暂定时间\nlabel ks //选项\nkernel vmlinuz\nappend ks=ftp://192.168.0.1/ks/ks.cfg initrd=initrd.img\n```\n类似如下图：\n![cfg](/images/post/ai/hdp11.png)\n\n## <font color=#c00>小结</font>\n\n到此，无人值守服务已全部配置完成，分别开启其他3台机器后，可自动进入系统安装。下篇[《分布式平台前期规划》](/ai/hadoop-planning/)。\n\n本系列文章[《目录》](/ai/hadoop-start/)\n\n\n\n","source":"_posts/hadoop-servers.md","raw":"---\ntitle: 服务器批量安装\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-03-16 13:11:05\n---\n在安装Hadoop分布式系统之前，我们需要准备好服务器资源，如果采用云服务器，可以跳过此篇文章。批量无人值守安装操作系统，此次示例系统为<font color=#c00>CentOS7.x</font>且推荐安装<font color=#c00>X window用户界面</font>，后面会用到，服务器数量为<font color=#c00>4</font>台，当然你可以使用大于等于3台以上数量的机器。\n\n在4台机器中，随意选择1台安装服务。<font color=#c00>注：推荐直接使用实体机进行安装，或者非VMware的虚拟机，否则无人值守批量安装系统时可能会出错。</font>\n\n<!--more-->\n# Quick Start\n## <font color=#c00>安装FTP服务</font>\n\n### 安装[vsftp服务](https://baike.baidu.com/item/vsftpd/5254770?fr=aladdin)：\n\n``` bash\nyum -y install vsftpd \n```\n\n### 启动vsftp服务：\n\n``` bash\nsystemctl start vsftpd.service\n```\n\n### 将准备好的系统iso文件加载到光驱\n\n如果使用虚拟机，则加载iso文件，如果是实体机可使用光盘或U盘加载系统文件。\n\n### 将光驱文件挂在到ftp目录下：\n\n``` bash\nmount /dev/cdrom /var/ftp/pub\n```\n\n### 测试FTP服务是否可以匿名登录，命令如下：\n\n1. 如果系统提示[lftp服务](http://man.linuxde.net/lftp)未安装，安装lftp\n\n\t``` bash\n\tyum -y install lftp\n\t```\n\n2. 进入lftp模式后会看到pub文件夹，如果没有，请关闭防火墙和selinux\n\n   关闭防火墙：<font color=#999>systemctl stop firewalld.service</font>\n   查看selinux：<font color=#999>getenforce</font>\n   暂时关闭selinux：<font color=#999>setenforce 0</font>\n   永久关闭selinux：<font color=#999>修改/etc/selinux/config文件SELINUX=enforcing改为SELINUX=disabled，重启即可</font>\n\n3. 进入pub文件夹，如果有文件，测试正常\n\n\n## <font color=#c00>安装[PXE](https://baike.baidu.com/item/PXE/6107945?fr=aladdin)并生成pxelinux.0启动文件</font>\n\n### 安装syslinux服务：\n\n``` bash \nyum install -y syslinux\n```\n\n### 查询文件所在目录：\n\n``` bash\nrpm -ql syslinux | grep \"pxelinux.0\"\n```\n\n## <font color=#c00>安装TFTP服务</font>\n\n### 安装[tftp服务](https://baike.baidu.com/item/tftp/455170?fr=aladdin)：\n\n``` bash\nyum -y install tftp-server\n```\n\n### 修改配置文件：\n\n打开/etc/xinetd.d/tftp文件，修改disable=no\n\n### 启动tftp服务：\n\n``` bash\nsystemctl start xinetd.service\n```\n\n### 查看server_args的值找到tftpboot文件夹路径（通常为/var/lib/tftpboot）\n\n``` bash\nsystemctl start xinetd.service\n```\n\n### 拷贝文件\n\n在tftpboot文件夹下，新建文件夹pxelinux.cfg，并执行如下命令：\n``` bash\ncp /usr/share/syslinux/pxelinux.0 .\ncp /var/ftp/pub/isolinux/isolinux.cfg ./pxelinux.cfg/default\ncp /var/ftp/pbu/isolinux/vmlinuz .\ncp /var/ftp/pbu/isolinux/initrd.img .\n```\n\n### 设置权限\n设置./pxelinux.cfg/default的权限为644：\n\n``` bash\nchmod 644 default\n```\n\n## <font color=#c00>安装DHCP服务</font>\n\n### 安装[dhcp服务](https://baike.baidu.com/item/DHCP/218195?fr=aladdin) \n\n``` bash\nyum -y install dhcp\n```\n\n### 配置/etc/dhcp/dhcpd.conf：\n\n``` bash\nddns-update-style interim;\nallow booting;\nallow booting;\nnext-server 192.168.0.1;\nfilename \"pxelinux.0\";\ndefault-lease-time 1800;\nmax-lease-time 7200;\nping-check true;\noption domain-name-servers 192.168.0.1;\nsubnet 192.168.0.0 netmask 255.255.255.0\n{\n  range 192.168.0.100 192.168.0.220;\n  option routers 192.168.0.1;\n  option broadcast-address 192.168.0.255;\n}\n```\n\n### 启动HDCP： \n\n``` bash\nsystemctl start dhcpd.service\n```\n\n## <font color=#c00>安装Kickstart工具</font>\n\n### 安装:\n\n``` bash\nyum -y install system-config-kickstart\n```\n\n### 运行Kickstart并配置选项\n\n启动Kickstart Configurator界面<font color=#c00>（该软件需要系统安装X window）</font>\n``` bash\nsystem-config-kickstart\n```\n\n### 配置选项页Basic Configuration：\n\n1. Time Zone设置为Asia/Shanghai\n2. 勾选 Use UTC clock\n3. 设置Root Password与Confirm Password\n4. 勾选Reboot system after installation\n![Basic Configuration](/images/post/ai/hdp1.png)\n\n### 配置选项页Installation Method：\n\n1. 在Installation source选框中 点选 FTP\n2. 填写FTP Server： <font color=#999>192.168.0.1</font>\n3. 填写FTP Directory： <font color=#999>pub</font>\n![Basic Configuration](/images/post/ai/hdp2.png)\n\n### 配置选项页Boot Loader Options：\n\n1. 点选 Install new boot loader\n![Basic Configuration](/images/post/ai/hdp3.png)\n\n### 配置选项页Partition Information\n\n1. 勾选 Clear Master Boot Record\n2. 勾选 Remove all existing partitions\n3. 勾选 Initialize the disk label\n4. 点击Add 自定义分区\n![part](/images/post/ai/hdp4.png)\n\n### 创建分区\n\n1. 新增 /boot分区 文件系统类型xfs或者ext4 Fixed size: 200MB  \n![boot](/images/post/ai/hdp5.png)\n2. 新增 /swap分区(在File System Type中选择) Fixed size: 2048MB\n![swap](/images/post/ai/hdp6.png)\n3. 新增 / 分区 点选Fill all unused space on disk\n  ![other](/images/post/ai/hdp7.png)\n4. 创建完成后点击OK\n\n### 配置选项页Network COnfiguration：\n\n点击Add Network Device, 下拉菜单中选择DHCP, 如果Network Device为空，请填写自己的网卡设备\n![dhcp](/images/post/ai/hdp8.png)\n\n### 配置选项页Fireswall Configuration：\n\n1. SELinux下拉选项：<font color=#999>Disabled</font>\n2. Security level下拉选项：<font color=#999>Disable firewall</font>\n![selinux](/images/post/ai/hdp9.png)\n\n### 保存选项到文件\n\n完成配置并保存到/var/ftp/ks/ks.cfg\n![save](/images/post/ai/hdp10.png)\n\n### 修改启动引导文件\n\n文件路径为/var/lib/tftpboot/pxelinux.cfg/default\n\n``` bash\ntimeout 60 //暂定时间\nlabel ks //选项\nkernel vmlinuz\nappend ks=ftp://192.168.0.1/ks/ks.cfg initrd=initrd.img\n```\n类似如下图：\n![cfg](/images/post/ai/hdp11.png)\n\n## <font color=#c00>小结</font>\n\n到此，无人值守服务已全部配置完成，分别开启其他3台机器后，可自动进入系统安装。下篇[《分布式平台前期规划》](/ai/hadoop-planning/)。\n\n本系列文章[《目录》](/ai/hadoop-start/)\n\n\n\n","slug":"hadoop-servers","published":1,"updated":"2018-03-28T09:23:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup85000a3knac5gus4cx","content":"<p>在安装Hadoop分布式系统之前，我们需要准备好服务器资源，如果采用云服务器，可以跳过此篇文章。批量无人值守安装操作系统，此次示例系统为<font color=\"#c00\">CentOS7.x</font>且推荐安装<font color=\"#c00\">X window用户界面</font>，后面会用到，服务器数量为<font color=\"#c00\">4</font>台，当然你可以使用大于等于3台以上数量的机器。</p>\n<p>在4台机器中，随意选择1台安装服务。<font color=\"#c00\">注：推荐直接使用实体机进行安装，或者非VMware的虚拟机，否则无人值守批量安装系统时可能会出错。</font></p>\n<a id=\"more\"></a>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"安装FTP服务\"><a href=\"#安装FTP服务\" class=\"headerlink\" title=\"安装FTP服务\"></a><font color=\"#c00\">安装FTP服务</font></h2><h3 id=\"安装vsftp服务：\"><a href=\"#安装vsftp服务：\" class=\"headerlink\" title=\"安装vsftp服务：\"></a>安装<a href=\"https://baike.baidu.com/item/vsftpd/5254770?fr=aladdin\" target=\"_blank\" rel=\"noopener\">vsftp服务</a>：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install vsftpd</span><br></pre></td></tr></table></figure>\n<h3 id=\"启动vsftp服务：\"><a href=\"#启动vsftp服务：\" class=\"headerlink\" title=\"启动vsftp服务：\"></a>启动vsftp服务：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start vsftpd.service</span><br></pre></td></tr></table></figure>\n<h3 id=\"将准备好的系统iso文件加载到光驱\"><a href=\"#将准备好的系统iso文件加载到光驱\" class=\"headerlink\" title=\"将准备好的系统iso文件加载到光驱\"></a>将准备好的系统iso文件加载到光驱</h3><p>如果使用虚拟机，则加载iso文件，如果是实体机可使用光盘或U盘加载系统文件。</p>\n<h3 id=\"将光驱文件挂在到ftp目录下：\"><a href=\"#将光驱文件挂在到ftp目录下：\" class=\"headerlink\" title=\"将光驱文件挂在到ftp目录下：\"></a>将光驱文件挂在到ftp目录下：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mount /dev/cdrom /var/ftp/pub</span><br></pre></td></tr></table></figure>\n<h3 id=\"测试FTP服务是否可以匿名登录，命令如下：\"><a href=\"#测试FTP服务是否可以匿名登录，命令如下：\" class=\"headerlink\" title=\"测试FTP服务是否可以匿名登录，命令如下：\"></a>测试FTP服务是否可以匿名登录，命令如下：</h3><ol>\n<li><p>如果系统提示<a href=\"http://man.linuxde.net/lftp\" target=\"_blank\" rel=\"noopener\">lftp服务</a>未安装，安装lftp</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install lftp</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>进入lftp模式后会看到pub文件夹，如果没有，请关闭防火墙和selinux</p>\n<p>关闭防火墙：<font color=\"#999\">systemctl stop firewalld.service</font><br>查看selinux：<font color=\"#999\">getenforce</font><br>暂时关闭selinux：<font color=\"#999\">setenforce 0</font><br>永久关闭selinux：<font color=\"#999\">修改/etc/selinux/config文件SELINUX=enforcing改为SELINUX=disabled，重启即可</font></p>\n</li>\n<li><p>进入pub文件夹，如果有文件，测试正常</p>\n</li>\n</ol>\n<h2 id=\"安装PXE并生成pxelinux-0启动文件\"><a href=\"#安装PXE并生成pxelinux-0启动文件\" class=\"headerlink\" title=\"安装PXE并生成pxelinux.0启动文件\"></a><font color=\"#c00\">安装<a href=\"https://baike.baidu.com/item/PXE/6107945?fr=aladdin\" target=\"_blank\" rel=\"noopener\">PXE</a>并生成pxelinux.0启动文件</font></h2><h3 id=\"安装syslinux服务：\"><a href=\"#安装syslinux服务：\" class=\"headerlink\" title=\"安装syslinux服务：\"></a>安装syslinux服务：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y syslinux</span><br></pre></td></tr></table></figure>\n<h3 id=\"查询文件所在目录：\"><a href=\"#查询文件所在目录：\" class=\"headerlink\" title=\"查询文件所在目录：\"></a>查询文件所在目录：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rpm -ql syslinux | grep <span class=\"string\">\"pxelinux.0\"</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"安装TFTP服务\"><a href=\"#安装TFTP服务\" class=\"headerlink\" title=\"安装TFTP服务\"></a><font color=\"#c00\">安装TFTP服务</font></h2><h3 id=\"安装tftp服务：\"><a href=\"#安装tftp服务：\" class=\"headerlink\" title=\"安装tftp服务：\"></a>安装<a href=\"https://baike.baidu.com/item/tftp/455170?fr=aladdin\" target=\"_blank\" rel=\"noopener\">tftp服务</a>：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install tftp-server</span><br></pre></td></tr></table></figure>\n<h3 id=\"修改配置文件：\"><a href=\"#修改配置文件：\" class=\"headerlink\" title=\"修改配置文件：\"></a>修改配置文件：</h3><p>打开/etc/xinetd.d/tftp文件，修改disable=no</p>\n<h3 id=\"启动tftp服务：\"><a href=\"#启动tftp服务：\" class=\"headerlink\" title=\"启动tftp服务：\"></a>启动tftp服务：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start xinetd.service</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看server-args的值找到tftpboot文件夹路径（通常为-var-lib-tftpboot）\"><a href=\"#查看server-args的值找到tftpboot文件夹路径（通常为-var-lib-tftpboot）\" class=\"headerlink\" title=\"查看server_args的值找到tftpboot文件夹路径（通常为/var/lib/tftpboot）\"></a>查看server_args的值找到tftpboot文件夹路径（通常为/var/lib/tftpboot）</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start xinetd.service</span><br></pre></td></tr></table></figure>\n<h3 id=\"拷贝文件\"><a href=\"#拷贝文件\" class=\"headerlink\" title=\"拷贝文件\"></a>拷贝文件</h3><p>在tftpboot文件夹下，新建文件夹pxelinux.cfg，并执行如下命令：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp /usr/share/syslinux/pxelinux.0 .</span><br><span class=\"line\">cp /var/ftp/pub/isolinux/isolinux.cfg ./pxelinux.cfg/default</span><br><span class=\"line\">cp /var/ftp/pbu/isolinux/vmlinuz .</span><br><span class=\"line\">cp /var/ftp/pbu/isolinux/initrd.img .</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"设置权限\"><a href=\"#设置权限\" class=\"headerlink\" title=\"设置权限\"></a>设置权限</h3><p>设置./pxelinux.cfg/default的权限为644：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod 644 default</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装DHCP服务\"><a href=\"#安装DHCP服务\" class=\"headerlink\" title=\"安装DHCP服务\"></a><font color=\"#c00\">安装DHCP服务</font></h2><h3 id=\"安装dhcp服务\"><a href=\"#安装dhcp服务\" class=\"headerlink\" title=\"安装dhcp服务\"></a>安装<a href=\"https://baike.baidu.com/item/DHCP/218195?fr=aladdin\" target=\"_blank\" rel=\"noopener\">dhcp服务</a></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install dhcp</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置-etc-dhcp-dhcpd-conf：\"><a href=\"#配置-etc-dhcp-dhcpd-conf：\" class=\"headerlink\" title=\"配置/etc/dhcp/dhcpd.conf：\"></a>配置/etc/dhcp/dhcpd.conf：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ddns-update-style interim;</span><br><span class=\"line\">allow booting;</span><br><span class=\"line\">allow booting;</span><br><span class=\"line\">next-server 192.168.0.1;</span><br><span class=\"line\">filename <span class=\"string\">\"pxelinux.0\"</span>;</span><br><span class=\"line\">default-lease-time 1800;</span><br><span class=\"line\">max-lease-time 7200;</span><br><span class=\"line\">ping-check <span class=\"literal\">true</span>;</span><br><span class=\"line\">option domain-name-servers 192.168.0.1;</span><br><span class=\"line\">subnet 192.168.0.0 netmask 255.255.255.0</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  range 192.168.0.100 192.168.0.220;</span><br><span class=\"line\">  option routers 192.168.0.1;</span><br><span class=\"line\">  option broadcast-address 192.168.0.255;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"启动HDCP：\"><a href=\"#启动HDCP：\" class=\"headerlink\" title=\"启动HDCP：\"></a>启动HDCP：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start dhcpd.service</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Kickstart工具\"><a href=\"#安装Kickstart工具\" class=\"headerlink\" title=\"安装Kickstart工具\"></a><font color=\"#c00\">安装Kickstart工具</font></h2><h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装:\"></a>安装:</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install system-config-kickstart</span><br></pre></td></tr></table></figure>\n<h3 id=\"运行Kickstart并配置选项\"><a href=\"#运行Kickstart并配置选项\" class=\"headerlink\" title=\"运行Kickstart并配置选项\"></a>运行Kickstart并配置选项</h3><p>启动Kickstart Configurator界面<font color=\"#c00\">（该软件需要系统安装X window）</font><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">system-config-kickstart</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"配置选项页Basic-Configuration：\"><a href=\"#配置选项页Basic-Configuration：\" class=\"headerlink\" title=\"配置选项页Basic Configuration：\"></a>配置选项页Basic Configuration：</h3><ol>\n<li>Time Zone设置为Asia/Shanghai</li>\n<li>勾选 Use UTC clock</li>\n<li>设置Root Password与Confirm Password</li>\n<li>勾选Reboot system after installation<br><img src=\"/images/post/ai/hdp1.png\" alt=\"Basic Configuration\"></li>\n</ol>\n<h3 id=\"配置选项页Installation-Method：\"><a href=\"#配置选项页Installation-Method：\" class=\"headerlink\" title=\"配置选项页Installation Method：\"></a>配置选项页Installation Method：</h3><ol>\n<li>在Installation source选框中 点选 FTP</li>\n<li>填写FTP Server： <font color=\"#999\">192.168.0.1</font></li>\n<li>填写FTP Directory： <font color=\"#999\">pub</font><br><img src=\"/images/post/ai/hdp2.png\" alt=\"Basic Configuration\"></li>\n</ol>\n<h3 id=\"配置选项页Boot-Loader-Options：\"><a href=\"#配置选项页Boot-Loader-Options：\" class=\"headerlink\" title=\"配置选项页Boot Loader Options：\"></a>配置选项页Boot Loader Options：</h3><ol>\n<li>点选 Install new boot loader<br><img src=\"/images/post/ai/hdp3.png\" alt=\"Basic Configuration\"></li>\n</ol>\n<h3 id=\"配置选项页Partition-Information\"><a href=\"#配置选项页Partition-Information\" class=\"headerlink\" title=\"配置选项页Partition Information\"></a>配置选项页Partition Information</h3><ol>\n<li>勾选 Clear Master Boot Record</li>\n<li>勾选 Remove all existing partitions</li>\n<li>勾选 Initialize the disk label</li>\n<li>点击Add 自定义分区<br><img src=\"/images/post/ai/hdp4.png\" alt=\"part\"></li>\n</ol>\n<h3 id=\"创建分区\"><a href=\"#创建分区\" class=\"headerlink\" title=\"创建分区\"></a>创建分区</h3><ol>\n<li>新增 /boot分区 文件系统类型xfs或者ext4 Fixed size: 200MB<br><img src=\"/images/post/ai/hdp5.png\" alt=\"boot\"></li>\n<li>新增 /swap分区(在File System Type中选择) Fixed size: 2048MB<br><img src=\"/images/post/ai/hdp6.png\" alt=\"swap\"></li>\n<li>新增 / 分区 点选Fill all unused space on disk<br><img src=\"/images/post/ai/hdp7.png\" alt=\"other\"></li>\n<li>创建完成后点击OK</li>\n</ol>\n<h3 id=\"配置选项页Network-COnfiguration：\"><a href=\"#配置选项页Network-COnfiguration：\" class=\"headerlink\" title=\"配置选项页Network COnfiguration：\"></a>配置选项页Network COnfiguration：</h3><p>点击Add Network Device, 下拉菜单中选择DHCP, 如果Network Device为空，请填写自己的网卡设备<br><img src=\"/images/post/ai/hdp8.png\" alt=\"dhcp\"></p>\n<h3 id=\"配置选项页Fireswall-Configuration：\"><a href=\"#配置选项页Fireswall-Configuration：\" class=\"headerlink\" title=\"配置选项页Fireswall Configuration：\"></a>配置选项页Fireswall Configuration：</h3><ol>\n<li>SELinux下拉选项：<font color=\"#999\">Disabled</font></li>\n<li>Security level下拉选项：<font color=\"#999\">Disable firewall</font><br><img src=\"/images/post/ai/hdp9.png\" alt=\"selinux\"></li>\n</ol>\n<h3 id=\"保存选项到文件\"><a href=\"#保存选项到文件\" class=\"headerlink\" title=\"保存选项到文件\"></a>保存选项到文件</h3><p>完成配置并保存到/var/ftp/ks/ks.cfg<br><img src=\"/images/post/ai/hdp10.png\" alt=\"save\"></p>\n<h3 id=\"修改启动引导文件\"><a href=\"#修改启动引导文件\" class=\"headerlink\" title=\"修改启动引导文件\"></a>修改启动引导文件</h3><p>文件路径为/var/lib/tftpboot/pxelinux.cfg/default</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timeout 60 //暂定时间</span><br><span class=\"line\">label ks //选项</span><br><span class=\"line\">kernel vmlinuz</span><br><span class=\"line\">append ks=ftp://192.168.0.1/ks/ks.cfg initrd=initrd.img</span><br></pre></td></tr></table></figure>\n<p>类似如下图：<br><img src=\"/images/post/ai/hdp11.png\" alt=\"cfg\"></p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>到此，无人值守服务已全部配置完成，分别开启其他3台机器后，可自动进入系统安装。下篇<a href=\"/ai/hadoop-planning/\">《分布式平台前期规划》</a>。</p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>\n","site":{"data":{}},"excerpt":"<p>在安装Hadoop分布式系统之前，我们需要准备好服务器资源，如果采用云服务器，可以跳过此篇文章。批量无人值守安装操作系统，此次示例系统为<font color=\"#c00\">CentOS7.x</font>且推荐安装<font color=\"#c00\">X window用户界面</font>，后面会用到，服务器数量为<font color=\"#c00\">4</font>台，当然你可以使用大于等于3台以上数量的机器。</p>\n<p>在4台机器中，随意选择1台安装服务。<font color=\"#c00\">注：推荐直接使用实体机进行安装，或者非VMware的虚拟机，否则无人值守批量安装系统时可能会出错。</font></p>","more":"<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"安装FTP服务\"><a href=\"#安装FTP服务\" class=\"headerlink\" title=\"安装FTP服务\"></a><font color=\"#c00\">安装FTP服务</font></h2><h3 id=\"安装vsftp服务：\"><a href=\"#安装vsftp服务：\" class=\"headerlink\" title=\"安装vsftp服务：\"></a>安装<a href=\"https://baike.baidu.com/item/vsftpd/5254770?fr=aladdin\" target=\"_blank\" rel=\"noopener\">vsftp服务</a>：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install vsftpd</span><br></pre></td></tr></table></figure>\n<h3 id=\"启动vsftp服务：\"><a href=\"#启动vsftp服务：\" class=\"headerlink\" title=\"启动vsftp服务：\"></a>启动vsftp服务：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start vsftpd.service</span><br></pre></td></tr></table></figure>\n<h3 id=\"将准备好的系统iso文件加载到光驱\"><a href=\"#将准备好的系统iso文件加载到光驱\" class=\"headerlink\" title=\"将准备好的系统iso文件加载到光驱\"></a>将准备好的系统iso文件加载到光驱</h3><p>如果使用虚拟机，则加载iso文件，如果是实体机可使用光盘或U盘加载系统文件。</p>\n<h3 id=\"将光驱文件挂在到ftp目录下：\"><a href=\"#将光驱文件挂在到ftp目录下：\" class=\"headerlink\" title=\"将光驱文件挂在到ftp目录下：\"></a>将光驱文件挂在到ftp目录下：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mount /dev/cdrom /var/ftp/pub</span><br></pre></td></tr></table></figure>\n<h3 id=\"测试FTP服务是否可以匿名登录，命令如下：\"><a href=\"#测试FTP服务是否可以匿名登录，命令如下：\" class=\"headerlink\" title=\"测试FTP服务是否可以匿名登录，命令如下：\"></a>测试FTP服务是否可以匿名登录，命令如下：</h3><ol>\n<li><p>如果系统提示<a href=\"http://man.linuxde.net/lftp\" target=\"_blank\" rel=\"noopener\">lftp服务</a>未安装，安装lftp</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install lftp</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>进入lftp模式后会看到pub文件夹，如果没有，请关闭防火墙和selinux</p>\n<p>关闭防火墙：<font color=\"#999\">systemctl stop firewalld.service</font><br>查看selinux：<font color=\"#999\">getenforce</font><br>暂时关闭selinux：<font color=\"#999\">setenforce 0</font><br>永久关闭selinux：<font color=\"#999\">修改/etc/selinux/config文件SELINUX=enforcing改为SELINUX=disabled，重启即可</font></p>\n</li>\n<li><p>进入pub文件夹，如果有文件，测试正常</p>\n</li>\n</ol>\n<h2 id=\"安装PXE并生成pxelinux-0启动文件\"><a href=\"#安装PXE并生成pxelinux-0启动文件\" class=\"headerlink\" title=\"安装PXE并生成pxelinux.0启动文件\"></a><font color=\"#c00\">安装<a href=\"https://baike.baidu.com/item/PXE/6107945?fr=aladdin\" target=\"_blank\" rel=\"noopener\">PXE</a>并生成pxelinux.0启动文件</font></h2><h3 id=\"安装syslinux服务：\"><a href=\"#安装syslinux服务：\" class=\"headerlink\" title=\"安装syslinux服务：\"></a>安装syslinux服务：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y syslinux</span><br></pre></td></tr></table></figure>\n<h3 id=\"查询文件所在目录：\"><a href=\"#查询文件所在目录：\" class=\"headerlink\" title=\"查询文件所在目录：\"></a>查询文件所在目录：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rpm -ql syslinux | grep <span class=\"string\">\"pxelinux.0\"</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"安装TFTP服务\"><a href=\"#安装TFTP服务\" class=\"headerlink\" title=\"安装TFTP服务\"></a><font color=\"#c00\">安装TFTP服务</font></h2><h3 id=\"安装tftp服务：\"><a href=\"#安装tftp服务：\" class=\"headerlink\" title=\"安装tftp服务：\"></a>安装<a href=\"https://baike.baidu.com/item/tftp/455170?fr=aladdin\" target=\"_blank\" rel=\"noopener\">tftp服务</a>：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install tftp-server</span><br></pre></td></tr></table></figure>\n<h3 id=\"修改配置文件：\"><a href=\"#修改配置文件：\" class=\"headerlink\" title=\"修改配置文件：\"></a>修改配置文件：</h3><p>打开/etc/xinetd.d/tftp文件，修改disable=no</p>\n<h3 id=\"启动tftp服务：\"><a href=\"#启动tftp服务：\" class=\"headerlink\" title=\"启动tftp服务：\"></a>启动tftp服务：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start xinetd.service</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看server-args的值找到tftpboot文件夹路径（通常为-var-lib-tftpboot）\"><a href=\"#查看server-args的值找到tftpboot文件夹路径（通常为-var-lib-tftpboot）\" class=\"headerlink\" title=\"查看server_args的值找到tftpboot文件夹路径（通常为/var/lib/tftpboot）\"></a>查看server_args的值找到tftpboot文件夹路径（通常为/var/lib/tftpboot）</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start xinetd.service</span><br></pre></td></tr></table></figure>\n<h3 id=\"拷贝文件\"><a href=\"#拷贝文件\" class=\"headerlink\" title=\"拷贝文件\"></a>拷贝文件</h3><p>在tftpboot文件夹下，新建文件夹pxelinux.cfg，并执行如下命令：<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp /usr/share/syslinux/pxelinux.0 .</span><br><span class=\"line\">cp /var/ftp/pub/isolinux/isolinux.cfg ./pxelinux.cfg/default</span><br><span class=\"line\">cp /var/ftp/pbu/isolinux/vmlinuz .</span><br><span class=\"line\">cp /var/ftp/pbu/isolinux/initrd.img .</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"设置权限\"><a href=\"#设置权限\" class=\"headerlink\" title=\"设置权限\"></a>设置权限</h3><p>设置./pxelinux.cfg/default的权限为644：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">chmod 644 default</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装DHCP服务\"><a href=\"#安装DHCP服务\" class=\"headerlink\" title=\"安装DHCP服务\"></a><font color=\"#c00\">安装DHCP服务</font></h2><h3 id=\"安装dhcp服务\"><a href=\"#安装dhcp服务\" class=\"headerlink\" title=\"安装dhcp服务\"></a>安装<a href=\"https://baike.baidu.com/item/DHCP/218195?fr=aladdin\" target=\"_blank\" rel=\"noopener\">dhcp服务</a></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install dhcp</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置-etc-dhcp-dhcpd-conf：\"><a href=\"#配置-etc-dhcp-dhcpd-conf：\" class=\"headerlink\" title=\"配置/etc/dhcp/dhcpd.conf：\"></a>配置/etc/dhcp/dhcpd.conf：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ddns-update-style interim;</span><br><span class=\"line\">allow booting;</span><br><span class=\"line\">allow booting;</span><br><span class=\"line\">next-server 192.168.0.1;</span><br><span class=\"line\">filename <span class=\"string\">\"pxelinux.0\"</span>;</span><br><span class=\"line\">default-lease-time 1800;</span><br><span class=\"line\">max-lease-time 7200;</span><br><span class=\"line\">ping-check <span class=\"literal\">true</span>;</span><br><span class=\"line\">option domain-name-servers 192.168.0.1;</span><br><span class=\"line\">subnet 192.168.0.0 netmask 255.255.255.0</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  range 192.168.0.100 192.168.0.220;</span><br><span class=\"line\">  option routers 192.168.0.1;</span><br><span class=\"line\">  option broadcast-address 192.168.0.255;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"启动HDCP：\"><a href=\"#启动HDCP：\" class=\"headerlink\" title=\"启动HDCP：\"></a>启动HDCP：</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl start dhcpd.service</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装Kickstart工具\"><a href=\"#安装Kickstart工具\" class=\"headerlink\" title=\"安装Kickstart工具\"></a><font color=\"#c00\">安装Kickstart工具</font></h2><h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装:\"></a>安装:</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum -y install system-config-kickstart</span><br></pre></td></tr></table></figure>\n<h3 id=\"运行Kickstart并配置选项\"><a href=\"#运行Kickstart并配置选项\" class=\"headerlink\" title=\"运行Kickstart并配置选项\"></a>运行Kickstart并配置选项</h3><p>启动Kickstart Configurator界面<font color=\"#c00\">（该软件需要系统安装X window）</font><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">system-config-kickstart</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"配置选项页Basic-Configuration：\"><a href=\"#配置选项页Basic-Configuration：\" class=\"headerlink\" title=\"配置选项页Basic Configuration：\"></a>配置选项页Basic Configuration：</h3><ol>\n<li>Time Zone设置为Asia/Shanghai</li>\n<li>勾选 Use UTC clock</li>\n<li>设置Root Password与Confirm Password</li>\n<li>勾选Reboot system after installation<br><img src=\"/images/post/ai/hdp1.png\" alt=\"Basic Configuration\"></li>\n</ol>\n<h3 id=\"配置选项页Installation-Method：\"><a href=\"#配置选项页Installation-Method：\" class=\"headerlink\" title=\"配置选项页Installation Method：\"></a>配置选项页Installation Method：</h3><ol>\n<li>在Installation source选框中 点选 FTP</li>\n<li>填写FTP Server： <font color=\"#999\">192.168.0.1</font></li>\n<li>填写FTP Directory： <font color=\"#999\">pub</font><br><img src=\"/images/post/ai/hdp2.png\" alt=\"Basic Configuration\"></li>\n</ol>\n<h3 id=\"配置选项页Boot-Loader-Options：\"><a href=\"#配置选项页Boot-Loader-Options：\" class=\"headerlink\" title=\"配置选项页Boot Loader Options：\"></a>配置选项页Boot Loader Options：</h3><ol>\n<li>点选 Install new boot loader<br><img src=\"/images/post/ai/hdp3.png\" alt=\"Basic Configuration\"></li>\n</ol>\n<h3 id=\"配置选项页Partition-Information\"><a href=\"#配置选项页Partition-Information\" class=\"headerlink\" title=\"配置选项页Partition Information\"></a>配置选项页Partition Information</h3><ol>\n<li>勾选 Clear Master Boot Record</li>\n<li>勾选 Remove all existing partitions</li>\n<li>勾选 Initialize the disk label</li>\n<li>点击Add 自定义分区<br><img src=\"/images/post/ai/hdp4.png\" alt=\"part\"></li>\n</ol>\n<h3 id=\"创建分区\"><a href=\"#创建分区\" class=\"headerlink\" title=\"创建分区\"></a>创建分区</h3><ol>\n<li>新增 /boot分区 文件系统类型xfs或者ext4 Fixed size: 200MB<br><img src=\"/images/post/ai/hdp5.png\" alt=\"boot\"></li>\n<li>新增 /swap分区(在File System Type中选择) Fixed size: 2048MB<br><img src=\"/images/post/ai/hdp6.png\" alt=\"swap\"></li>\n<li>新增 / 分区 点选Fill all unused space on disk<br><img src=\"/images/post/ai/hdp7.png\" alt=\"other\"></li>\n<li>创建完成后点击OK</li>\n</ol>\n<h3 id=\"配置选项页Network-COnfiguration：\"><a href=\"#配置选项页Network-COnfiguration：\" class=\"headerlink\" title=\"配置选项页Network COnfiguration：\"></a>配置选项页Network COnfiguration：</h3><p>点击Add Network Device, 下拉菜单中选择DHCP, 如果Network Device为空，请填写自己的网卡设备<br><img src=\"/images/post/ai/hdp8.png\" alt=\"dhcp\"></p>\n<h3 id=\"配置选项页Fireswall-Configuration：\"><a href=\"#配置选项页Fireswall-Configuration：\" class=\"headerlink\" title=\"配置选项页Fireswall Configuration：\"></a>配置选项页Fireswall Configuration：</h3><ol>\n<li>SELinux下拉选项：<font color=\"#999\">Disabled</font></li>\n<li>Security level下拉选项：<font color=\"#999\">Disable firewall</font><br><img src=\"/images/post/ai/hdp9.png\" alt=\"selinux\"></li>\n</ol>\n<h3 id=\"保存选项到文件\"><a href=\"#保存选项到文件\" class=\"headerlink\" title=\"保存选项到文件\"></a>保存选项到文件</h3><p>完成配置并保存到/var/ftp/ks/ks.cfg<br><img src=\"/images/post/ai/hdp10.png\" alt=\"save\"></p>\n<h3 id=\"修改启动引导文件\"><a href=\"#修改启动引导文件\" class=\"headerlink\" title=\"修改启动引导文件\"></a>修改启动引导文件</h3><p>文件路径为/var/lib/tftpboot/pxelinux.cfg/default</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">timeout 60 //暂定时间</span><br><span class=\"line\">label ks //选项</span><br><span class=\"line\">kernel vmlinuz</span><br><span class=\"line\">append ks=ftp://192.168.0.1/ks/ks.cfg initrd=initrd.img</span><br></pre></td></tr></table></figure>\n<p>类似如下图：<br><img src=\"/images/post/ai/hdp11.png\" alt=\"cfg\"></p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>到此，无人值守服务已全部配置完成，分别开启其他3台机器后，可自动进入系统安装。下篇<a href=\"/ai/hadoop-planning/\">《分布式平台前期规划》</a>。</p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>"},{"title":"Hadoop 系统搭建[系列]","date":"2017-12-06T02:30:03.000Z","_content":"## 前言\n\n这一系列的文章主要介绍，Hadoop分布式系统如何从硬件到软件搭建完成，相关插件的开发及使用的教程\n\n## 目录\n\n- #### [服务器批量安装](/ai/hadoop-servers/)\n\n- #### [分布式平台前期规划](/ai/hadoop-planning/)\n\n- #### [ZooKeeper 部署](/ai/hadoop-zkp/)\n\n<!--more-->\n\n- #### [HDFS 部署](/ai/hadoop-dfs/)\n\n- #### [YARN 部署](/ai/hadoop-yrn/)\n\n- #### [Spark 部署](/ai/hadoop-spk/)\n\n- #### [HBase 部署](/ai/hadoop-hbs/)\n\n- #### [Jupyter 部署](/ai/hadoop-jpt/)\n\n- #### [Thrift 部署](/ai/hadoop-thr/)\n\n- #### [Hadoop 附录](/ai/hadoop-add/)\n","source":"_posts/hadoop-start.md","raw":"---\ntitle: Hadoop 系统搭建[系列]\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2017-12-06 10:30:03\n---\n## 前言\n\n这一系列的文章主要介绍，Hadoop分布式系统如何从硬件到软件搭建完成，相关插件的开发及使用的教程\n\n## 目录\n\n- #### [服务器批量安装](/ai/hadoop-servers/)\n\n- #### [分布式平台前期规划](/ai/hadoop-planning/)\n\n- #### [ZooKeeper 部署](/ai/hadoop-zkp/)\n\n<!--more-->\n\n- #### [HDFS 部署](/ai/hadoop-dfs/)\n\n- #### [YARN 部署](/ai/hadoop-yrn/)\n\n- #### [Spark 部署](/ai/hadoop-spk/)\n\n- #### [HBase 部署](/ai/hadoop-hbs/)\n\n- #### [Jupyter 部署](/ai/hadoop-jpt/)\n\n- #### [Thrift 部署](/ai/hadoop-thr/)\n\n- #### [Hadoop 附录](/ai/hadoop-add/)\n","slug":"hadoop-start","published":1,"updated":"2018-04-03T04:09:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup86000c3knagaw6sy59","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>这一系列的文章主要介绍，Hadoop分布式系统如何从硬件到软件搭建完成，相关插件的开发及使用的教程</p>\n<h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><ul>\n<li><h4 id=\"服务器批量安装\"><a href=\"#服务器批量安装\" class=\"headerlink\" title=\"服务器批量安装\"></a><a href=\"/ai/hadoop-servers/\">服务器批量安装</a></h4></li>\n<li><h4 id=\"分布式平台前期规划\"><a href=\"#分布式平台前期规划\" class=\"headerlink\" title=\"分布式平台前期规划\"></a><a href=\"/ai/hadoop-planning/\">分布式平台前期规划</a></h4></li>\n<li><h4 id=\"ZooKeeper-部署\"><a href=\"#ZooKeeper-部署\" class=\"headerlink\" title=\"ZooKeeper 部署\"></a><a href=\"/ai/hadoop-zkp/\">ZooKeeper 部署</a></h4></li>\n</ul>\n<a id=\"more\"></a>\n<ul>\n<li><h4 id=\"HDFS-部署\"><a href=\"#HDFS-部署\" class=\"headerlink\" title=\"HDFS 部署\"></a><a href=\"/ai/hadoop-dfs/\">HDFS 部署</a></h4></li>\n<li><h4 id=\"YARN-部署\"><a href=\"#YARN-部署\" class=\"headerlink\" title=\"YARN 部署\"></a><a href=\"/ai/hadoop-yrn/\">YARN 部署</a></h4></li>\n<li><h4 id=\"Spark-部署\"><a href=\"#Spark-部署\" class=\"headerlink\" title=\"Spark 部署\"></a><a href=\"/ai/hadoop-spk/\">Spark 部署</a></h4></li>\n<li><h4 id=\"HBase-部署\"><a href=\"#HBase-部署\" class=\"headerlink\" title=\"HBase 部署\"></a><a href=\"/ai/hadoop-hbs/\">HBase 部署</a></h4></li>\n<li><h4 id=\"Jupyter-部署\"><a href=\"#Jupyter-部署\" class=\"headerlink\" title=\"Jupyter 部署\"></a><a href=\"/ai/hadoop-jpt/\">Jupyter 部署</a></h4></li>\n<li><h4 id=\"Thrift-部署\"><a href=\"#Thrift-部署\" class=\"headerlink\" title=\"Thrift 部署\"></a><a href=\"/ai/hadoop-thr/\">Thrift 部署</a></h4></li>\n<li><h4 id=\"Hadoop-附录\"><a href=\"#Hadoop-附录\" class=\"headerlink\" title=\"Hadoop 附录\"></a><a href=\"/ai/hadoop-add/\">Hadoop 附录</a></h4></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>这一系列的文章主要介绍，Hadoop分布式系统如何从硬件到软件搭建完成，相关插件的开发及使用的教程</p>\n<h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><ul>\n<li><h4 id=\"服务器批量安装\"><a href=\"#服务器批量安装\" class=\"headerlink\" title=\"服务器批量安装\"></a><a href=\"/ai/hadoop-servers/\">服务器批量安装</a></h4></li>\n<li><h4 id=\"分布式平台前期规划\"><a href=\"#分布式平台前期规划\" class=\"headerlink\" title=\"分布式平台前期规划\"></a><a href=\"/ai/hadoop-planning/\">分布式平台前期规划</a></h4></li>\n<li><h4 id=\"ZooKeeper-部署\"><a href=\"#ZooKeeper-部署\" class=\"headerlink\" title=\"ZooKeeper 部署\"></a><a href=\"/ai/hadoop-zkp/\">ZooKeeper 部署</a></h4></li>\n</ul>","more":"<ul>\n<li><h4 id=\"HDFS-部署\"><a href=\"#HDFS-部署\" class=\"headerlink\" title=\"HDFS 部署\"></a><a href=\"/ai/hadoop-dfs/\">HDFS 部署</a></h4></li>\n<li><h4 id=\"YARN-部署\"><a href=\"#YARN-部署\" class=\"headerlink\" title=\"YARN 部署\"></a><a href=\"/ai/hadoop-yrn/\">YARN 部署</a></h4></li>\n<li><h4 id=\"Spark-部署\"><a href=\"#Spark-部署\" class=\"headerlink\" title=\"Spark 部署\"></a><a href=\"/ai/hadoop-spk/\">Spark 部署</a></h4></li>\n<li><h4 id=\"HBase-部署\"><a href=\"#HBase-部署\" class=\"headerlink\" title=\"HBase 部署\"></a><a href=\"/ai/hadoop-hbs/\">HBase 部署</a></h4></li>\n<li><h4 id=\"Jupyter-部署\"><a href=\"#Jupyter-部署\" class=\"headerlink\" title=\"Jupyter 部署\"></a><a href=\"/ai/hadoop-jpt/\">Jupyter 部署</a></h4></li>\n<li><h4 id=\"Thrift-部署\"><a href=\"#Thrift-部署\" class=\"headerlink\" title=\"Thrift 部署\"></a><a href=\"/ai/hadoop-thr/\">Thrift 部署</a></h4></li>\n<li><h4 id=\"Hadoop-附录\"><a href=\"#Hadoop-附录\" class=\"headerlink\" title=\"Hadoop 附录\"></a><a href=\"/ai/hadoop-add/\">Hadoop 附录</a></h4></li>\n</ul>"},{"title":"Thrift 部署","date":"2018-04-03T03:15:16.000Z","_content":"Thrift服务是帮助Jupyter Notebook访问HBase，安装后我们就可以在程序中直接访问HBase了。\n\n# Quick Start\n\n## <font color=#c00>下载安装</font>\n\n按照之前的规划表，我们会在node3中启动Thrift服务，所以在这篇文章我们选择在node3中进行配置安装。\n\n登陆[官方网站](http://thrift.apache.org/)下载Thrift安装包，版本0.10.0，下载完成后解压并进入该文件夹。\n\n运行如下命令进行安装：\n\n<!--more-->\n\n``` bash\n# 配置\n./configure --with-cpp --with-boost --with-python --without-csharp --with-java --without-erlang --without-perl --with-php --without-php_extension --without-ruby --without-haskell  --without-go\n\n# 编译\nmake\n\n# 安装\nmake install\n```\n\n## <font color=#c00>启动服务</font>\n\n安装完成后，进入/opt/hbase-1.3.1，启动thrift服务\n\n``` bash\nbin/hbase-daemon.sh start thrift\n```\n\n## <font color=#c00>安装依赖包</font>\n\n``` bash\nsudo pip install thrift\n\nsudo pip install hbase-thrift\n```\n\n到此Thrift已安装完成，是不是很简单 : ）\n\n## <font color=#c00>测试</font>\n\n下面我们来写段简单的Python(2.7)程序，测试HBase是否联通。这段程序获取HBase下的所有表名，结果会以类数组的方式打印出来。\n\n``` python\nfrom thrift import Thrift\nfrom thrift.transport import TSocket, TTransport\nfrom thrift.protocol import TBinaryProtocol\nfrom hbase import Hbase\nfrom hbase.ttypes import * \n\n# 参数配置\nhm_ip = 'node3的IP地址'\n# 这里的9090是HBase的RPC协议端口\nhm_port = 9090\n\ntransport = TSocket.TSocket(hm_ip, hm_port)\ntransport = TTransport.TBufferedTransport(transport)\nprotocol = TBinaryProtocol.TBinaryProtocol(transport)\nclient = Hbase.Client(protocol)\ntransport.open()\ntableName = client.getTableNames()\nprint tableName\ntransport.close()\n```\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://thrift.apache.org/docs/)\n\n## <font color=#c00>小结</font>\n\n完成上述配置后，我们可以通过Python程序访问HBase了。下篇[《Hadoop 附录》](/ai/hadoop-add/)\n\n本系列文章[《目录》](/ai/hadoop-start/)","source":"_posts/hadoop-thr.md","raw":"---\ntitle: Thrift 部署\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-04-03 11:15:16\n---\nThrift服务是帮助Jupyter Notebook访问HBase，安装后我们就可以在程序中直接访问HBase了。\n\n# Quick Start\n\n## <font color=#c00>下载安装</font>\n\n按照之前的规划表，我们会在node3中启动Thrift服务，所以在这篇文章我们选择在node3中进行配置安装。\n\n登陆[官方网站](http://thrift.apache.org/)下载Thrift安装包，版本0.10.0，下载完成后解压并进入该文件夹。\n\n运行如下命令进行安装：\n\n<!--more-->\n\n``` bash\n# 配置\n./configure --with-cpp --with-boost --with-python --without-csharp --with-java --without-erlang --without-perl --with-php --without-php_extension --without-ruby --without-haskell  --without-go\n\n# 编译\nmake\n\n# 安装\nmake install\n```\n\n## <font color=#c00>启动服务</font>\n\n安装完成后，进入/opt/hbase-1.3.1，启动thrift服务\n\n``` bash\nbin/hbase-daemon.sh start thrift\n```\n\n## <font color=#c00>安装依赖包</font>\n\n``` bash\nsudo pip install thrift\n\nsudo pip install hbase-thrift\n```\n\n到此Thrift已安装完成，是不是很简单 : ）\n\n## <font color=#c00>测试</font>\n\n下面我们来写段简单的Python(2.7)程序，测试HBase是否联通。这段程序获取HBase下的所有表名，结果会以类数组的方式打印出来。\n\n``` python\nfrom thrift import Thrift\nfrom thrift.transport import TSocket, TTransport\nfrom thrift.protocol import TBinaryProtocol\nfrom hbase import Hbase\nfrom hbase.ttypes import * \n\n# 参数配置\nhm_ip = 'node3的IP地址'\n# 这里的9090是HBase的RPC协议端口\nhm_port = 9090\n\ntransport = TSocket.TSocket(hm_ip, hm_port)\ntransport = TTransport.TBufferedTransport(transport)\nprotocol = TBinaryProtocol.TBinaryProtocol(transport)\nclient = Hbase.Client(protocol)\ntransport.open()\ntableName = client.getTableNames()\nprint tableName\ntransport.close()\n```\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://thrift.apache.org/docs/)\n\n## <font color=#c00>小结</font>\n\n完成上述配置后，我们可以通过Python程序访问HBase了。下篇[《Hadoop 附录》](/ai/hadoop-add/)\n\n本系列文章[《目录》](/ai/hadoop-start/)","slug":"hadoop-thr","published":1,"updated":"2018-04-03T04:09:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup88000h3knac1u8gahc","content":"<p>Thrift服务是帮助Jupyter Notebook访问HBase，安装后我们就可以在程序中直接访问HBase了。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"下载安装\"><a href=\"#下载安装\" class=\"headerlink\" title=\"下载安装\"></a><font color=\"#c00\">下载安装</font></h2><p>按照之前的规划表，我们会在node3中启动Thrift服务，所以在这篇文章我们选择在node3中进行配置安装。</p>\n<p>登陆<a href=\"http://thrift.apache.org/\" target=\"_blank\" rel=\"noopener\">官方网站</a>下载Thrift安装包，版本0.10.0，下载完成后解压并进入该文件夹。</p>\n<p>运行如下命令进行安装：</p>\n<a id=\"more\"></a>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 配置</span></span><br><span class=\"line\">./configure --with-cpp --with-boost --with-python --without-csharp --with-java --without-erlang --without-perl --with-php --without-php_extension --without-ruby --without-haskell  --without-go</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 编译</span></span><br><span class=\"line\">make</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 安装</span></span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动服务\"><a href=\"#启动服务\" class=\"headerlink\" title=\"启动服务\"></a><font color=\"#c00\">启动服务</font></h2><p>安装完成后，进入/opt/hbase-1.3.1，启动thrift服务</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hbase-daemon.sh start thrift</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装依赖包\"><a href=\"#安装依赖包\" class=\"headerlink\" title=\"安装依赖包\"></a><font color=\"#c00\">安装依赖包</font></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip install thrift</span><br><span class=\"line\"></span><br><span class=\"line\">sudo pip install hbase-thrift</span><br></pre></td></tr></table></figure>\n<p>到此Thrift已安装完成，是不是很简单 : ）</p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a><font color=\"#c00\">测试</font></h2><p>下面我们来写段简单的Python(2.7)程序，测试HBase是否联通。这段程序获取HBase下的所有表名，结果会以类数组的方式打印出来。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> thrift <span class=\"keyword\">import</span> Thrift</span><br><span class=\"line\"><span class=\"keyword\">from</span> thrift.transport <span class=\"keyword\">import</span> TSocket, TTransport</span><br><span class=\"line\"><span class=\"keyword\">from</span> thrift.protocol <span class=\"keyword\">import</span> TBinaryProtocol</span><br><span class=\"line\"><span class=\"keyword\">from</span> hbase <span class=\"keyword\">import</span> Hbase</span><br><span class=\"line\"><span class=\"keyword\">from</span> hbase.ttypes <span class=\"keyword\">import</span> * </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 参数配置</span></span><br><span class=\"line\">hm_ip = <span class=\"string\">'node3的IP地址'</span></span><br><span class=\"line\"><span class=\"comment\"># 这里的9090是HBase的RPC协议端口</span></span><br><span class=\"line\">hm_port = <span class=\"number\">9090</span></span><br><span class=\"line\"></span><br><span class=\"line\">transport = TSocket.TSocket(hm_ip, hm_port)</span><br><span class=\"line\">transport = TTransport.TBufferedTransport(transport)</span><br><span class=\"line\">protocol = TBinaryProtocol.TBinaryProtocol(transport)</span><br><span class=\"line\">client = Hbase.Client(protocol)</span><br><span class=\"line\">transport.open()</span><br><span class=\"line\">tableName = client.getTableNames()</span><br><span class=\"line\"><span class=\"keyword\">print</span> tableName</span><br><span class=\"line\">transport.close()</span><br></pre></td></tr></table></figure>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://thrift.apache.org/docs/\" target=\"_blank\" rel=\"noopener\">官方文档</a></p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成上述配置后，我们可以通过Python程序访问HBase了。下篇<a href=\"/ai/hadoop-add/\">《Hadoop 附录》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>\n","site":{"data":{}},"excerpt":"<p>Thrift服务是帮助Jupyter Notebook访问HBase，安装后我们就可以在程序中直接访问HBase了。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"下载安装\"><a href=\"#下载安装\" class=\"headerlink\" title=\"下载安装\"></a><font color=\"#c00\">下载安装</font></h2><p>按照之前的规划表，我们会在node3中启动Thrift服务，所以在这篇文章我们选择在node3中进行配置安装。</p>\n<p>登陆<a href=\"http://thrift.apache.org/\" target=\"_blank\" rel=\"noopener\">官方网站</a>下载Thrift安装包，版本0.10.0，下载完成后解压并进入该文件夹。</p>\n<p>运行如下命令进行安装：</p>","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 配置</span></span><br><span class=\"line\">./configure --with-cpp --with-boost --with-python --without-csharp --with-java --without-erlang --without-perl --with-php --without-php_extension --without-ruby --without-haskell  --without-go</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 编译</span></span><br><span class=\"line\">make</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 安装</span></span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动服务\"><a href=\"#启动服务\" class=\"headerlink\" title=\"启动服务\"></a><font color=\"#c00\">启动服务</font></h2><p>安装完成后，进入/opt/hbase-1.3.1，启动thrift服务</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/hbase-daemon.sh start thrift</span><br></pre></td></tr></table></figure>\n<h2 id=\"安装依赖包\"><a href=\"#安装依赖包\" class=\"headerlink\" title=\"安装依赖包\"></a><font color=\"#c00\">安装依赖包</font></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip install thrift</span><br><span class=\"line\"></span><br><span class=\"line\">sudo pip install hbase-thrift</span><br></pre></td></tr></table></figure>\n<p>到此Thrift已安装完成，是不是很简单 : ）</p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a><font color=\"#c00\">测试</font></h2><p>下面我们来写段简单的Python(2.7)程序，测试HBase是否联通。这段程序获取HBase下的所有表名，结果会以类数组的方式打印出来。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> thrift <span class=\"keyword\">import</span> Thrift</span><br><span class=\"line\"><span class=\"keyword\">from</span> thrift.transport <span class=\"keyword\">import</span> TSocket, TTransport</span><br><span class=\"line\"><span class=\"keyword\">from</span> thrift.protocol <span class=\"keyword\">import</span> TBinaryProtocol</span><br><span class=\"line\"><span class=\"keyword\">from</span> hbase <span class=\"keyword\">import</span> Hbase</span><br><span class=\"line\"><span class=\"keyword\">from</span> hbase.ttypes <span class=\"keyword\">import</span> * </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 参数配置</span></span><br><span class=\"line\">hm_ip = <span class=\"string\">'node3的IP地址'</span></span><br><span class=\"line\"><span class=\"comment\"># 这里的9090是HBase的RPC协议端口</span></span><br><span class=\"line\">hm_port = <span class=\"number\">9090</span></span><br><span class=\"line\"></span><br><span class=\"line\">transport = TSocket.TSocket(hm_ip, hm_port)</span><br><span class=\"line\">transport = TTransport.TBufferedTransport(transport)</span><br><span class=\"line\">protocol = TBinaryProtocol.TBinaryProtocol(transport)</span><br><span class=\"line\">client = Hbase.Client(protocol)</span><br><span class=\"line\">transport.open()</span><br><span class=\"line\">tableName = client.getTableNames()</span><br><span class=\"line\"><span class=\"keyword\">print</span> tableName</span><br><span class=\"line\">transport.close()</span><br></pre></td></tr></table></figure>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://thrift.apache.org/docs/\" target=\"_blank\" rel=\"noopener\">官方文档</a></p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成上述配置后，我们可以通过Python程序访问HBase了。下篇<a href=\"/ai/hadoop-add/\">《Hadoop 附录》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>"},{"title":"深入学习硬件那些事...","date":"2018-03-20T02:18:18.000Z","_content":"\n\n提到深度学习，想必大家都知道这是件计算密集型的事，第一个蒙B的困扰是：“攒一个适合做这件事的系统到底需不需要买一个多核高速的CPU...- -？”。“要想性能猛，就得花钱糟”，带着这样的想法，我们在搭建深度学习系统时，做的最糟糕的事就是在硬件上花了很多冤枉钱。这篇文章，我将告诉大家如果一步步的攒出一个性能高端大气，价格童叟无欺的牛X系统。\n\n那时，开始并行深度学习方面的工作，我需要搭建一个GPU集群。因为经验不足，所以我想：“得仔细挑选才行”。经管自己做了不少的研究，推理，但在选择硬件这件事上还是走了不少弯路。真是实践出真知，随着不断对集群的测试，才慢慢也抹出点门道。在这儿，我想把自己学到的东西分享出来，避免大家踩同样的坑。\n\nGPU\n\n这篇文章主要关于如何用GPU进行深度学习。如果此时，你正想搭建或者升级你的系统去做机器学习方面的事，那么我想告诉你：“GPU真是太tm重要了”。当然，GPU也只是深度学习应用程序的核心（它尤其在整体系统处理速度提高方面帮助，不容忽视）\n\n[在我之前的文章](https://timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/)中就详细讨论过GPU的选择，因为这是深度学习系统搭建中的致命一环。通常来说，如果你的预算比较羞涩的话，个人比较推荐去网上淘个GTX 680。当然如果你是土豪（别忘了留下联系方式，大家可以做朋友∩_∩），在小规模的卷积神经网络方面，我推荐GTX TITAN X。稍大一些规划的卷积神经网络，GTX 980（这也许是当时最好的GPU） 效果会更好。还是那句话，如果你想价格便宜点还是去网上淘吧！我之前一直在用GTX 580，但由于cuDNN库的更新（新版本在卷积速度方面提高的一大截），GTX 580已无法支持。如果你不拿它做卷积神经网络方面的事。个人觉得580还是一个不错的选择。\n\n下面这张图你能看出那块牛X，哪块令你蛋碎吗？\n![]()\n\nCPU\n\n为了能够对CPU做出明智的选择，我们首先得了解CPU与深度学习的关系，以及它到底在深度学习方面起什么作用。当你在GPU上运行你的深度学习算法时，这时的CPU到底在忙些什么？下面我将为你列这货在干的事：\n\n编写和读取代码中的变量\n执行指令（比如调个函数啥的）\n在GPU上初始化函数调用\n样本数据mini-batch\n把准备好的子集循环传给GPU\n\n注：如果你还不了解什么是mini-batch，[请点击此链接](https://testerhome.com/topics/10877)。\n\n需要的CPU核心数\n\n当我用三个不同的库训练同样的神经网络时，CPU线程占用率都是100%（有时，另一个线程会在0到100%之前波动一会）。从这点可以看出，大部分到深度学习使用的库（实际上大部分软件程序）只使用一个线程运行。这意味着，一般情况下，多核CPU基本没啥用。但是如果你同时运行多个GPU或者使用像MPI这样的并行框架，多个程序的同时运行，多线程就显得很重要了。通常情况下，一个GPU使用一个CPU线程，但如果一个GPU可以使用两个线程，那会大大提高深度学习库的性能。由于这些库在一个核上运行，因为有时会异步调用函数，所以会使用第二个CPU线程。敲黑板了，知识点啊：现在CPU的每个核都会有多个CPU线程（在Intel的CPUs中这点尤为突出）因此单核的CPU通常已经足够。\n\nCPU and PCI-Express\n\n注：一些Haswell架构的GPU并不支持完整的40路PCI-E通道，如果你想搭建多GPU系统，确保你的CPU和主板支持PCI-E 3.0\n\nCPU 缓存大小\n\n下面我会从CPU到GPU运行的过程，做一个大致的分析，告诉你关于CPU缓存的故事。对整个过程有了透彻的理解，我们才能从中找到可能存在瓶颈的地方。\n\n当我们购买CPU时，CPU缓存常常被忽略（有木有看到缓存们悲愤的眼神'_'），但其实，他们在整体性能难题中扮演着非常重要的角色。CPU缓存时一组数量非常少的芯片内存，他们被集成在CPU中，用于执行高速的运算及指令操作。CPU中的缓存通常存在一个层级结构，从小而快（L1, L2）到大而慢（L3, L4）。作为一个程序猿，你应该知道它就像个哈希表，每条记录就是一个键值对。它可以对特殊的健做非常快速的查找：如果找到的健，就可以对其值进行快速的读写操作；如果未找到（缓存缺失），CPU将会去内存中查找，然后从那把值读取出来（这是一个非常缓慢的过程，如同你遇到了那个叫闪电的家伙）。上述过程我们可以看到高效的CPU缓存过程体系结构通常对CPU性能至关重要。\n\nCPU是如何确定他的缓存过程是一个非常复杂的议题。不过大致可以这样理解，重复使用频率高的变量，指令以及内存地址将会被缓存，其他的则不会。\n\n现在我们分析在深度学习中缓存的使用情况。数据在发送到GPU处理前，相同内存空间的数据以mini-batch块的形式被重复读取，那么这部分样本数据就可以存储在缓存中，当然这也取决于mini-batch的大小。我们取每个mini-batch块中128个样本，就好像我们有0.4MB的[MNIST](https://www.cnblogs.com/lizheng114/p/7439556.html)和1.5MB的[CIFAR](https://blog.csdn.net/zeuseign/article/details/72773342)，这适合大多数CPU缓存。但是，在[ImageNet](https://baike.baidu.com/item/ImageNet/17752829?fr=aladdin)中，每个mini-batch却高达85MB的大小（4 * 128 * 244^2 * 3* 1024^-2），这个数量远远大于CPU最大量级的缓存（L3也只有那么有限的2，30MB）。\n\n通常情况下，样本数据都非常的大而无法放入缓存。每个新的mini-batch块都需要从内存中重新读区。所以无论怎样，都会不断的访问内存。\n\n也许你会想到，可以把样本数据都精确内存地址放入缓存，这样CPU在执行时就可以高速查找了。可真如我们所愿吗？如果这样，你必须把整个样本集都放入内存，否则查找时内存地址就会发生变化，这样依然无法依靠缓存提速，比如我们使用[页锁内存](https://blog.csdn.net/ziv555/article/details/52116877)时。\n\n当然，代码中的变量和函数调用还是得益于高速缓存，但这些通常数量很少，很容易把它们放进CPU的L1缓存内。\n\n从上述内容中我们可以得出结论，在深度学习方面，CPU的缓存大小似乎没那么重要。下一节，我们会进一步分析验证这个结论。\n\nCPU时钟频率\n\n当人们形容CPU的快慢时，通常首先会想到时钟频率。4GHz比3.5GHz好，是这样吗？一般来说两个相同架构的处理器（比如都是 Ivy Bridge）可以这样看待，但是无法比较出两个处理器的优劣。它并不是一个好的衡量性能的度量衡。\n\n在深度学习领域，CPU的计算量其实非常的小（增加几个变量，计算一些布尔表达式，在GPU的计算过程中调用几个函数，当然这些事情都取决于CPU的核心时钟频率）。这么推理似乎也挺合理，但当我们运行代码时，却发现CPU的使用率高达100%，这么点操作使用率却如此之高，究竟问题出在哪？于是，我做了一些CPU降频的实验，发现问题所在。\n\n在CPU的使用率高达100%时，如果与其主频无关的话，应该与神马有关呢？答案也许是CPU缓存缺失：CPU一只非常忙碌的在访问内存，但同时CPU不得不等待内存的低频率，结果导致奇怪的忙等待状态。如果这个推论是正确的，那么CPU降频也不会导致性能的急剧下降，正如上图所示。\n\n当然，CPU还会执行一些其他的操作，例如：拷贝数据到mini-batches，把准备好的数据拷贝到GPU，但这些操作的速度依赖于内存频率，并不取决于CPU主频。那么现在我嘛来看看内存。\n\n内存频率\n\nCPU与内存以及与其他硬件的相互作用是一个强大复杂的过程。本文将此简化，来进行研究CPU到内存再到显存到整个过程。以便帮助大家更透彻的理解。\n\nCPU时钟与内存被纠缠在一起，CPU的主频决定了内存的最大频率，且这两者决定了你的CPU带宽，但是，通常来说内存自己决定了全部可用带宽，因为它的速度慢于CPU速率。你可以这样来计算带宽：bandwidth in GB/s = RAM clock in GHz * memory channels of CPU * 64 / 8\n\n这里的64是指64位CPU架构。通过计算我的处理器与内存带宽位51.2GB/s\n\n通常情况下，如果要拷贝大批量数据，那带宽与性能将息息相关。例如：CPU需要匹配内存的速度，从内存中获取大批量小块数据。这种情况，几乎适合所有的深度学习相关的程序。要么数据块大小可以放进缓存，那很容易从中获益，要么数据块太大而无法有效利用缓存。从上述例子中看到带宽比缓存似乎更加重要。\n\n那么，这与深度学习程序有什么关系呢？我刚才说过带宽似乎是很重要的，但我们继续往下看时，发现情况似乎又发生了变化。内存带宽决定了一个mini-batch以多快的速度呗覆盖以及分配去初始化GPU传输，但继续下一步时，我们会发现CPU到内存到GPU再回到内存这个过程存在瓶颈（直接内存访问）。之前提到过，我的机器带宽时51.2GB/s，但DMA带宽只有12GB/s。\n\nDMA的带宽速率与常规带宽有点关系，但在还是有细节上的差异。具体DMA带宽与内存之间的恩怨纠葛，有兴趣的朋友可以查看维基百科。本文还是让我们先了解下DMA是如何工作的吧。\n\n直接存储器（DMA）\n\nCPU及内存只能通过DMA才能与GPU通信。首先，内存与显存之间保留了特定的DMA传输缓存区；第二步，CPU把请求数据写入到CPU侧的缓冲区内；最后一步，保留的缓冲区被转移到显存中，而不需要CPU的协助。假设这样一个问题：你的PCI-E(2.0)带宽是8.0GB/s或者是（3.0）带宽15.75GB/s，那么你的传输峰值是否会被上述描述所决定？\n\n个人觉得并非如此。软件本身就扮演了一个很重要的角色。如果你使用了一个不错的传输算法，那么你同样会远离廉价且缓慢的内存。\n\nmini-batch异步分配\n\n一旦GPU完成了当前mini-batch上的计算，那么它就像立刻处理下一个数据块。当然你可以启动DMA传输，等待传输完成以便GPU能够继续工作。但是有一个更有效的方法：如果能提前准备好下一个数据块，这样你的GPU就不用等待了。这样做可以在不降低GPU性能的情况下，异步且轻松的完成传输任务。\n\n下图是有关mini-batch异步分配的CUDA代码：前两次的调用是在GPU开始前发出的；后两行调用是GPU完成后发出的。数据的传输在第二步传输前同步完成，因此不会在下批数据开始前使得GPU延时。\n\n\nImageNet2012的每个mini-batch大小为128，Alex Krishevsky卷积网以0.35秒为全BackProp通过。我们是否能在这个时间分配下批数据？\n\n我们取每个数据块为128，那么244*244*3规模的数据，总共大约0.085GB（4 * 128 * 244^2 * 3 * 1024^-3），再慢的内存速度也有6.4GB/s，换句话说每秒75个mini-batch！所以对于异步分配来说既是最慢的内存也足以满足深度学习的需要。如果你使用异步分配算法，就不需要购那么块的内存了。\n\n这个过程还间接说明了与CPU缓存的无关。你的CPU能多快的速度重写数据（在高速缓存中），以及多快为DMA的传输准备一个mini-batch（从缓存写入内存）已不那么重要了。因为在你的GPU请求下一个mini-batch的时候整个传输早已完成。所以大缓存实际上也没那么重要。\n\n所以最终的结论是内存的主频并不重要。买个廉价的就可以，故事结束。那么我们该买多大的呢？\n\n内存大小\n\n","source":"_drafts/dl-hware.md","raw":"---\ntitle: 深入学习硬件那些事...\ncategories:\n  - ai\ntags:\n  - 深度学习\ndate: 2018-03-20 10:18:18\n---\n\n\n提到深度学习，想必大家都知道这是件计算密集型的事，第一个蒙B的困扰是：“攒一个适合做这件事的系统到底需不需要买一个多核高速的CPU...- -？”。“要想性能猛，就得花钱糟”，带着这样的想法，我们在搭建深度学习系统时，做的最糟糕的事就是在硬件上花了很多冤枉钱。这篇文章，我将告诉大家如果一步步的攒出一个性能高端大气，价格童叟无欺的牛X系统。\n\n那时，开始并行深度学习方面的工作，我需要搭建一个GPU集群。因为经验不足，所以我想：“得仔细挑选才行”。经管自己做了不少的研究，推理，但在选择硬件这件事上还是走了不少弯路。真是实践出真知，随着不断对集群的测试，才慢慢也抹出点门道。在这儿，我想把自己学到的东西分享出来，避免大家踩同样的坑。\n\nGPU\n\n这篇文章主要关于如何用GPU进行深度学习。如果此时，你正想搭建或者升级你的系统去做机器学习方面的事，那么我想告诉你：“GPU真是太tm重要了”。当然，GPU也只是深度学习应用程序的核心（它尤其在整体系统处理速度提高方面帮助，不容忽视）\n\n[在我之前的文章](https://timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/)中就详细讨论过GPU的选择，因为这是深度学习系统搭建中的致命一环。通常来说，如果你的预算比较羞涩的话，个人比较推荐去网上淘个GTX 680。当然如果你是土豪（别忘了留下联系方式，大家可以做朋友∩_∩），在小规模的卷积神经网络方面，我推荐GTX TITAN X。稍大一些规划的卷积神经网络，GTX 980（这也许是当时最好的GPU） 效果会更好。还是那句话，如果你想价格便宜点还是去网上淘吧！我之前一直在用GTX 580，但由于cuDNN库的更新（新版本在卷积速度方面提高的一大截），GTX 580已无法支持。如果你不拿它做卷积神经网络方面的事。个人觉得580还是一个不错的选择。\n\n下面这张图你能看出那块牛X，哪块令你蛋碎吗？\n![]()\n\nCPU\n\n为了能够对CPU做出明智的选择，我们首先得了解CPU与深度学习的关系，以及它到底在深度学习方面起什么作用。当你在GPU上运行你的深度学习算法时，这时的CPU到底在忙些什么？下面我将为你列这货在干的事：\n\n编写和读取代码中的变量\n执行指令（比如调个函数啥的）\n在GPU上初始化函数调用\n样本数据mini-batch\n把准备好的子集循环传给GPU\n\n注：如果你还不了解什么是mini-batch，[请点击此链接](https://testerhome.com/topics/10877)。\n\n需要的CPU核心数\n\n当我用三个不同的库训练同样的神经网络时，CPU线程占用率都是100%（有时，另一个线程会在0到100%之前波动一会）。从这点可以看出，大部分到深度学习使用的库（实际上大部分软件程序）只使用一个线程运行。这意味着，一般情况下，多核CPU基本没啥用。但是如果你同时运行多个GPU或者使用像MPI这样的并行框架，多个程序的同时运行，多线程就显得很重要了。通常情况下，一个GPU使用一个CPU线程，但如果一个GPU可以使用两个线程，那会大大提高深度学习库的性能。由于这些库在一个核上运行，因为有时会异步调用函数，所以会使用第二个CPU线程。敲黑板了，知识点啊：现在CPU的每个核都会有多个CPU线程（在Intel的CPUs中这点尤为突出）因此单核的CPU通常已经足够。\n\nCPU and PCI-Express\n\n注：一些Haswell架构的GPU并不支持完整的40路PCI-E通道，如果你想搭建多GPU系统，确保你的CPU和主板支持PCI-E 3.0\n\nCPU 缓存大小\n\n下面我会从CPU到GPU运行的过程，做一个大致的分析，告诉你关于CPU缓存的故事。对整个过程有了透彻的理解，我们才能从中找到可能存在瓶颈的地方。\n\n当我们购买CPU时，CPU缓存常常被忽略（有木有看到缓存们悲愤的眼神'_'），但其实，他们在整体性能难题中扮演着非常重要的角色。CPU缓存时一组数量非常少的芯片内存，他们被集成在CPU中，用于执行高速的运算及指令操作。CPU中的缓存通常存在一个层级结构，从小而快（L1, L2）到大而慢（L3, L4）。作为一个程序猿，你应该知道它就像个哈希表，每条记录就是一个键值对。它可以对特殊的健做非常快速的查找：如果找到的健，就可以对其值进行快速的读写操作；如果未找到（缓存缺失），CPU将会去内存中查找，然后从那把值读取出来（这是一个非常缓慢的过程，如同你遇到了那个叫闪电的家伙）。上述过程我们可以看到高效的CPU缓存过程体系结构通常对CPU性能至关重要。\n\nCPU是如何确定他的缓存过程是一个非常复杂的议题。不过大致可以这样理解，重复使用频率高的变量，指令以及内存地址将会被缓存，其他的则不会。\n\n现在我们分析在深度学习中缓存的使用情况。数据在发送到GPU处理前，相同内存空间的数据以mini-batch块的形式被重复读取，那么这部分样本数据就可以存储在缓存中，当然这也取决于mini-batch的大小。我们取每个mini-batch块中128个样本，就好像我们有0.4MB的[MNIST](https://www.cnblogs.com/lizheng114/p/7439556.html)和1.5MB的[CIFAR](https://blog.csdn.net/zeuseign/article/details/72773342)，这适合大多数CPU缓存。但是，在[ImageNet](https://baike.baidu.com/item/ImageNet/17752829?fr=aladdin)中，每个mini-batch却高达85MB的大小（4 * 128 * 244^2 * 3* 1024^-2），这个数量远远大于CPU最大量级的缓存（L3也只有那么有限的2，30MB）。\n\n通常情况下，样本数据都非常的大而无法放入缓存。每个新的mini-batch块都需要从内存中重新读区。所以无论怎样，都会不断的访问内存。\n\n也许你会想到，可以把样本数据都精确内存地址放入缓存，这样CPU在执行时就可以高速查找了。可真如我们所愿吗？如果这样，你必须把整个样本集都放入内存，否则查找时内存地址就会发生变化，这样依然无法依靠缓存提速，比如我们使用[页锁内存](https://blog.csdn.net/ziv555/article/details/52116877)时。\n\n当然，代码中的变量和函数调用还是得益于高速缓存，但这些通常数量很少，很容易把它们放进CPU的L1缓存内。\n\n从上述内容中我们可以得出结论，在深度学习方面，CPU的缓存大小似乎没那么重要。下一节，我们会进一步分析验证这个结论。\n\nCPU时钟频率\n\n当人们形容CPU的快慢时，通常首先会想到时钟频率。4GHz比3.5GHz好，是这样吗？一般来说两个相同架构的处理器（比如都是 Ivy Bridge）可以这样看待，但是无法比较出两个处理器的优劣。它并不是一个好的衡量性能的度量衡。\n\n在深度学习领域，CPU的计算量其实非常的小（增加几个变量，计算一些布尔表达式，在GPU的计算过程中调用几个函数，当然这些事情都取决于CPU的核心时钟频率）。这么推理似乎也挺合理，但当我们运行代码时，却发现CPU的使用率高达100%，这么点操作使用率却如此之高，究竟问题出在哪？于是，我做了一些CPU降频的实验，发现问题所在。\n\n在CPU的使用率高达100%时，如果与其主频无关的话，应该与神马有关呢？答案也许是CPU缓存缺失：CPU一只非常忙碌的在访问内存，但同时CPU不得不等待内存的低频率，结果导致奇怪的忙等待状态。如果这个推论是正确的，那么CPU降频也不会导致性能的急剧下降，正如上图所示。\n\n当然，CPU还会执行一些其他的操作，例如：拷贝数据到mini-batches，把准备好的数据拷贝到GPU，但这些操作的速度依赖于内存频率，并不取决于CPU主频。那么现在我嘛来看看内存。\n\n内存频率\n\nCPU与内存以及与其他硬件的相互作用是一个强大复杂的过程。本文将此简化，来进行研究CPU到内存再到显存到整个过程。以便帮助大家更透彻的理解。\n\nCPU时钟与内存被纠缠在一起，CPU的主频决定了内存的最大频率，且这两者决定了你的CPU带宽，但是，通常来说内存自己决定了全部可用带宽，因为它的速度慢于CPU速率。你可以这样来计算带宽：bandwidth in GB/s = RAM clock in GHz * memory channels of CPU * 64 / 8\n\n这里的64是指64位CPU架构。通过计算我的处理器与内存带宽位51.2GB/s\n\n通常情况下，如果要拷贝大批量数据，那带宽与性能将息息相关。例如：CPU需要匹配内存的速度，从内存中获取大批量小块数据。这种情况，几乎适合所有的深度学习相关的程序。要么数据块大小可以放进缓存，那很容易从中获益，要么数据块太大而无法有效利用缓存。从上述例子中看到带宽比缓存似乎更加重要。\n\n那么，这与深度学习程序有什么关系呢？我刚才说过带宽似乎是很重要的，但我们继续往下看时，发现情况似乎又发生了变化。内存带宽决定了一个mini-batch以多快的速度呗覆盖以及分配去初始化GPU传输，但继续下一步时，我们会发现CPU到内存到GPU再回到内存这个过程存在瓶颈（直接内存访问）。之前提到过，我的机器带宽时51.2GB/s，但DMA带宽只有12GB/s。\n\nDMA的带宽速率与常规带宽有点关系，但在还是有细节上的差异。具体DMA带宽与内存之间的恩怨纠葛，有兴趣的朋友可以查看维基百科。本文还是让我们先了解下DMA是如何工作的吧。\n\n直接存储器（DMA）\n\nCPU及内存只能通过DMA才能与GPU通信。首先，内存与显存之间保留了特定的DMA传输缓存区；第二步，CPU把请求数据写入到CPU侧的缓冲区内；最后一步，保留的缓冲区被转移到显存中，而不需要CPU的协助。假设这样一个问题：你的PCI-E(2.0)带宽是8.0GB/s或者是（3.0）带宽15.75GB/s，那么你的传输峰值是否会被上述描述所决定？\n\n个人觉得并非如此。软件本身就扮演了一个很重要的角色。如果你使用了一个不错的传输算法，那么你同样会远离廉价且缓慢的内存。\n\nmini-batch异步分配\n\n一旦GPU完成了当前mini-batch上的计算，那么它就像立刻处理下一个数据块。当然你可以启动DMA传输，等待传输完成以便GPU能够继续工作。但是有一个更有效的方法：如果能提前准备好下一个数据块，这样你的GPU就不用等待了。这样做可以在不降低GPU性能的情况下，异步且轻松的完成传输任务。\n\n下图是有关mini-batch异步分配的CUDA代码：前两次的调用是在GPU开始前发出的；后两行调用是GPU完成后发出的。数据的传输在第二步传输前同步完成，因此不会在下批数据开始前使得GPU延时。\n\n\nImageNet2012的每个mini-batch大小为128，Alex Krishevsky卷积网以0.35秒为全BackProp通过。我们是否能在这个时间分配下批数据？\n\n我们取每个数据块为128，那么244*244*3规模的数据，总共大约0.085GB（4 * 128 * 244^2 * 3 * 1024^-3），再慢的内存速度也有6.4GB/s，换句话说每秒75个mini-batch！所以对于异步分配来说既是最慢的内存也足以满足深度学习的需要。如果你使用异步分配算法，就不需要购那么块的内存了。\n\n这个过程还间接说明了与CPU缓存的无关。你的CPU能多快的速度重写数据（在高速缓存中），以及多快为DMA的传输准备一个mini-batch（从缓存写入内存）已不那么重要了。因为在你的GPU请求下一个mini-batch的时候整个传输早已完成。所以大缓存实际上也没那么重要。\n\n所以最终的结论是内存的主频并不重要。买个廉价的就可以，故事结束。那么我们该买多大的呢？\n\n内存大小\n\n","slug":"dl-hware","published":0,"updated":"2018-03-30T09:52:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup8a000k3kna6qqiogdv","content":"<p>提到深度学习，想必大家都知道这是件计算密集型的事，第一个蒙B的困扰是：“攒一个适合做这件事的系统到底需不需要买一个多核高速的CPU…- -？”。“要想性能猛，就得花钱糟”，带着这样的想法，我们在搭建深度学习系统时，做的最糟糕的事就是在硬件上花了很多冤枉钱。这篇文章，我将告诉大家如果一步步的攒出一个性能高端大气，价格童叟无欺的牛X系统。</p>\n<p>那时，开始并行深度学习方面的工作，我需要搭建一个GPU集群。因为经验不足，所以我想：“得仔细挑选才行”。经管自己做了不少的研究，推理，但在选择硬件这件事上还是走了不少弯路。真是实践出真知，随着不断对集群的测试，才慢慢也抹出点门道。在这儿，我想把自己学到的东西分享出来，避免大家踩同样的坑。</p>\n<p>GPU</p>\n<p>这篇文章主要关于如何用GPU进行深度学习。如果此时，你正想搭建或者升级你的系统去做机器学习方面的事，那么我想告诉你：“GPU真是太tm重要了”。当然，GPU也只是深度学习应用程序的核心（它尤其在整体系统处理速度提高方面帮助，不容忽视）</p>\n<p><a href=\"https://timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/\" target=\"_blank\" rel=\"noopener\">在我之前的文章</a>中就详细讨论过GPU的选择，因为这是深度学习系统搭建中的致命一环。通常来说，如果你的预算比较羞涩的话，个人比较推荐去网上淘个GTX 680。当然如果你是土豪（别忘了留下联系方式，大家可以做朋友∩_∩），在小规模的卷积神经网络方面，我推荐GTX TITAN X。稍大一些规划的卷积神经网络，GTX 980（这也许是当时最好的GPU） 效果会更好。还是那句话，如果你想价格便宜点还是去网上淘吧！我之前一直在用GTX 580，但由于cuDNN库的更新（新版本在卷积速度方面提高的一大截），GTX 580已无法支持。如果你不拿它做卷积神经网络方面的事。个人觉得580还是一个不错的选择。</p>\n<p>下面这张图你能看出那块牛X，哪块令你蛋碎吗？<br><img src=\"\" alt=\"\"></p>\n<p>CPU</p>\n<p>为了能够对CPU做出明智的选择，我们首先得了解CPU与深度学习的关系，以及它到底在深度学习方面起什么作用。当你在GPU上运行你的深度学习算法时，这时的CPU到底在忙些什么？下面我将为你列这货在干的事：</p>\n<p>编写和读取代码中的变量<br>执行指令（比如调个函数啥的）<br>在GPU上初始化函数调用<br>样本数据mini-batch<br>把准备好的子集循环传给GPU</p>\n<p>注：如果你还不了解什么是mini-batch，<a href=\"https://testerhome.com/topics/10877\" target=\"_blank\" rel=\"noopener\">请点击此链接</a>。</p>\n<p>需要的CPU核心数</p>\n<p>当我用三个不同的库训练同样的神经网络时，CPU线程占用率都是100%（有时，另一个线程会在0到100%之前波动一会）。从这点可以看出，大部分到深度学习使用的库（实际上大部分软件程序）只使用一个线程运行。这意味着，一般情况下，多核CPU基本没啥用。但是如果你同时运行多个GPU或者使用像MPI这样的并行框架，多个程序的同时运行，多线程就显得很重要了。通常情况下，一个GPU使用一个CPU线程，但如果一个GPU可以使用两个线程，那会大大提高深度学习库的性能。由于这些库在一个核上运行，因为有时会异步调用函数，所以会使用第二个CPU线程。敲黑板了，知识点啊：现在CPU的每个核都会有多个CPU线程（在Intel的CPUs中这点尤为突出）因此单核的CPU通常已经足够。</p>\n<p>CPU and PCI-Express</p>\n<p>注：一些Haswell架构的GPU并不支持完整的40路PCI-E通道，如果你想搭建多GPU系统，确保你的CPU和主板支持PCI-E 3.0</p>\n<p>CPU 缓存大小</p>\n<p>下面我会从CPU到GPU运行的过程，做一个大致的分析，告诉你关于CPU缓存的故事。对整个过程有了透彻的理解，我们才能从中找到可能存在瓶颈的地方。</p>\n<p>当我们购买CPU时，CPU缓存常常被忽略（有木有看到缓存们悲愤的眼神’_’），但其实，他们在整体性能难题中扮演着非常重要的角色。CPU缓存时一组数量非常少的芯片内存，他们被集成在CPU中，用于执行高速的运算及指令操作。CPU中的缓存通常存在一个层级结构，从小而快（L1, L2）到大而慢（L3, L4）。作为一个程序猿，你应该知道它就像个哈希表，每条记录就是一个键值对。它可以对特殊的健做非常快速的查找：如果找到的健，就可以对其值进行快速的读写操作；如果未找到（缓存缺失），CPU将会去内存中查找，然后从那把值读取出来（这是一个非常缓慢的过程，如同你遇到了那个叫闪电的家伙）。上述过程我们可以看到高效的CPU缓存过程体系结构通常对CPU性能至关重要。</p>\n<p>CPU是如何确定他的缓存过程是一个非常复杂的议题。不过大致可以这样理解，重复使用频率高的变量，指令以及内存地址将会被缓存，其他的则不会。</p>\n<p>现在我们分析在深度学习中缓存的使用情况。数据在发送到GPU处理前，相同内存空间的数据以mini-batch块的形式被重复读取，那么这部分样本数据就可以存储在缓存中，当然这也取决于mini-batch的大小。我们取每个mini-batch块中128个样本，就好像我们有0.4MB的<a href=\"https://www.cnblogs.com/lizheng114/p/7439556.html\" target=\"_blank\" rel=\"noopener\">MNIST</a>和1.5MB的<a href=\"https://blog.csdn.net/zeuseign/article/details/72773342\" target=\"_blank\" rel=\"noopener\">CIFAR</a>，这适合大多数CPU缓存。但是，在<a href=\"https://baike.baidu.com/item/ImageNet/17752829?fr=aladdin\" target=\"_blank\" rel=\"noopener\">ImageNet</a>中，每个mini-batch却高达85MB的大小（4 <em> 128 </em> 244^2 <em> 3</em> 1024^-2），这个数量远远大于CPU最大量级的缓存（L3也只有那么有限的2，30MB）。</p>\n<p>通常情况下，样本数据都非常的大而无法放入缓存。每个新的mini-batch块都需要从内存中重新读区。所以无论怎样，都会不断的访问内存。</p>\n<p>也许你会想到，可以把样本数据都精确内存地址放入缓存，这样CPU在执行时就可以高速查找了。可真如我们所愿吗？如果这样，你必须把整个样本集都放入内存，否则查找时内存地址就会发生变化，这样依然无法依靠缓存提速，比如我们使用<a href=\"https://blog.csdn.net/ziv555/article/details/52116877\" target=\"_blank\" rel=\"noopener\">页锁内存</a>时。</p>\n<p>当然，代码中的变量和函数调用还是得益于高速缓存，但这些通常数量很少，很容易把它们放进CPU的L1缓存内。</p>\n<p>从上述内容中我们可以得出结论，在深度学习方面，CPU的缓存大小似乎没那么重要。下一节，我们会进一步分析验证这个结论。</p>\n<p>CPU时钟频率</p>\n<p>当人们形容CPU的快慢时，通常首先会想到时钟频率。4GHz比3.5GHz好，是这样吗？一般来说两个相同架构的处理器（比如都是 Ivy Bridge）可以这样看待，但是无法比较出两个处理器的优劣。它并不是一个好的衡量性能的度量衡。</p>\n<p>在深度学习领域，CPU的计算量其实非常的小（增加几个变量，计算一些布尔表达式，在GPU的计算过程中调用几个函数，当然这些事情都取决于CPU的核心时钟频率）。这么推理似乎也挺合理，但当我们运行代码时，却发现CPU的使用率高达100%，这么点操作使用率却如此之高，究竟问题出在哪？于是，我做了一些CPU降频的实验，发现问题所在。</p>\n<p>在CPU的使用率高达100%时，如果与其主频无关的话，应该与神马有关呢？答案也许是CPU缓存缺失：CPU一只非常忙碌的在访问内存，但同时CPU不得不等待内存的低频率，结果导致奇怪的忙等待状态。如果这个推论是正确的，那么CPU降频也不会导致性能的急剧下降，正如上图所示。</p>\n<p>当然，CPU还会执行一些其他的操作，例如：拷贝数据到mini-batches，把准备好的数据拷贝到GPU，但这些操作的速度依赖于内存频率，并不取决于CPU主频。那么现在我嘛来看看内存。</p>\n<p>内存频率</p>\n<p>CPU与内存以及与其他硬件的相互作用是一个强大复杂的过程。本文将此简化，来进行研究CPU到内存再到显存到整个过程。以便帮助大家更透彻的理解。</p>\n<p>CPU时钟与内存被纠缠在一起，CPU的主频决定了内存的最大频率，且这两者决定了你的CPU带宽，但是，通常来说内存自己决定了全部可用带宽，因为它的速度慢于CPU速率。你可以这样来计算带宽：bandwidth in GB/s = RAM clock in GHz <em> memory channels of CPU </em> 64 / 8</p>\n<p>这里的64是指64位CPU架构。通过计算我的处理器与内存带宽位51.2GB/s</p>\n<p>通常情况下，如果要拷贝大批量数据，那带宽与性能将息息相关。例如：CPU需要匹配内存的速度，从内存中获取大批量小块数据。这种情况，几乎适合所有的深度学习相关的程序。要么数据块大小可以放进缓存，那很容易从中获益，要么数据块太大而无法有效利用缓存。从上述例子中看到带宽比缓存似乎更加重要。</p>\n<p>那么，这与深度学习程序有什么关系呢？我刚才说过带宽似乎是很重要的，但我们继续往下看时，发现情况似乎又发生了变化。内存带宽决定了一个mini-batch以多快的速度呗覆盖以及分配去初始化GPU传输，但继续下一步时，我们会发现CPU到内存到GPU再回到内存这个过程存在瓶颈（直接内存访问）。之前提到过，我的机器带宽时51.2GB/s，但DMA带宽只有12GB/s。</p>\n<p>DMA的带宽速率与常规带宽有点关系，但在还是有细节上的差异。具体DMA带宽与内存之间的恩怨纠葛，有兴趣的朋友可以查看维基百科。本文还是让我们先了解下DMA是如何工作的吧。</p>\n<p>直接存储器（DMA）</p>\n<p>CPU及内存只能通过DMA才能与GPU通信。首先，内存与显存之间保留了特定的DMA传输缓存区；第二步，CPU把请求数据写入到CPU侧的缓冲区内；最后一步，保留的缓冲区被转移到显存中，而不需要CPU的协助。假设这样一个问题：你的PCI-E(2.0)带宽是8.0GB/s或者是（3.0）带宽15.75GB/s，那么你的传输峰值是否会被上述描述所决定？</p>\n<p>个人觉得并非如此。软件本身就扮演了一个很重要的角色。如果你使用了一个不错的传输算法，那么你同样会远离廉价且缓慢的内存。</p>\n<p>mini-batch异步分配</p>\n<p>一旦GPU完成了当前mini-batch上的计算，那么它就像立刻处理下一个数据块。当然你可以启动DMA传输，等待传输完成以便GPU能够继续工作。但是有一个更有效的方法：如果能提前准备好下一个数据块，这样你的GPU就不用等待了。这样做可以在不降低GPU性能的情况下，异步且轻松的完成传输任务。</p>\n<p>下图是有关mini-batch异步分配的CUDA代码：前两次的调用是在GPU开始前发出的；后两行调用是GPU完成后发出的。数据的传输在第二步传输前同步完成，因此不会在下批数据开始前使得GPU延时。</p>\n<p>ImageNet2012的每个mini-batch大小为128，Alex Krishevsky卷积网以0.35秒为全BackProp通过。我们是否能在这个时间分配下批数据？</p>\n<p>我们取每个数据块为128，那么244<em>244</em>3规模的数据，总共大约0.085GB（4 <em> 128 </em> 244^2 <em> 3 </em> 1024^-3），再慢的内存速度也有6.4GB/s，换句话说每秒75个mini-batch！所以对于异步分配来说既是最慢的内存也足以满足深度学习的需要。如果你使用异步分配算法，就不需要购那么块的内存了。</p>\n<p>这个过程还间接说明了与CPU缓存的无关。你的CPU能多快的速度重写数据（在高速缓存中），以及多快为DMA的传输准备一个mini-batch（从缓存写入内存）已不那么重要了。因为在你的GPU请求下一个mini-batch的时候整个传输早已完成。所以大缓存实际上也没那么重要。</p>\n<p>所以最终的结论是内存的主频并不重要。买个廉价的就可以，故事结束。那么我们该买多大的呢？</p>\n<p>内存大小</p>\n","site":{"data":{}},"excerpt":"","more":"<p>提到深度学习，想必大家都知道这是件计算密集型的事，第一个蒙B的困扰是：“攒一个适合做这件事的系统到底需不需要买一个多核高速的CPU…- -？”。“要想性能猛，就得花钱糟”，带着这样的想法，我们在搭建深度学习系统时，做的最糟糕的事就是在硬件上花了很多冤枉钱。这篇文章，我将告诉大家如果一步步的攒出一个性能高端大气，价格童叟无欺的牛X系统。</p>\n<p>那时，开始并行深度学习方面的工作，我需要搭建一个GPU集群。因为经验不足，所以我想：“得仔细挑选才行”。经管自己做了不少的研究，推理，但在选择硬件这件事上还是走了不少弯路。真是实践出真知，随着不断对集群的测试，才慢慢也抹出点门道。在这儿，我想把自己学到的东西分享出来，避免大家踩同样的坑。</p>\n<p>GPU</p>\n<p>这篇文章主要关于如何用GPU进行深度学习。如果此时，你正想搭建或者升级你的系统去做机器学习方面的事，那么我想告诉你：“GPU真是太tm重要了”。当然，GPU也只是深度学习应用程序的核心（它尤其在整体系统处理速度提高方面帮助，不容忽视）</p>\n<p><a href=\"https://timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/\" target=\"_blank\" rel=\"noopener\">在我之前的文章</a>中就详细讨论过GPU的选择，因为这是深度学习系统搭建中的致命一环。通常来说，如果你的预算比较羞涩的话，个人比较推荐去网上淘个GTX 680。当然如果你是土豪（别忘了留下联系方式，大家可以做朋友∩_∩），在小规模的卷积神经网络方面，我推荐GTX TITAN X。稍大一些规划的卷积神经网络，GTX 980（这也许是当时最好的GPU） 效果会更好。还是那句话，如果你想价格便宜点还是去网上淘吧！我之前一直在用GTX 580，但由于cuDNN库的更新（新版本在卷积速度方面提高的一大截），GTX 580已无法支持。如果你不拿它做卷积神经网络方面的事。个人觉得580还是一个不错的选择。</p>\n<p>下面这张图你能看出那块牛X，哪块令你蛋碎吗？<br><img src=\"\" alt=\"\"></p>\n<p>CPU</p>\n<p>为了能够对CPU做出明智的选择，我们首先得了解CPU与深度学习的关系，以及它到底在深度学习方面起什么作用。当你在GPU上运行你的深度学习算法时，这时的CPU到底在忙些什么？下面我将为你列这货在干的事：</p>\n<p>编写和读取代码中的变量<br>执行指令（比如调个函数啥的）<br>在GPU上初始化函数调用<br>样本数据mini-batch<br>把准备好的子集循环传给GPU</p>\n<p>注：如果你还不了解什么是mini-batch，<a href=\"https://testerhome.com/topics/10877\" target=\"_blank\" rel=\"noopener\">请点击此链接</a>。</p>\n<p>需要的CPU核心数</p>\n<p>当我用三个不同的库训练同样的神经网络时，CPU线程占用率都是100%（有时，另一个线程会在0到100%之前波动一会）。从这点可以看出，大部分到深度学习使用的库（实际上大部分软件程序）只使用一个线程运行。这意味着，一般情况下，多核CPU基本没啥用。但是如果你同时运行多个GPU或者使用像MPI这样的并行框架，多个程序的同时运行，多线程就显得很重要了。通常情况下，一个GPU使用一个CPU线程，但如果一个GPU可以使用两个线程，那会大大提高深度学习库的性能。由于这些库在一个核上运行，因为有时会异步调用函数，所以会使用第二个CPU线程。敲黑板了，知识点啊：现在CPU的每个核都会有多个CPU线程（在Intel的CPUs中这点尤为突出）因此单核的CPU通常已经足够。</p>\n<p>CPU and PCI-Express</p>\n<p>注：一些Haswell架构的GPU并不支持完整的40路PCI-E通道，如果你想搭建多GPU系统，确保你的CPU和主板支持PCI-E 3.0</p>\n<p>CPU 缓存大小</p>\n<p>下面我会从CPU到GPU运行的过程，做一个大致的分析，告诉你关于CPU缓存的故事。对整个过程有了透彻的理解，我们才能从中找到可能存在瓶颈的地方。</p>\n<p>当我们购买CPU时，CPU缓存常常被忽略（有木有看到缓存们悲愤的眼神’_’），但其实，他们在整体性能难题中扮演着非常重要的角色。CPU缓存时一组数量非常少的芯片内存，他们被集成在CPU中，用于执行高速的运算及指令操作。CPU中的缓存通常存在一个层级结构，从小而快（L1, L2）到大而慢（L3, L4）。作为一个程序猿，你应该知道它就像个哈希表，每条记录就是一个键值对。它可以对特殊的健做非常快速的查找：如果找到的健，就可以对其值进行快速的读写操作；如果未找到（缓存缺失），CPU将会去内存中查找，然后从那把值读取出来（这是一个非常缓慢的过程，如同你遇到了那个叫闪电的家伙）。上述过程我们可以看到高效的CPU缓存过程体系结构通常对CPU性能至关重要。</p>\n<p>CPU是如何确定他的缓存过程是一个非常复杂的议题。不过大致可以这样理解，重复使用频率高的变量，指令以及内存地址将会被缓存，其他的则不会。</p>\n<p>现在我们分析在深度学习中缓存的使用情况。数据在发送到GPU处理前，相同内存空间的数据以mini-batch块的形式被重复读取，那么这部分样本数据就可以存储在缓存中，当然这也取决于mini-batch的大小。我们取每个mini-batch块中128个样本，就好像我们有0.4MB的<a href=\"https://www.cnblogs.com/lizheng114/p/7439556.html\" target=\"_blank\" rel=\"noopener\">MNIST</a>和1.5MB的<a href=\"https://blog.csdn.net/zeuseign/article/details/72773342\" target=\"_blank\" rel=\"noopener\">CIFAR</a>，这适合大多数CPU缓存。但是，在<a href=\"https://baike.baidu.com/item/ImageNet/17752829?fr=aladdin\" target=\"_blank\" rel=\"noopener\">ImageNet</a>中，每个mini-batch却高达85MB的大小（4 <em> 128 </em> 244^2 <em> 3</em> 1024^-2），这个数量远远大于CPU最大量级的缓存（L3也只有那么有限的2，30MB）。</p>\n<p>通常情况下，样本数据都非常的大而无法放入缓存。每个新的mini-batch块都需要从内存中重新读区。所以无论怎样，都会不断的访问内存。</p>\n<p>也许你会想到，可以把样本数据都精确内存地址放入缓存，这样CPU在执行时就可以高速查找了。可真如我们所愿吗？如果这样，你必须把整个样本集都放入内存，否则查找时内存地址就会发生变化，这样依然无法依靠缓存提速，比如我们使用<a href=\"https://blog.csdn.net/ziv555/article/details/52116877\" target=\"_blank\" rel=\"noopener\">页锁内存</a>时。</p>\n<p>当然，代码中的变量和函数调用还是得益于高速缓存，但这些通常数量很少，很容易把它们放进CPU的L1缓存内。</p>\n<p>从上述内容中我们可以得出结论，在深度学习方面，CPU的缓存大小似乎没那么重要。下一节，我们会进一步分析验证这个结论。</p>\n<p>CPU时钟频率</p>\n<p>当人们形容CPU的快慢时，通常首先会想到时钟频率。4GHz比3.5GHz好，是这样吗？一般来说两个相同架构的处理器（比如都是 Ivy Bridge）可以这样看待，但是无法比较出两个处理器的优劣。它并不是一个好的衡量性能的度量衡。</p>\n<p>在深度学习领域，CPU的计算量其实非常的小（增加几个变量，计算一些布尔表达式，在GPU的计算过程中调用几个函数，当然这些事情都取决于CPU的核心时钟频率）。这么推理似乎也挺合理，但当我们运行代码时，却发现CPU的使用率高达100%，这么点操作使用率却如此之高，究竟问题出在哪？于是，我做了一些CPU降频的实验，发现问题所在。</p>\n<p>在CPU的使用率高达100%时，如果与其主频无关的话，应该与神马有关呢？答案也许是CPU缓存缺失：CPU一只非常忙碌的在访问内存，但同时CPU不得不等待内存的低频率，结果导致奇怪的忙等待状态。如果这个推论是正确的，那么CPU降频也不会导致性能的急剧下降，正如上图所示。</p>\n<p>当然，CPU还会执行一些其他的操作，例如：拷贝数据到mini-batches，把准备好的数据拷贝到GPU，但这些操作的速度依赖于内存频率，并不取决于CPU主频。那么现在我嘛来看看内存。</p>\n<p>内存频率</p>\n<p>CPU与内存以及与其他硬件的相互作用是一个强大复杂的过程。本文将此简化，来进行研究CPU到内存再到显存到整个过程。以便帮助大家更透彻的理解。</p>\n<p>CPU时钟与内存被纠缠在一起，CPU的主频决定了内存的最大频率，且这两者决定了你的CPU带宽，但是，通常来说内存自己决定了全部可用带宽，因为它的速度慢于CPU速率。你可以这样来计算带宽：bandwidth in GB/s = RAM clock in GHz <em> memory channels of CPU </em> 64 / 8</p>\n<p>这里的64是指64位CPU架构。通过计算我的处理器与内存带宽位51.2GB/s</p>\n<p>通常情况下，如果要拷贝大批量数据，那带宽与性能将息息相关。例如：CPU需要匹配内存的速度，从内存中获取大批量小块数据。这种情况，几乎适合所有的深度学习相关的程序。要么数据块大小可以放进缓存，那很容易从中获益，要么数据块太大而无法有效利用缓存。从上述例子中看到带宽比缓存似乎更加重要。</p>\n<p>那么，这与深度学习程序有什么关系呢？我刚才说过带宽似乎是很重要的，但我们继续往下看时，发现情况似乎又发生了变化。内存带宽决定了一个mini-batch以多快的速度呗覆盖以及分配去初始化GPU传输，但继续下一步时，我们会发现CPU到内存到GPU再回到内存这个过程存在瓶颈（直接内存访问）。之前提到过，我的机器带宽时51.2GB/s，但DMA带宽只有12GB/s。</p>\n<p>DMA的带宽速率与常规带宽有点关系，但在还是有细节上的差异。具体DMA带宽与内存之间的恩怨纠葛，有兴趣的朋友可以查看维基百科。本文还是让我们先了解下DMA是如何工作的吧。</p>\n<p>直接存储器（DMA）</p>\n<p>CPU及内存只能通过DMA才能与GPU通信。首先，内存与显存之间保留了特定的DMA传输缓存区；第二步，CPU把请求数据写入到CPU侧的缓冲区内；最后一步，保留的缓冲区被转移到显存中，而不需要CPU的协助。假设这样一个问题：你的PCI-E(2.0)带宽是8.0GB/s或者是（3.0）带宽15.75GB/s，那么你的传输峰值是否会被上述描述所决定？</p>\n<p>个人觉得并非如此。软件本身就扮演了一个很重要的角色。如果你使用了一个不错的传输算法，那么你同样会远离廉价且缓慢的内存。</p>\n<p>mini-batch异步分配</p>\n<p>一旦GPU完成了当前mini-batch上的计算，那么它就像立刻处理下一个数据块。当然你可以启动DMA传输，等待传输完成以便GPU能够继续工作。但是有一个更有效的方法：如果能提前准备好下一个数据块，这样你的GPU就不用等待了。这样做可以在不降低GPU性能的情况下，异步且轻松的完成传输任务。</p>\n<p>下图是有关mini-batch异步分配的CUDA代码：前两次的调用是在GPU开始前发出的；后两行调用是GPU完成后发出的。数据的传输在第二步传输前同步完成，因此不会在下批数据开始前使得GPU延时。</p>\n<p>ImageNet2012的每个mini-batch大小为128，Alex Krishevsky卷积网以0.35秒为全BackProp通过。我们是否能在这个时间分配下批数据？</p>\n<p>我们取每个数据块为128，那么244<em>244</em>3规模的数据，总共大约0.085GB（4 <em> 128 </em> 244^2 <em> 3 </em> 1024^-3），再慢的内存速度也有6.4GB/s，换句话说每秒75个mini-batch！所以对于异步分配来说既是最慢的内存也足以满足深度学习的需要。如果你使用异步分配算法，就不需要购那么块的内存了。</p>\n<p>这个过程还间接说明了与CPU缓存的无关。你的CPU能多快的速度重写数据（在高速缓存中），以及多快为DMA的传输准备一个mini-batch（从缓存写入内存）已不那么重要了。因为在你的GPU请求下一个mini-batch的时候整个传输早已完成。所以大缓存实际上也没那么重要。</p>\n<p>所以最终的结论是内存的主频并不重要。买个廉价的就可以，故事结束。那么我们该买多大的呢？</p>\n<p>内存大小</p>\n"},{"title":"Spark 部署","date":"2018-03-28T02:24:07.000Z","_content":"Spark是内存式计算引擎，为了让我们的计算速度更快，计算更多复杂的模型。这篇文章我们部署它，之后我们编写的代码都将跑在Spark中。\n\n# Quick Start\n\n## <font color=#c00>下载安装</font>\n\n登陆[官方网站](http://spark.apache.org/)，下载版本为2.2.1，下载完成后解压（文件目录还是统一放在/opt路径下）并进入该文件夹，运行如下命令：\n\n<font color=#c00>注：从2.0版本开始，缺省支持Scala2.11版本，如果你习惯使用其他版本的Scala，请查看官网</font>\n\n``` bash\ncp conf/spark-env.sh.template conf/spark-env.sh\n```\n\n<!--more-->\n\n## <font color=#c00>环境变量配置</font>\n\n在conf/spark-env.sh文件中添加如下配置项：\n\n### Java环境变量\n\n``` bash\nexport JAVA_HOME=$JAVA_HOME\n```\n\n<font color=#999>如果未设置Java环境变量，请自行添加就好。</font>\n\n### Client模式运行时，所需的参数环境变量\n\n``` bash\n# yarn集群中，最多能够同时启动的Executors的实例个数。\n# yarn中实际能够启动的最大Executors的数量会小于等于该值。如果不能确定最大能够启动的Executors数量，建议将该值先设置的足够大。\nexport SPARK_ EXECUTOR_INSTANCES=9\n\n# 该参数为设置每个Executor能够使用的CPU核数\n# yarn集群能够最多并行的task数量为SPARK_EXECUTOR_INSTANCES ＊ SPARK_EXECUTOR_CORES\nexport SPARK_EXECUTOR_CORES=2\n\n# 该参数设置的是每个Executor分配的内存的数量。\n# 需要注意的是，该内存数量是SPARK_EXECUTOR_CORES中设置的内核数共用的内存数量。\nexport SPARK_EXECUTOR_MEMORY=8G\n\n#该参数设置的是DRIVER分配的内存的大小。\n#也就是执行start-thriftserver.sh机器上分配给thriftserver的内存大小。\nexport SPARK_DRIVER_MEMORY=8G\n```\n\n\n### ZooKeeper环境变量\n\n``` bash\nexport SPARK_DAEMON_JAVA_OPTS=\"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node0的IP:2181,node2的IP:2181,node3IP:2181\"\n```\n\n### 其他环境变量\n\n``` bash\nexport HADOOP_CONF_DIR=/opt/hadoop-2.7.4/etc/hadoop\nexport YARN_CONF_DIR=/opt/hadoop-2.7.4/etc/hadoop\nexport SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7\nexport SPARK_JAR=$SPARK_HOME/jars/*.jar\nexport PATH=$SPARK_HOME/bin:$PATH\n```\n\n## <font color=#c00>从属节点配置</font>\n\n### 复制文件\n\n``` bash\ncp conf/slaves.template conf/slaves\n```\n\n### 配置地址\n\n打开slaves文件，填写如下内容：\n\n``` bash\nnode1的IP\nnode2的IP\nnode3的IP\n```\n\n## <font color=#c00>测试</font>\n\n我们用spark文件夹中自带的求Pi例子做测试\n\n### 单机模式（本地模式）\n\n``` bash\nbin/spark-submit --master yarn-client --class org.apache.spark.examples.SparkPi examples/jars/spark-examples_2.11-2.2.0.jar\n```\n\n### 集群模式\n\n``` bash\nbin/spark-submit --master yarn-cluster --class org.apache.spark.examples.SparkPi  examples/jars/spark-examples_2.11-2.2.0.jar\n```\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://spark.apache.org/docs/2.2.1/)，文档版本2.2.1\n\n## <font color=#c00>小结</font>\n\n完成这篇的配置后，我们可以做大部分数据挖掘工作了，但数据只能使用csv文件，为了让我们可以使用数据库，快速查找，快速计算，快速存取。下篇文件我们开始[《HBase 部署》](/ai/hadoop-hba/)\n\n本系列文章[《目录》](/ai/hadoop-start/)\n","source":"_posts/hadoop-spk.md","raw":"---\ntitle: Spark 部署\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-03-28 10:24:07\n---\nSpark是内存式计算引擎，为了让我们的计算速度更快，计算更多复杂的模型。这篇文章我们部署它，之后我们编写的代码都将跑在Spark中。\n\n# Quick Start\n\n## <font color=#c00>下载安装</font>\n\n登陆[官方网站](http://spark.apache.org/)，下载版本为2.2.1，下载完成后解压（文件目录还是统一放在/opt路径下）并进入该文件夹，运行如下命令：\n\n<font color=#c00>注：从2.0版本开始，缺省支持Scala2.11版本，如果你习惯使用其他版本的Scala，请查看官网</font>\n\n``` bash\ncp conf/spark-env.sh.template conf/spark-env.sh\n```\n\n<!--more-->\n\n## <font color=#c00>环境变量配置</font>\n\n在conf/spark-env.sh文件中添加如下配置项：\n\n### Java环境变量\n\n``` bash\nexport JAVA_HOME=$JAVA_HOME\n```\n\n<font color=#999>如果未设置Java环境变量，请自行添加就好。</font>\n\n### Client模式运行时，所需的参数环境变量\n\n``` bash\n# yarn集群中，最多能够同时启动的Executors的实例个数。\n# yarn中实际能够启动的最大Executors的数量会小于等于该值。如果不能确定最大能够启动的Executors数量，建议将该值先设置的足够大。\nexport SPARK_ EXECUTOR_INSTANCES=9\n\n# 该参数为设置每个Executor能够使用的CPU核数\n# yarn集群能够最多并行的task数量为SPARK_EXECUTOR_INSTANCES ＊ SPARK_EXECUTOR_CORES\nexport SPARK_EXECUTOR_CORES=2\n\n# 该参数设置的是每个Executor分配的内存的数量。\n# 需要注意的是，该内存数量是SPARK_EXECUTOR_CORES中设置的内核数共用的内存数量。\nexport SPARK_EXECUTOR_MEMORY=8G\n\n#该参数设置的是DRIVER分配的内存的大小。\n#也就是执行start-thriftserver.sh机器上分配给thriftserver的内存大小。\nexport SPARK_DRIVER_MEMORY=8G\n```\n\n\n### ZooKeeper环境变量\n\n``` bash\nexport SPARK_DAEMON_JAVA_OPTS=\"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node0的IP:2181,node2的IP:2181,node3IP:2181\"\n```\n\n### 其他环境变量\n\n``` bash\nexport HADOOP_CONF_DIR=/opt/hadoop-2.7.4/etc/hadoop\nexport YARN_CONF_DIR=/opt/hadoop-2.7.4/etc/hadoop\nexport SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7\nexport SPARK_JAR=$SPARK_HOME/jars/*.jar\nexport PATH=$SPARK_HOME/bin:$PATH\n```\n\n## <font color=#c00>从属节点配置</font>\n\n### 复制文件\n\n``` bash\ncp conf/slaves.template conf/slaves\n```\n\n### 配置地址\n\n打开slaves文件，填写如下内容：\n\n``` bash\nnode1的IP\nnode2的IP\nnode3的IP\n```\n\n## <font color=#c00>测试</font>\n\n我们用spark文件夹中自带的求Pi例子做测试\n\n### 单机模式（本地模式）\n\n``` bash\nbin/spark-submit --master yarn-client --class org.apache.spark.examples.SparkPi examples/jars/spark-examples_2.11-2.2.0.jar\n```\n\n### 集群模式\n\n``` bash\nbin/spark-submit --master yarn-cluster --class org.apache.spark.examples.SparkPi  examples/jars/spark-examples_2.11-2.2.0.jar\n```\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://spark.apache.org/docs/2.2.1/)，文档版本2.2.1\n\n## <font color=#c00>小结</font>\n\n完成这篇的配置后，我们可以做大部分数据挖掘工作了，但数据只能使用csv文件，为了让我们可以使用数据库，快速查找，快速计算，快速存取。下篇文件我们开始[《HBase 部署》](/ai/hadoop-hba/)\n\n本系列文章[《目录》](/ai/hadoop-start/)\n","slug":"hadoop-spk","published":1,"updated":"2018-03-30T09:52:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup8c000n3knar9v3drdv","content":"<p>Spark是内存式计算引擎，为了让我们的计算速度更快，计算更多复杂的模型。这篇文章我们部署它，之后我们编写的代码都将跑在Spark中。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"下载安装\"><a href=\"#下载安装\" class=\"headerlink\" title=\"下载安装\"></a><font color=\"#c00\">下载安装</font></h2><p>登陆<a href=\"http://spark.apache.org/\" target=\"_blank\" rel=\"noopener\">官方网站</a>，下载版本为2.2.1，下载完成后解压（文件目录还是统一放在/opt路径下）并进入该文件夹，运行如下命令：</p>\n<font color=\"#c00\">注：从2.0版本开始，缺省支持Scala2.11版本，如果你习惯使用其他版本的Scala，请查看官网</font>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp conf/spark-env.sh.template conf/spark-env.sh</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<h2 id=\"环境变量配置\"><a href=\"#环境变量配置\" class=\"headerlink\" title=\"环境变量配置\"></a><font color=\"#c00\">环境变量配置</font></h2><p>在conf/spark-env.sh文件中添加如下配置项：</p>\n<h3 id=\"Java环境变量\"><a href=\"#Java环境变量\" class=\"headerlink\" title=\"Java环境变量\"></a>Java环境变量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=<span class=\"variable\">$JAVA_HOME</span></span><br></pre></td></tr></table></figure>\n<font color=\"#999\">如果未设置Java环境变量，请自行添加就好。</font>\n\n<h3 id=\"Client模式运行时，所需的参数环境变量\"><a href=\"#Client模式运行时，所需的参数环境变量\" class=\"headerlink\" title=\"Client模式运行时，所需的参数环境变量\"></a>Client模式运行时，所需的参数环境变量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># yarn集群中，最多能够同时启动的Executors的实例个数。</span></span><br><span class=\"line\"><span class=\"comment\"># yarn中实际能够启动的最大Executors的数量会小于等于该值。如果不能确定最大能够启动的Executors数量，建议将该值先设置的足够大。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_ EXECUTOR_INSTANCES=9</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 该参数为设置每个Executor能够使用的CPU核数</span></span><br><span class=\"line\"><span class=\"comment\"># yarn集群能够最多并行的task数量为SPARK_EXECUTOR_INSTANCES ＊ SPARK_EXECUTOR_CORES</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_EXECUTOR_CORES=2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 该参数设置的是每个Executor分配的内存的数量。</span></span><br><span class=\"line\"><span class=\"comment\"># 需要注意的是，该内存数量是SPARK_EXECUTOR_CORES中设置的内核数共用的内存数量。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_EXECUTOR_MEMORY=8G</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#该参数设置的是DRIVER分配的内存的大小。</span></span><br><span class=\"line\"><span class=\"comment\">#也就是执行start-thriftserver.sh机器上分配给thriftserver的内存大小。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_DRIVER_MEMORY=8G</span><br></pre></td></tr></table></figure>\n<h3 id=\"ZooKeeper环境变量\"><a href=\"#ZooKeeper环境变量\" class=\"headerlink\" title=\"ZooKeeper环境变量\"></a>ZooKeeper环境变量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> SPARK_DAEMON_JAVA_OPTS=<span class=\"string\">\"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node0的IP:2181,node2的IP:2181,node3IP:2181\"</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"其他环境变量\"><a href=\"#其他环境变量\" class=\"headerlink\" title=\"其他环境变量\"></a>其他环境变量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_CONF_DIR=/opt/hadoop-2.7.4/etc/hadoop</span><br><span class=\"line\"><span class=\"built_in\">export</span> YARN_CONF_DIR=/opt/hadoop-2.7.4/etc/hadoop</span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7</span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_JAR=<span class=\"variable\">$SPARK_HOME</span>/jars/*.jar</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$SPARK_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"从属节点配置\"><a href=\"#从属节点配置\" class=\"headerlink\" title=\"从属节点配置\"></a><font color=\"#c00\">从属节点配置</font></h2><h3 id=\"复制文件\"><a href=\"#复制文件\" class=\"headerlink\" title=\"复制文件\"></a>复制文件</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp conf/slaves.template conf/slaves</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置地址\"><a href=\"#配置地址\" class=\"headerlink\" title=\"配置地址\"></a>配置地址</h3><p>打开slaves文件，填写如下内容：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node1的IP</span><br><span class=\"line\">node2的IP</span><br><span class=\"line\">node3的IP</span><br></pre></td></tr></table></figure>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a><font color=\"#c00\">测试</font></h2><p>我们用spark文件夹中自带的求Pi例子做测试</p>\n<h3 id=\"单机模式（本地模式）\"><a href=\"#单机模式（本地模式）\" class=\"headerlink\" title=\"单机模式（本地模式）\"></a>单机模式（本地模式）</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/spark-submit --master yarn-client --class org.apache.spark.examples.SparkPi examples/jars/spark-examples_2.11-2.2.0.jar</span><br></pre></td></tr></table></figure>\n<h3 id=\"集群模式\"><a href=\"#集群模式\" class=\"headerlink\" title=\"集群模式\"></a>集群模式</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/spark-submit --master yarn-cluster --class org.apache.spark.examples.SparkPi  examples/jars/spark-examples_2.11-2.2.0.jar</span><br></pre></td></tr></table></figure>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://spark.apache.org/docs/2.2.1/\" target=\"_blank\" rel=\"noopener\">官方文档</a>，文档版本2.2.1</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成这篇的配置后，我们可以做大部分数据挖掘工作了，但数据只能使用csv文件，为了让我们可以使用数据库，快速查找，快速计算，快速存取。下篇文件我们开始<a href=\"/ai/hadoop-hba/\">《HBase 部署》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>\n","site":{"data":{}},"excerpt":"<p>Spark是内存式计算引擎，为了让我们的计算速度更快，计算更多复杂的模型。这篇文章我们部署它，之后我们编写的代码都将跑在Spark中。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"下载安装\"><a href=\"#下载安装\" class=\"headerlink\" title=\"下载安装\"></a><font color=\"#c00\">下载安装</font></h2><p>登陆<a href=\"http://spark.apache.org/\" target=\"_blank\" rel=\"noopener\">官方网站</a>，下载版本为2.2.1，下载完成后解压（文件目录还是统一放在/opt路径下）并进入该文件夹，运行如下命令：</p>\n<font color=\"#c00\">注：从2.0版本开始，缺省支持Scala2.11版本，如果你习惯使用其他版本的Scala，请查看官网</font>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp conf/spark-env.sh.template conf/spark-env.sh</span><br></pre></td></tr></table></figure>","more":"<h2 id=\"环境变量配置\"><a href=\"#环境变量配置\" class=\"headerlink\" title=\"环境变量配置\"></a><font color=\"#c00\">环境变量配置</font></h2><p>在conf/spark-env.sh文件中添加如下配置项：</p>\n<h3 id=\"Java环境变量\"><a href=\"#Java环境变量\" class=\"headerlink\" title=\"Java环境变量\"></a>Java环境变量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=<span class=\"variable\">$JAVA_HOME</span></span><br></pre></td></tr></table></figure>\n<font color=\"#999\">如果未设置Java环境变量，请自行添加就好。</font>\n\n<h3 id=\"Client模式运行时，所需的参数环境变量\"><a href=\"#Client模式运行时，所需的参数环境变量\" class=\"headerlink\" title=\"Client模式运行时，所需的参数环境变量\"></a>Client模式运行时，所需的参数环境变量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># yarn集群中，最多能够同时启动的Executors的实例个数。</span></span><br><span class=\"line\"><span class=\"comment\"># yarn中实际能够启动的最大Executors的数量会小于等于该值。如果不能确定最大能够启动的Executors数量，建议将该值先设置的足够大。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_ EXECUTOR_INSTANCES=9</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 该参数为设置每个Executor能够使用的CPU核数</span></span><br><span class=\"line\"><span class=\"comment\"># yarn集群能够最多并行的task数量为SPARK_EXECUTOR_INSTANCES ＊ SPARK_EXECUTOR_CORES</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_EXECUTOR_CORES=2</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 该参数设置的是每个Executor分配的内存的数量。</span></span><br><span class=\"line\"><span class=\"comment\"># 需要注意的是，该内存数量是SPARK_EXECUTOR_CORES中设置的内核数共用的内存数量。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_EXECUTOR_MEMORY=8G</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#该参数设置的是DRIVER分配的内存的大小。</span></span><br><span class=\"line\"><span class=\"comment\">#也就是执行start-thriftserver.sh机器上分配给thriftserver的内存大小。</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_DRIVER_MEMORY=8G</span><br></pre></td></tr></table></figure>\n<h3 id=\"ZooKeeper环境变量\"><a href=\"#ZooKeeper环境变量\" class=\"headerlink\" title=\"ZooKeeper环境变量\"></a>ZooKeeper环境变量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> SPARK_DAEMON_JAVA_OPTS=<span class=\"string\">\"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node0的IP:2181,node2的IP:2181,node3IP:2181\"</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"其他环境变量\"><a href=\"#其他环境变量\" class=\"headerlink\" title=\"其他环境变量\"></a>其他环境变量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_CONF_DIR=/opt/hadoop-2.7.4/etc/hadoop</span><br><span class=\"line\"><span class=\"built_in\">export</span> YARN_CONF_DIR=/opt/hadoop-2.7.4/etc/hadoop</span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_HOME=/opt/spark-2.2.0-bin-hadoop2.7</span><br><span class=\"line\"><span class=\"built_in\">export</span> SPARK_JAR=<span class=\"variable\">$SPARK_HOME</span>/jars/*.jar</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$SPARK_HOME</span>/bin:<span class=\"variable\">$PATH</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"从属节点配置\"><a href=\"#从属节点配置\" class=\"headerlink\" title=\"从属节点配置\"></a><font color=\"#c00\">从属节点配置</font></h2><h3 id=\"复制文件\"><a href=\"#复制文件\" class=\"headerlink\" title=\"复制文件\"></a>复制文件</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp conf/slaves.template conf/slaves</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置地址\"><a href=\"#配置地址\" class=\"headerlink\" title=\"配置地址\"></a>配置地址</h3><p>打开slaves文件，填写如下内容：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node1的IP</span><br><span class=\"line\">node2的IP</span><br><span class=\"line\">node3的IP</span><br></pre></td></tr></table></figure>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a><font color=\"#c00\">测试</font></h2><p>我们用spark文件夹中自带的求Pi例子做测试</p>\n<h3 id=\"单机模式（本地模式）\"><a href=\"#单机模式（本地模式）\" class=\"headerlink\" title=\"单机模式（本地模式）\"></a>单机模式（本地模式）</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/spark-submit --master yarn-client --class org.apache.spark.examples.SparkPi examples/jars/spark-examples_2.11-2.2.0.jar</span><br></pre></td></tr></table></figure>\n<h3 id=\"集群模式\"><a href=\"#集群模式\" class=\"headerlink\" title=\"集群模式\"></a>集群模式</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/spark-submit --master yarn-cluster --class org.apache.spark.examples.SparkPi  examples/jars/spark-examples_2.11-2.2.0.jar</span><br></pre></td></tr></table></figure>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://spark.apache.org/docs/2.2.1/\" target=\"_blank\" rel=\"noopener\">官方文档</a>，文档版本2.2.1</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成这篇的配置后，我们可以做大部分数据挖掘工作了，但数据只能使用csv文件，为了让我们可以使用数据库，快速查找，快速计算，快速存取。下篇文件我们开始<a href=\"/ai/hadoop-hba/\">《HBase 部署》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>"},{"title":"Hadoop 使用[系列]","date":"2018-04-03T07:37:03.000Z","_content":"## 前言\n\n这一系列的文章主要介绍，HDFS，Spark，HBase在Jupyter中该如何使用，如何编写我们的程序。\n\n## 目录\n\n- #### [Word Count](/ai/hadoop-wct/)\n\n\n<!--more-->\n","source":"_posts/hadoop-use.md","raw":"---\ntitle: Hadoop 使用[系列]\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-04-03 15:37:03\n---\n## 前言\n\n这一系列的文章主要介绍，HDFS，Spark，HBase在Jupyter中该如何使用，如何编写我们的程序。\n\n## 目录\n\n- #### [Word Count](/ai/hadoop-wct/)\n\n\n<!--more-->\n","slug":"hadoop-use","published":1,"updated":"2018-04-03T09:32:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup8e000r3knaywn9xh01","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>这一系列的文章主要介绍，HDFS，Spark，HBase在Jupyter中该如何使用，如何编写我们的程序。</p>\n<h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><ul>\n<li><h4 id=\"Word-Count\"><a href=\"#Word-Count\" class=\"headerlink\" title=\"Word Count\"></a><a href=\"/ai/hadoop-wct/\">Word Count</a></h4></li>\n</ul>\n<a id=\"more\"></a>\n","site":{"data":{}},"excerpt":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>这一系列的文章主要介绍，HDFS，Spark，HBase在Jupyter中该如何使用，如何编写我们的程序。</p>\n<h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><ul>\n<li><h4 id=\"Word-Count\"><a href=\"#Word-Count\" class=\"headerlink\" title=\"Word Count\"></a><a href=\"/ai/hadoop-wct/\">Word Count</a></h4></li>\n</ul>","more":""},{"title":"Word Count","date":"2018-04-03T07:49:39.000Z","_content":"Word Count程序就像初学每种语言时要写的Hello World一样。他可以用来统计大段文章（可能是一本朗文字典那么厚的书）中相同单词出现的次数。当然除了统计相同词数量外，我们经常拿它来统计网站中大量的PV，UV。\n\n所有的Spark程序可以在local模式下运行，也可以在cluster模式下运行。因为是第一次应用，我们会分别讲解这两种模式。以后的程序基本都是运行在集群模式。\n\nSpark程序可以使用Python，Scala，Java，R编写，推荐程度Python最高，R最低。按道理说整个Spark都是Scala开发的，使用Scala是最好的选择，的确是这样的。但是由于Python在整个机器学习领域的热度越来越热，为了方便大家之后开发其他程序（比如模式识别，语音识别等等），这里推荐使用Python，当然其他语言版本我们会大概讲下，本文我们看看Python，Scala，Java三种语言分别是如何实现World Count程序的，废话不多说，下面上主菜...\n\n<!--more-->\n\n# Quick Start\n\n## <font color=#c00>Python</font>\n\n<font color=#c00>注：本文使用的语言是Python2.7，编辑器Jupyter Notebook</font>\n\n### 本地模式\n\n``` python\nimport os\nfrom pyspark import SparkConf, SparkContext\n\n# 准备好的数据本地路径\ninput_file = \"file:///home/test/jupyter_notebook/wordcount/data_wc_py\"\n\n# 计算完成后统计结果存放路径\nout_dir = \"file:///home/test/jupyter_notebook/wordcount/wjh\"\n\n# 判断spark上下文是否已释放\ntry:  \n    sc.stop()  \nexcept:  \n    pass \n\n# 设置spark运行模式以及任务名称\nconf = SparkConf().setMaster(\"local\").setAppName(\"word_count_local\")\n\n# 按照设置，获取sprak上下文\nsc = SparkContext(conf=conf)\n\n# 按行读取数据，生成类数组\nlines = sc.textFile(input_file)\n\n# 这里使用了lambda表达式\n# 第一个表达式，将每行按空格把行转换成单词\n# 第二个把每一个单词转换成元组（单词，1）\n# 最后一个将单词相同的元组做累加\n# 最后把（单词，累加值）返回给counts数组\ncounts = lines.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n\n# 把最后的结果集保存在文件中\ncounts.saveAsTextFile(out_dir) \n\n# 释放spark上下文\nsc.stop()\n```\n\n<font color=#c00>注：只有本地模式才能在计算后，直接访问到存储结果集文件。</font>\n\n### 集群模式\n\n在讲这段程序前，讲点其他有的没的。首先，Jupyter是一个网页程序，尤其团队使用时，它被不同的人同时使用，所以为了代码管理需要，每个人可以在Jupyter的根目录建立自己的工作文件目录，自己编写的程序都放在自己工作目录下，这样可以有效管理自己的代码。\n\n第二，集群模式下运行时，我们可以在用8088端口访问浏览器，查看我们提交的计算任务进度，计算日志等。如下图，我们只要提交任务，都可以在这里看到，蓝框中是你为本次任务设置任务名，我不推荐这样命名，之前说过了因为同时间会有不止一人提交任务，如果大家都按程序目的命名，你很难分辨哪个才是你自己提交的。所以我推荐使用自己的名字命名，当然你可以用（姓名＋目的名＋时间戳）命名也不错，为什么要加时间戳，因为同一个任务可能程序问题，会提交不止一个版本。\n\n第三，你可以对应不同的计算引擎（MapReduce, Spark, Storm等），编写不同的代码，提交后都可以在这里看到。\n\n![jobname](/images/post/ai/hdp20.png)\n\n<font color=#c00>注：集群模式下提交任务后，无法停止，要么等运行结束，要么报错结束。所以小规模测试时可以使用本地模式，等程序调试基本完成，可以提交集群模式，运行大规模数据版本。</font>\n\n``` python\nimport os\nimport time\nfrom os import path \nfrom pyspark import SparkConf, SparkContext\n\n# 生成当前时间戳\ntime_now = int(time.time())\n\n# 获取程序所在的父目录路径\ndir_path = os.getcwd()\n\n# 获取父目录名，因为个人的工作目录以自己的名字命名（英文或拼音）\ndir_name = path.basename(dir_path)\n\n# 获取数据文件在HDFS中的路径\nserver_input_file = '/hfile/data/data_wc_py'\n\n# 运行集群模式，所以资源调度交给yarn\nmaster = 'yarn'\n\n# 之前提到过的任务名设置\njob_name = '%s_%s' % (dir_name, time_now)\n\ntry:  \n    sc.stop()  \nexcept:  \n    pass \n\nconf = SparkConf().setMaster(master).setAppName(job_name)\nsc = SparkContext(conf=conf)\nlines = sc.textFile(server_input_file)\ncounts = lines.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n\n# 这次我们选择将结果直接打印出来\n# 因为Spark程序计算后依然是RDD，我们需要用collect将其转化为类数组\nresult = counts.collect()\n\n# 打印前100个结果\nprint result[:100]\n\nsc.stop()\n```\n\n## <font color=#c00>Scala</font>\n\n<font color=#c00>注：本文使用的语言是Scala2.1，编辑器Scala Eclipse，官网提供</font>\n\n``` scala\npackage org.test.wct\n\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkConf\n\nobject WordCount {\n  def main(args: Array[String]): Unit = {\n    val inputFile = \"数据文件路径\"\n    val outFile = \"输出结果路径\"\n    val conf = new SparkConf().setAppName(\"任务名\")\n    val sc = new SparkContext(conf)\n    val textFile = sc.textFile(inputFile)\n    val wordCount = textFile.flatMap(_.split(\" \")).map((_, 1)).reduceByKey(_+_)\n    wordCount.saveAsTextFile(outFile)\n    sc.stop()\n  }\n}\n```\n\nScala程序非常简洁，它提供了很多API，能够快速有效的帮助我们完成代码，编写Spark相关的程序，个人还是非常推荐的。\n\n编写好程序后，就可以像Java一样，打包成jar文件，提交给Spark进行计算了。如果忘记了如何提交任务，请查看[《Spark 部署》](/ai/hadoop-spk/)\n\n\n## <font color=#c00>Java</font>\n\n<font color=#c00>注：Java1.8，编辑器Spring Tool Suite</font>\n\n最后我们编写word count的Java版本，这次我们使用MapReduce作为计算引擎。\n\nJava版本的文件会稍微多一些，文件结构如下图所示：\n\n![javampr](/images/post/ai/hdp22.png)\n\n### Map程序\n\n在WordCountMapper.java中编写如下代码：\n\n``` java\npackage org.test.mpr;\n\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.LongWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Mapper;\n\npublic class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\n\n\t@Override\n\tprotected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context)\n\t\t\tthrows IOException, InterruptedException {\n\t\tString line = value.toString();\n\t\tStringTokenizer st = new StringTokenizer(line);\n\t\twhile(st.hasMoreTokens()) {\n\t\t\tString word = st.nextToken();\n\t\t\tcontext.write(new Text(word), new IntWritable(1));\n\t\t}\n\t}\n}\n```\n\n### Reduce程序\n\n在WordCountReducer.java中编写如下代码：\n\n``` java\npackage org.test.mpr;\n\nimport java.io.IOException;\n\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Reducer;\n\npublic class WordCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n\n\t@Override\n\tprotected void reduce(Text key, Iterable<IntWritable> iterable,\n\t\t\tReducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {\n\t\tint sum = 0;\n\t\tfor(IntWritable i:iterable) {\n\t\t\tsum = sum + i.get();\n\t\t}\n\t\tcontext.write(key, new IntWritable(sum));\n\t}\n}\n```\n\n### 提交程序\n\n在JobRun.java中编写如下代码：\n\n``` java\npackage org.test.mpr;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\npublic class JobRun {\n\tpublic static void main(String[] args) {\n\t\tConfiguration conf = new Configuration();\n\t\ttry {\n\t\t\tJob job = Job.getInstance(conf, \"任务名\");\n\t\t\tjob.setJarByClass(JobRun.class);\n\t\t\tjob.setMapperClass(WordCountMapper.class);\n\t\t\tjob.setReducerClass(WordCountReducer.class);\n\t\t\tjob.setOutputKeyClass(Text.class);\n\t\t\tjob.setOutputValueClass(IntWritable.class);\n\t\t\t\n\t\t\tFileInputFormat.addInputPath(job, new Path(\"数据文件路径\"));\n\t\t\tFileOutputFormat.setOutputPath(job, new Path(\"计算结果路径\"));\n\t\t\tSystem.exit(job.waitForCompletion(true) ? 0: 1);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n\n完成编写后，依然打jar，提交即可。\n\n代码中看到的Writable类型，由hadoop提供，它跟普通的Int，String类型没有太多区别，你可以将它理解为分布式的整型，字符型。有兴趣的朋友可以查看官网文档。\n\n## <font color=#c00>小结</font>\n\n这篇文章我们介绍了如果用不同的语言在两种计算引擎上，完成同一个任务。用户可以对比来看，那种语言更适合你。\n\n本系列文章[《目录》](/ai/hadoop-use/)","source":"_posts/hadoop-wct.md","raw":"---\ntitle: Word Count\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-04-03 15:49:39\n---\nWord Count程序就像初学每种语言时要写的Hello World一样。他可以用来统计大段文章（可能是一本朗文字典那么厚的书）中相同单词出现的次数。当然除了统计相同词数量外，我们经常拿它来统计网站中大量的PV，UV。\n\n所有的Spark程序可以在local模式下运行，也可以在cluster模式下运行。因为是第一次应用，我们会分别讲解这两种模式。以后的程序基本都是运行在集群模式。\n\nSpark程序可以使用Python，Scala，Java，R编写，推荐程度Python最高，R最低。按道理说整个Spark都是Scala开发的，使用Scala是最好的选择，的确是这样的。但是由于Python在整个机器学习领域的热度越来越热，为了方便大家之后开发其他程序（比如模式识别，语音识别等等），这里推荐使用Python，当然其他语言版本我们会大概讲下，本文我们看看Python，Scala，Java三种语言分别是如何实现World Count程序的，废话不多说，下面上主菜...\n\n<!--more-->\n\n# Quick Start\n\n## <font color=#c00>Python</font>\n\n<font color=#c00>注：本文使用的语言是Python2.7，编辑器Jupyter Notebook</font>\n\n### 本地模式\n\n``` python\nimport os\nfrom pyspark import SparkConf, SparkContext\n\n# 准备好的数据本地路径\ninput_file = \"file:///home/test/jupyter_notebook/wordcount/data_wc_py\"\n\n# 计算完成后统计结果存放路径\nout_dir = \"file:///home/test/jupyter_notebook/wordcount/wjh\"\n\n# 判断spark上下文是否已释放\ntry:  \n    sc.stop()  \nexcept:  \n    pass \n\n# 设置spark运行模式以及任务名称\nconf = SparkConf().setMaster(\"local\").setAppName(\"word_count_local\")\n\n# 按照设置，获取sprak上下文\nsc = SparkContext(conf=conf)\n\n# 按行读取数据，生成类数组\nlines = sc.textFile(input_file)\n\n# 这里使用了lambda表达式\n# 第一个表达式，将每行按空格把行转换成单词\n# 第二个把每一个单词转换成元组（单词，1）\n# 最后一个将单词相同的元组做累加\n# 最后把（单词，累加值）返回给counts数组\ncounts = lines.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n\n# 把最后的结果集保存在文件中\ncounts.saveAsTextFile(out_dir) \n\n# 释放spark上下文\nsc.stop()\n```\n\n<font color=#c00>注：只有本地模式才能在计算后，直接访问到存储结果集文件。</font>\n\n### 集群模式\n\n在讲这段程序前，讲点其他有的没的。首先，Jupyter是一个网页程序，尤其团队使用时，它被不同的人同时使用，所以为了代码管理需要，每个人可以在Jupyter的根目录建立自己的工作文件目录，自己编写的程序都放在自己工作目录下，这样可以有效管理自己的代码。\n\n第二，集群模式下运行时，我们可以在用8088端口访问浏览器，查看我们提交的计算任务进度，计算日志等。如下图，我们只要提交任务，都可以在这里看到，蓝框中是你为本次任务设置任务名，我不推荐这样命名，之前说过了因为同时间会有不止一人提交任务，如果大家都按程序目的命名，你很难分辨哪个才是你自己提交的。所以我推荐使用自己的名字命名，当然你可以用（姓名＋目的名＋时间戳）命名也不错，为什么要加时间戳，因为同一个任务可能程序问题，会提交不止一个版本。\n\n第三，你可以对应不同的计算引擎（MapReduce, Spark, Storm等），编写不同的代码，提交后都可以在这里看到。\n\n![jobname](/images/post/ai/hdp20.png)\n\n<font color=#c00>注：集群模式下提交任务后，无法停止，要么等运行结束，要么报错结束。所以小规模测试时可以使用本地模式，等程序调试基本完成，可以提交集群模式，运行大规模数据版本。</font>\n\n``` python\nimport os\nimport time\nfrom os import path \nfrom pyspark import SparkConf, SparkContext\n\n# 生成当前时间戳\ntime_now = int(time.time())\n\n# 获取程序所在的父目录路径\ndir_path = os.getcwd()\n\n# 获取父目录名，因为个人的工作目录以自己的名字命名（英文或拼音）\ndir_name = path.basename(dir_path)\n\n# 获取数据文件在HDFS中的路径\nserver_input_file = '/hfile/data/data_wc_py'\n\n# 运行集群模式，所以资源调度交给yarn\nmaster = 'yarn'\n\n# 之前提到过的任务名设置\njob_name = '%s_%s' % (dir_name, time_now)\n\ntry:  \n    sc.stop()  \nexcept:  \n    pass \n\nconf = SparkConf().setMaster(master).setAppName(job_name)\nsc = SparkContext(conf=conf)\nlines = sc.textFile(server_input_file)\ncounts = lines.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n\n# 这次我们选择将结果直接打印出来\n# 因为Spark程序计算后依然是RDD，我们需要用collect将其转化为类数组\nresult = counts.collect()\n\n# 打印前100个结果\nprint result[:100]\n\nsc.stop()\n```\n\n## <font color=#c00>Scala</font>\n\n<font color=#c00>注：本文使用的语言是Scala2.1，编辑器Scala Eclipse，官网提供</font>\n\n``` scala\npackage org.test.wct\n\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.SparkConf\n\nobject WordCount {\n  def main(args: Array[String]): Unit = {\n    val inputFile = \"数据文件路径\"\n    val outFile = \"输出结果路径\"\n    val conf = new SparkConf().setAppName(\"任务名\")\n    val sc = new SparkContext(conf)\n    val textFile = sc.textFile(inputFile)\n    val wordCount = textFile.flatMap(_.split(\" \")).map((_, 1)).reduceByKey(_+_)\n    wordCount.saveAsTextFile(outFile)\n    sc.stop()\n  }\n}\n```\n\nScala程序非常简洁，它提供了很多API，能够快速有效的帮助我们完成代码，编写Spark相关的程序，个人还是非常推荐的。\n\n编写好程序后，就可以像Java一样，打包成jar文件，提交给Spark进行计算了。如果忘记了如何提交任务，请查看[《Spark 部署》](/ai/hadoop-spk/)\n\n\n## <font color=#c00>Java</font>\n\n<font color=#c00>注：Java1.8，编辑器Spring Tool Suite</font>\n\n最后我们编写word count的Java版本，这次我们使用MapReduce作为计算引擎。\n\nJava版本的文件会稍微多一些，文件结构如下图所示：\n\n![javampr](/images/post/ai/hdp22.png)\n\n### Map程序\n\n在WordCountMapper.java中编写如下代码：\n\n``` java\npackage org.test.mpr;\n\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.LongWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Mapper;\n\npublic class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\n\n\t@Override\n\tprotected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context)\n\t\t\tthrows IOException, InterruptedException {\n\t\tString line = value.toString();\n\t\tStringTokenizer st = new StringTokenizer(line);\n\t\twhile(st.hasMoreTokens()) {\n\t\t\tString word = st.nextToken();\n\t\t\tcontext.write(new Text(word), new IntWritable(1));\n\t\t}\n\t}\n}\n```\n\n### Reduce程序\n\n在WordCountReducer.java中编写如下代码：\n\n``` java\npackage org.test.mpr;\n\nimport java.io.IOException;\n\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Reducer;\n\npublic class WordCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n\n\t@Override\n\tprotected void reduce(Text key, Iterable<IntWritable> iterable,\n\t\t\tReducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {\n\t\tint sum = 0;\n\t\tfor(IntWritable i:iterable) {\n\t\t\tsum = sum + i.get();\n\t\t}\n\t\tcontext.write(key, new IntWritable(sum));\n\t}\n}\n```\n\n### 提交程序\n\n在JobRun.java中编写如下代码：\n\n``` java\npackage org.test.mpr;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\npublic class JobRun {\n\tpublic static void main(String[] args) {\n\t\tConfiguration conf = new Configuration();\n\t\ttry {\n\t\t\tJob job = Job.getInstance(conf, \"任务名\");\n\t\t\tjob.setJarByClass(JobRun.class);\n\t\t\tjob.setMapperClass(WordCountMapper.class);\n\t\t\tjob.setReducerClass(WordCountReducer.class);\n\t\t\tjob.setOutputKeyClass(Text.class);\n\t\t\tjob.setOutputValueClass(IntWritable.class);\n\t\t\t\n\t\t\tFileInputFormat.addInputPath(job, new Path(\"数据文件路径\"));\n\t\t\tFileOutputFormat.setOutputPath(job, new Path(\"计算结果路径\"));\n\t\t\tSystem.exit(job.waitForCompletion(true) ? 0: 1);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n\n完成编写后，依然打jar，提交即可。\n\n代码中看到的Writable类型，由hadoop提供，它跟普通的Int，String类型没有太多区别，你可以将它理解为分布式的整型，字符型。有兴趣的朋友可以查看官网文档。\n\n## <font color=#c00>小结</font>\n\n这篇文章我们介绍了如果用不同的语言在两种计算引擎上，完成同一个任务。用户可以对比来看，那种语言更适合你。\n\n本系列文章[《目录》](/ai/hadoop-use/)","slug":"hadoop-wct","published":1,"updated":"2018-04-04T03:17:44.000Z","_id":"cjfjgup8t00143knacz7klp3u","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Word Count程序就像初学每种语言时要写的Hello World一样。他可以用来统计大段文章（可能是一本朗文字典那么厚的书）中相同单词出现的次数。当然除了统计相同词数量外，我们经常拿它来统计网站中大量的PV，UV。</p>\n<p>所有的Spark程序可以在local模式下运行，也可以在cluster模式下运行。因为是第一次应用，我们会分别讲解这两种模式。以后的程序基本都是运行在集群模式。</p>\n<p>Spark程序可以使用Python，Scala，Java，R编写，推荐程度Python最高，R最低。按道理说整个Spark都是Scala开发的，使用Scala是最好的选择，的确是这样的。但是由于Python在整个机器学习领域的热度越来越热，为了方便大家之后开发其他程序（比如模式识别，语音识别等等），这里推荐使用Python，当然其他语言版本我们会大概讲下，本文我们看看Python，Scala，Java三种语言分别是如何实现World Count程序的，废话不多说，下面上主菜…</p>\n<a id=\"more\"></a>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a><font color=\"#c00\">Python</font></h2><font color=\"#c00\">注：本文使用的语言是Python2.7，编辑器Jupyter Notebook</font>\n\n<h3 id=\"本地模式\"><a href=\"#本地模式\" class=\"headerlink\" title=\"本地模式\"></a>本地模式</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> pyspark <span class=\"keyword\">import</span> SparkConf, SparkContext</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 准备好的数据本地路径</span></span><br><span class=\"line\">input_file = <span class=\"string\">\"file:///home/test/jupyter_notebook/wordcount/data_wc_py\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算完成后统计结果存放路径</span></span><br><span class=\"line\">out_dir = <span class=\"string\">\"file:///home/test/jupyter_notebook/wordcount/wjh\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 判断spark上下文是否已释放</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:  </span><br><span class=\"line\">    sc.stop()  </span><br><span class=\"line\"><span class=\"keyword\">except</span>:  </span><br><span class=\"line\">    <span class=\"keyword\">pass</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置spark运行模式以及任务名称</span></span><br><span class=\"line\">conf = SparkConf().setMaster(<span class=\"string\">\"local\"</span>).setAppName(<span class=\"string\">\"word_count_local\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 按照设置，获取sprak上下文</span></span><br><span class=\"line\">sc = SparkContext(conf=conf)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 按行读取数据，生成类数组</span></span><br><span class=\"line\">lines = sc.textFile(input_file)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 这里使用了lambda表达式</span></span><br><span class=\"line\"><span class=\"comment\"># 第一个表达式，将每行按空格把行转换成单词</span></span><br><span class=\"line\"><span class=\"comment\"># 第二个把每一个单词转换成元组（单词，1）</span></span><br><span class=\"line\"><span class=\"comment\"># 最后一个将单词相同的元组做累加</span></span><br><span class=\"line\"><span class=\"comment\"># 最后把（单词，累加值）返回给counts数组</span></span><br><span class=\"line\">counts = lines.flatMap(<span class=\"keyword\">lambda</span> line: line.split(<span class=\"string\">\" \"</span>)).map(<span class=\"keyword\">lambda</span> word: (word, <span class=\"number\">1</span>)).reduceByKey(<span class=\"keyword\">lambda</span> a, b: a + b)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 把最后的结果集保存在文件中</span></span><br><span class=\"line\">counts.saveAsTextFile(out_dir) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 释放spark上下文</span></span><br><span class=\"line\">sc.stop()</span><br></pre></td></tr></table></figure>\n<font color=\"#c00\">注：只有本地模式才能在计算后，直接访问到存储结果集文件。</font>\n\n<h3 id=\"集群模式\"><a href=\"#集群模式\" class=\"headerlink\" title=\"集群模式\"></a>集群模式</h3><p>在讲这段程序前，讲点其他有的没的。首先，Jupyter是一个网页程序，尤其团队使用时，它被不同的人同时使用，所以为了代码管理需要，每个人可以在Jupyter的根目录建立自己的工作文件目录，自己编写的程序都放在自己工作目录下，这样可以有效管理自己的代码。</p>\n<p>第二，集群模式下运行时，我们可以在用8088端口访问浏览器，查看我们提交的计算任务进度，计算日志等。如下图，我们只要提交任务，都可以在这里看到，蓝框中是你为本次任务设置任务名，我不推荐这样命名，之前说过了因为同时间会有不止一人提交任务，如果大家都按程序目的命名，你很难分辨哪个才是你自己提交的。所以我推荐使用自己的名字命名，当然你可以用（姓名＋目的名＋时间戳）命名也不错，为什么要加时间戳，因为同一个任务可能程序问题，会提交不止一个版本。</p>\n<p>第三，你可以对应不同的计算引擎（MapReduce, Spark, Storm等），编写不同的代码，提交后都可以在这里看到。</p>\n<p><img src=\"/images/post/ai/hdp20.png\" alt=\"jobname\"></p>\n<font color=\"#c00\">注：集群模式下提交任务后，无法停止，要么等运行结束，要么报错结束。所以小规模测试时可以使用本地模式，等程序调试基本完成，可以提交集群模式，运行大规模数据版本。</font>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">from</span> os <span class=\"keyword\">import</span> path </span><br><span class=\"line\"><span class=\"keyword\">from</span> pyspark <span class=\"keyword\">import</span> SparkConf, SparkContext</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成当前时间戳</span></span><br><span class=\"line\">time_now = int(time.time())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取程序所在的父目录路径</span></span><br><span class=\"line\">dir_path = os.getcwd()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取父目录名，因为个人的工作目录以自己的名字命名（英文或拼音）</span></span><br><span class=\"line\">dir_name = path.basename(dir_path)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据文件在HDFS中的路径</span></span><br><span class=\"line\">server_input_file = <span class=\"string\">'/hfile/data/data_wc_py'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 运行集群模式，所以资源调度交给yarn</span></span><br><span class=\"line\">master = <span class=\"string\">'yarn'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 之前提到过的任务名设置</span></span><br><span class=\"line\">job_name = <span class=\"string\">'%s_%s'</span> % (dir_name, time_now)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">try</span>:  </span><br><span class=\"line\">    sc.stop()  </span><br><span class=\"line\"><span class=\"keyword\">except</span>:  </span><br><span class=\"line\">    <span class=\"keyword\">pass</span> </span><br><span class=\"line\"></span><br><span class=\"line\">conf = SparkConf().setMaster(master).setAppName(job_name)</span><br><span class=\"line\">sc = SparkContext(conf=conf)</span><br><span class=\"line\">lines = sc.textFile(server_input_file)</span><br><span class=\"line\">counts = lines.flatMap(<span class=\"keyword\">lambda</span> line: line.split(<span class=\"string\">\" \"</span>)).map(<span class=\"keyword\">lambda</span> word: (word, <span class=\"number\">1</span>)).reduceByKey(<span class=\"keyword\">lambda</span> a, b: a + b)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 这次我们选择将结果直接打印出来</span></span><br><span class=\"line\"><span class=\"comment\"># 因为Spark程序计算后依然是RDD，我们需要用collect将其转化为类数组</span></span><br><span class=\"line\">result = counts.collect()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打印前100个结果</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> result[:<span class=\"number\">100</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">sc.stop()</span><br></pre></td></tr></table></figure>\n<h2 id=\"Scala\"><a href=\"#Scala\" class=\"headerlink\" title=\"Scala\"></a><font color=\"#c00\">Scala</font></h2><font color=\"#c00\">注：本文使用的语言是Scala2.1，编辑器Scala Eclipse，官网提供</font>\n\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> org.test.wct</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.<span class=\"type\">SparkContext</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.<span class=\"type\">SparkContext</span>._</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.<span class=\"type\">SparkConf</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">object</span> <span class=\"title\">WordCount</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span></span>(args: <span class=\"type\">Array</span>[<span class=\"type\">String</span>]): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\">    <span class=\"keyword\">val</span> inputFile = <span class=\"string\">\"数据文件路径\"</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> outFile = <span class=\"string\">\"输出结果路径\"</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> conf = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().setAppName(<span class=\"string\">\"任务名\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> sc = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(conf)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> textFile = sc.textFile(inputFile)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> wordCount = textFile.flatMap(_.split(<span class=\"string\">\" \"</span>)).map((_, <span class=\"number\">1</span>)).reduceByKey(_+_)</span><br><span class=\"line\">    wordCount.saveAsTextFile(outFile)</span><br><span class=\"line\">    sc.stop()</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Scala程序非常简洁，它提供了很多API，能够快速有效的帮助我们完成代码，编写Spark相关的程序，个人还是非常推荐的。</p>\n<p>编写好程序后，就可以像Java一样，打包成jar文件，提交给Spark进行计算了。如果忘记了如何提交任务，请查看<a href=\"/ai/hadoop-spk/\">《Spark 部署》</a></p>\n<h2 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a><font color=\"#c00\">Java</font></h2><font color=\"#c00\">注：Java1.8，编辑器Spring Tool Suite</font>\n\n<p>最后我们编写word count的Java版本，这次我们使用MapReduce作为计算引擎。</p>\n<p>Java版本的文件会稍微多一些，文件结构如下图所示：</p>\n<p><img src=\"/images/post/ai/hdp22.png\" alt=\"javampr\"></p>\n<h3 id=\"Map程序\"><a href=\"#Map程序\" class=\"headerlink\" title=\"Map程序\"></a>Map程序</h3><p>在WordCountMapper.java中编写如下代码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> org.test.mpr;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.StringTokenizer;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WordCountMapper</span> <span class=\"keyword\">extends</span> <span class=\"title\">Mapper</span>&lt;<span class=\"title\">LongWritable</span>, <span class=\"title\">Text</span>, <span class=\"title\">Text</span>, <span class=\"title\">IntWritable</span>&gt; </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">map</span><span class=\"params\">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, IntWritable&gt;.Context context)</span></span></span><br><span class=\"line\"><span class=\"function\">\t\t\t<span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">\t\tString line = value.toString();</span><br><span class=\"line\">\t\tStringTokenizer st = <span class=\"keyword\">new</span> StringTokenizer(line);</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span>(st.hasMoreTokens()) &#123;</span><br><span class=\"line\">\t\t\tString word = st.nextToken();</span><br><span class=\"line\">\t\t\tcontext.write(<span class=\"keyword\">new</span> Text(word), <span class=\"keyword\">new</span> IntWritable(<span class=\"number\">1</span>));</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"Reduce程序\"><a href=\"#Reduce程序\" class=\"headerlink\" title=\"Reduce程序\"></a>Reduce程序</h3><p>在WordCountReducer.java中编写如下代码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> org.test.mpr;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WordCountReducer</span> <span class=\"keyword\">extends</span> <span class=\"title\">Reducer</span>&lt;<span class=\"title\">Text</span>, <span class=\"title\">IntWritable</span>, <span class=\"title\">Text</span>, <span class=\"title\">IntWritable</span>&gt; </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">reduce</span><span class=\"params\">(Text key, Iterable&lt;IntWritable&gt; iterable,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">\t\t\tReducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> sum = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(IntWritable i:iterable) &#123;</span><br><span class=\"line\">\t\t\tsum = sum + i.get();</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tcontext.write(key, <span class=\"keyword\">new</span> IntWritable(sum));</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"提交程序\"><a href=\"#提交程序\" class=\"headerlink\" title=\"提交程序\"></a>提交程序</h3><p>在JobRun.java中编写如下代码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> org.test.mpr;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.Path;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JobRun</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">\t\tConfiguration conf = <span class=\"keyword\">new</span> Configuration();</span><br><span class=\"line\">\t\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t\t\tJob job = Job.getInstance(conf, <span class=\"string\">\"任务名\"</span>);</span><br><span class=\"line\">\t\t\tjob.setJarByClass(JobRun.class);</span><br><span class=\"line\">\t\t\tjob.setMapperClass(WordCountMapper.class);</span><br><span class=\"line\">\t\t\tjob.setReducerClass(WordCountReducer.class);</span><br><span class=\"line\">\t\t\tjob.setOutputKeyClass(Text.class);</span><br><span class=\"line\">\t\t\tjob.setOutputValueClass(IntWritable.class);</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\tFileInputFormat.addInputPath(job, <span class=\"keyword\">new</span> Path(<span class=\"string\">\"数据文件路径\"</span>));</span><br><span class=\"line\">\t\t\tFileOutputFormat.setOutputPath(job, <span class=\"keyword\">new</span> Path(<span class=\"string\">\"计算结果路径\"</span>));</span><br><span class=\"line\">\t\t\tSystem.exit(job.waitForCompletion(<span class=\"keyword\">true</span>) ? <span class=\"number\">0</span>: <span class=\"number\">1</span>);</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">\t\t\te.printStackTrace();</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>完成编写后，依然打jar，提交即可。</p>\n<p>代码中看到的Writable类型，由hadoop提供，它跟普通的Int，String类型没有太多区别，你可以将它理解为分布式的整型，字符型。有兴趣的朋友可以查看官网文档。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>这篇文章我们介绍了如果用不同的语言在两种计算引擎上，完成同一个任务。用户可以对比来看，那种语言更适合你。</p>\n<p>本系列文章<a href=\"/ai/hadoop-use/\">《目录》</a></p>\n","site":{"data":{}},"excerpt":"<p>Word Count程序就像初学每种语言时要写的Hello World一样。他可以用来统计大段文章（可能是一本朗文字典那么厚的书）中相同单词出现的次数。当然除了统计相同词数量外，我们经常拿它来统计网站中大量的PV，UV。</p>\n<p>所有的Spark程序可以在local模式下运行，也可以在cluster模式下运行。因为是第一次应用，我们会分别讲解这两种模式。以后的程序基本都是运行在集群模式。</p>\n<p>Spark程序可以使用Python，Scala，Java，R编写，推荐程度Python最高，R最低。按道理说整个Spark都是Scala开发的，使用Scala是最好的选择，的确是这样的。但是由于Python在整个机器学习领域的热度越来越热，为了方便大家之后开发其他程序（比如模式识别，语音识别等等），这里推荐使用Python，当然其他语言版本我们会大概讲下，本文我们看看Python，Scala，Java三种语言分别是如何实现World Count程序的，废话不多说，下面上主菜…</p>","more":"<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a><font color=\"#c00\">Python</font></h2><font color=\"#c00\">注：本文使用的语言是Python2.7，编辑器Jupyter Notebook</font>\n\n<h3 id=\"本地模式\"><a href=\"#本地模式\" class=\"headerlink\" title=\"本地模式\"></a>本地模式</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> pyspark <span class=\"keyword\">import</span> SparkConf, SparkContext</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 准备好的数据本地路径</span></span><br><span class=\"line\">input_file = <span class=\"string\">\"file:///home/test/jupyter_notebook/wordcount/data_wc_py\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算完成后统计结果存放路径</span></span><br><span class=\"line\">out_dir = <span class=\"string\">\"file:///home/test/jupyter_notebook/wordcount/wjh\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 判断spark上下文是否已释放</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:  </span><br><span class=\"line\">    sc.stop()  </span><br><span class=\"line\"><span class=\"keyword\">except</span>:  </span><br><span class=\"line\">    <span class=\"keyword\">pass</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置spark运行模式以及任务名称</span></span><br><span class=\"line\">conf = SparkConf().setMaster(<span class=\"string\">\"local\"</span>).setAppName(<span class=\"string\">\"word_count_local\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 按照设置，获取sprak上下文</span></span><br><span class=\"line\">sc = SparkContext(conf=conf)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 按行读取数据，生成类数组</span></span><br><span class=\"line\">lines = sc.textFile(input_file)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 这里使用了lambda表达式</span></span><br><span class=\"line\"><span class=\"comment\"># 第一个表达式，将每行按空格把行转换成单词</span></span><br><span class=\"line\"><span class=\"comment\"># 第二个把每一个单词转换成元组（单词，1）</span></span><br><span class=\"line\"><span class=\"comment\"># 最后一个将单词相同的元组做累加</span></span><br><span class=\"line\"><span class=\"comment\"># 最后把（单词，累加值）返回给counts数组</span></span><br><span class=\"line\">counts = lines.flatMap(<span class=\"keyword\">lambda</span> line: line.split(<span class=\"string\">\" \"</span>)).map(<span class=\"keyword\">lambda</span> word: (word, <span class=\"number\">1</span>)).reduceByKey(<span class=\"keyword\">lambda</span> a, b: a + b)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 把最后的结果集保存在文件中</span></span><br><span class=\"line\">counts.saveAsTextFile(out_dir) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 释放spark上下文</span></span><br><span class=\"line\">sc.stop()</span><br></pre></td></tr></table></figure>\n<font color=\"#c00\">注：只有本地模式才能在计算后，直接访问到存储结果集文件。</font>\n\n<h3 id=\"集群模式\"><a href=\"#集群模式\" class=\"headerlink\" title=\"集群模式\"></a>集群模式</h3><p>在讲这段程序前，讲点其他有的没的。首先，Jupyter是一个网页程序，尤其团队使用时，它被不同的人同时使用，所以为了代码管理需要，每个人可以在Jupyter的根目录建立自己的工作文件目录，自己编写的程序都放在自己工作目录下，这样可以有效管理自己的代码。</p>\n<p>第二，集群模式下运行时，我们可以在用8088端口访问浏览器，查看我们提交的计算任务进度，计算日志等。如下图，我们只要提交任务，都可以在这里看到，蓝框中是你为本次任务设置任务名，我不推荐这样命名，之前说过了因为同时间会有不止一人提交任务，如果大家都按程序目的命名，你很难分辨哪个才是你自己提交的。所以我推荐使用自己的名字命名，当然你可以用（姓名＋目的名＋时间戳）命名也不错，为什么要加时间戳，因为同一个任务可能程序问题，会提交不止一个版本。</p>\n<p>第三，你可以对应不同的计算引擎（MapReduce, Spark, Storm等），编写不同的代码，提交后都可以在这里看到。</p>\n<p><img src=\"/images/post/ai/hdp20.png\" alt=\"jobname\"></p>\n<font color=\"#c00\">注：集群模式下提交任务后，无法停止，要么等运行结束，要么报错结束。所以小规模测试时可以使用本地模式，等程序调试基本完成，可以提交集群模式，运行大规模数据版本。</font>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">from</span> os <span class=\"keyword\">import</span> path </span><br><span class=\"line\"><span class=\"keyword\">from</span> pyspark <span class=\"keyword\">import</span> SparkConf, SparkContext</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成当前时间戳</span></span><br><span class=\"line\">time_now = int(time.time())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取程序所在的父目录路径</span></span><br><span class=\"line\">dir_path = os.getcwd()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取父目录名，因为个人的工作目录以自己的名字命名（英文或拼音）</span></span><br><span class=\"line\">dir_name = path.basename(dir_path)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据文件在HDFS中的路径</span></span><br><span class=\"line\">server_input_file = <span class=\"string\">'/hfile/data/data_wc_py'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 运行集群模式，所以资源调度交给yarn</span></span><br><span class=\"line\">master = <span class=\"string\">'yarn'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 之前提到过的任务名设置</span></span><br><span class=\"line\">job_name = <span class=\"string\">'%s_%s'</span> % (dir_name, time_now)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">try</span>:  </span><br><span class=\"line\">    sc.stop()  </span><br><span class=\"line\"><span class=\"keyword\">except</span>:  </span><br><span class=\"line\">    <span class=\"keyword\">pass</span> </span><br><span class=\"line\"></span><br><span class=\"line\">conf = SparkConf().setMaster(master).setAppName(job_name)</span><br><span class=\"line\">sc = SparkContext(conf=conf)</span><br><span class=\"line\">lines = sc.textFile(server_input_file)</span><br><span class=\"line\">counts = lines.flatMap(<span class=\"keyword\">lambda</span> line: line.split(<span class=\"string\">\" \"</span>)).map(<span class=\"keyword\">lambda</span> word: (word, <span class=\"number\">1</span>)).reduceByKey(<span class=\"keyword\">lambda</span> a, b: a + b)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 这次我们选择将结果直接打印出来</span></span><br><span class=\"line\"><span class=\"comment\"># 因为Spark程序计算后依然是RDD，我们需要用collect将其转化为类数组</span></span><br><span class=\"line\">result = counts.collect()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打印前100个结果</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> result[:<span class=\"number\">100</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">sc.stop()</span><br></pre></td></tr></table></figure>\n<h2 id=\"Scala\"><a href=\"#Scala\" class=\"headerlink\" title=\"Scala\"></a><font color=\"#c00\">Scala</font></h2><font color=\"#c00\">注：本文使用的语言是Scala2.1，编辑器Scala Eclipse，官网提供</font>\n\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> org.test.wct</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.<span class=\"type\">SparkContext</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.<span class=\"type\">SparkContext</span>._</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.spark.<span class=\"type\">SparkConf</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">object</span> <span class=\"title\">WordCount</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span></span>(args: <span class=\"type\">Array</span>[<span class=\"type\">String</span>]): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\">    <span class=\"keyword\">val</span> inputFile = <span class=\"string\">\"数据文件路径\"</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> outFile = <span class=\"string\">\"输出结果路径\"</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> conf = <span class=\"keyword\">new</span> <span class=\"type\">SparkConf</span>().setAppName(<span class=\"string\">\"任务名\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> sc = <span class=\"keyword\">new</span> <span class=\"type\">SparkContext</span>(conf)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> textFile = sc.textFile(inputFile)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> wordCount = textFile.flatMap(_.split(<span class=\"string\">\" \"</span>)).map((_, <span class=\"number\">1</span>)).reduceByKey(_+_)</span><br><span class=\"line\">    wordCount.saveAsTextFile(outFile)</span><br><span class=\"line\">    sc.stop()</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Scala程序非常简洁，它提供了很多API，能够快速有效的帮助我们完成代码，编写Spark相关的程序，个人还是非常推荐的。</p>\n<p>编写好程序后，就可以像Java一样，打包成jar文件，提交给Spark进行计算了。如果忘记了如何提交任务，请查看<a href=\"/ai/hadoop-spk/\">《Spark 部署》</a></p>\n<h2 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a><font color=\"#c00\">Java</font></h2><font color=\"#c00\">注：Java1.8，编辑器Spring Tool Suite</font>\n\n<p>最后我们编写word count的Java版本，这次我们使用MapReduce作为计算引擎。</p>\n<p>Java版本的文件会稍微多一些，文件结构如下图所示：</p>\n<p><img src=\"/images/post/ai/hdp22.png\" alt=\"javampr\"></p>\n<h3 id=\"Map程序\"><a href=\"#Map程序\" class=\"headerlink\" title=\"Map程序\"></a>Map程序</h3><p>在WordCountMapper.java中编写如下代码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> org.test.mpr;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.StringTokenizer;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WordCountMapper</span> <span class=\"keyword\">extends</span> <span class=\"title\">Mapper</span>&lt;<span class=\"title\">LongWritable</span>, <span class=\"title\">Text</span>, <span class=\"title\">Text</span>, <span class=\"title\">IntWritable</span>&gt; </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">map</span><span class=\"params\">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, IntWritable&gt;.Context context)</span></span></span><br><span class=\"line\"><span class=\"function\">\t\t\t<span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">\t\tString line = value.toString();</span><br><span class=\"line\">\t\tStringTokenizer st = <span class=\"keyword\">new</span> StringTokenizer(line);</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span>(st.hasMoreTokens()) &#123;</span><br><span class=\"line\">\t\t\tString word = st.nextToken();</span><br><span class=\"line\">\t\t\tcontext.write(<span class=\"keyword\">new</span> Text(word), <span class=\"keyword\">new</span> IntWritable(<span class=\"number\">1</span>));</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"Reduce程序\"><a href=\"#Reduce程序\" class=\"headerlink\" title=\"Reduce程序\"></a>Reduce程序</h3><p>在WordCountReducer.java中编写如下代码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> org.test.mpr;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.io.IOException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">WordCountReducer</span> <span class=\"keyword\">extends</span> <span class=\"title\">Reducer</span>&lt;<span class=\"title\">Text</span>, <span class=\"title\">IntWritable</span>, <span class=\"title\">Text</span>, <span class=\"title\">IntWritable</span>&gt; </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"meta\">@Override</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">reduce</span><span class=\"params\">(Text key, Iterable&lt;IntWritable&gt; iterable,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">\t\t\tReducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class=\"keyword\">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">int</span> sum = <span class=\"number\">0</span>;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(IntWritable i:iterable) &#123;</span><br><span class=\"line\">\t\t\tsum = sum + i.get();</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tcontext.write(key, <span class=\"keyword\">new</span> IntWritable(sum));</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"提交程序\"><a href=\"#提交程序\" class=\"headerlink\" title=\"提交程序\"></a>提交程序</h3><p>在JobRun.java中编写如下代码：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> org.test.mpr;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.fs.Path;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.io.Text;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JobRun</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">\t\tConfiguration conf = <span class=\"keyword\">new</span> Configuration();</span><br><span class=\"line\">\t\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t\t\tJob job = Job.getInstance(conf, <span class=\"string\">\"任务名\"</span>);</span><br><span class=\"line\">\t\t\tjob.setJarByClass(JobRun.class);</span><br><span class=\"line\">\t\t\tjob.setMapperClass(WordCountMapper.class);</span><br><span class=\"line\">\t\t\tjob.setReducerClass(WordCountReducer.class);</span><br><span class=\"line\">\t\t\tjob.setOutputKeyClass(Text.class);</span><br><span class=\"line\">\t\t\tjob.setOutputValueClass(IntWritable.class);</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\tFileInputFormat.addInputPath(job, <span class=\"keyword\">new</span> Path(<span class=\"string\">\"数据文件路径\"</span>));</span><br><span class=\"line\">\t\t\tFileOutputFormat.setOutputPath(job, <span class=\"keyword\">new</span> Path(<span class=\"string\">\"计算结果路径\"</span>));</span><br><span class=\"line\">\t\t\tSystem.exit(job.waitForCompletion(<span class=\"keyword\">true</span>) ? <span class=\"number\">0</span>: <span class=\"number\">1</span>);</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">\t\t\te.printStackTrace();</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>完成编写后，依然打jar，提交即可。</p>\n<p>代码中看到的Writable类型，由hadoop提供，它跟普通的Int，String类型没有太多区别，你可以将它理解为分布式的整型，字符型。有兴趣的朋友可以查看官网文档。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>这篇文章我们介绍了如果用不同的语言在两种计算引擎上，完成同一个任务。用户可以对比来看，那种语言更适合你。</p>\n<p>本系列文章<a href=\"/ai/hadoop-use/\">《目录》</a></p>"},{"title":"info.md","_content":"发行版本：CentOS Linux release 7.3.1611 (Core) \n内核：Linux version 4.13.5-1.el7.elrepo.x86_64 (mockbuild@Build64R7) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)) #1 SMP Thu Oct 5 08:24:09 EDT 2017\n机器节点数：4\nCPU个数：双路\n内核数：10\n线程数：20\n基础信息：\n\tprocessor\t: 0\n\tvendor_id\t: GenuineIntel\n\tcpu family\t: 6\n\tmodel\t\t: 63\n\tmodel name\t: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz\n\tstepping\t: 2\n\tmicrocode\t: 0x38\n\tcpu MHz\t\t: 2294.686\n\tcache size\t: 25600 KB\n\tphysical id\t: 0\n\tsiblings\t: 10\n\tcore id\t\t: 0\n\tcpu cores\t: 10\n\tapicid\t\t: 0\n\tinitial apicid\t: 0\n\tfpu\t\t: yes\n\tfpu_exception\t: yes\n\tcpuid level\t: 15\n\twp\t\t: yes\n\tflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx hypervisor lahf_lm epb cqm_llc cqm_occup_llc dtherm ida arat pln pts\n\tbugs\t\t:\n\tbogomips\t: 4589.37\n\tclflush size\t: 64\n\tcache_alignment\t: 64\n\taddress sizes\t: 40 bits physical, 48 bits virtual\n\tpower management:\n内存信息：\n\t       total       used        free         shared     buff/cache  available\nMem:       99003780    52820972    28880564     1696800    17302244    43267624\nSwap:      10485756           0    10485756\n\n\n","source":"_drafts/info-md.md","raw":"---\ntitle: info.md\ntags:\n---\n发行版本：CentOS Linux release 7.3.1611 (Core) \n内核：Linux version 4.13.5-1.el7.elrepo.x86_64 (mockbuild@Build64R7) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)) #1 SMP Thu Oct 5 08:24:09 EDT 2017\n机器节点数：4\nCPU个数：双路\n内核数：10\n线程数：20\n基础信息：\n\tprocessor\t: 0\n\tvendor_id\t: GenuineIntel\n\tcpu family\t: 6\n\tmodel\t\t: 63\n\tmodel name\t: Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz\n\tstepping\t: 2\n\tmicrocode\t: 0x38\n\tcpu MHz\t\t: 2294.686\n\tcache size\t: 25600 KB\n\tphysical id\t: 0\n\tsiblings\t: 10\n\tcore id\t\t: 0\n\tcpu cores\t: 10\n\tapicid\t\t: 0\n\tinitial apicid\t: 0\n\tfpu\t\t: yes\n\tfpu_exception\t: yes\n\tcpuid level\t: 15\n\twp\t\t: yes\n\tflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx hypervisor lahf_lm epb cqm_llc cqm_occup_llc dtherm ida arat pln pts\n\tbugs\t\t:\n\tbogomips\t: 4589.37\n\tclflush size\t: 64\n\tcache_alignment\t: 64\n\taddress sizes\t: 40 bits physical, 48 bits virtual\n\tpower management:\n内存信息：\n\t       total       used        free         shared     buff/cache  available\nMem:       99003780    52820972    28880564     1696800    17302244    43267624\nSwap:      10485756           0    10485756\n\n\n","slug":"info-md","published":0,"date":"2018-03-30T09:52:11.000Z","updated":"2018-03-30T09:52:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup8u00153knar5arce2z","content":"<p>发行版本：CentOS Linux release 7.3.1611 (Core)<br>内核：Linux version 4.13.5-1.el7.elrepo.x86_64 (mockbuild@Build64R7) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)) #1 SMP Thu Oct 5 08:24:09 EDT 2017<br>机器节点数：4<br>CPU个数：双路<br>内核数：10<br>线程数：20<br>基础信息：<br>    processor    : 0<br>    vendor_id    : GenuineIntel<br>    cpu family    : 6<br>    model        : 63<br>    model name    : Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz<br>    stepping    : 2<br>    microcode    : 0x38<br>    cpu MHz        : 2294.686<br>    cache size    : 25600 KB<br>    physical id    : 0<br>    siblings    : 10<br>    core id        : 0<br>    cpu cores    : 10<br>    apicid        : 0<br>    initial apicid    : 0<br>    fpu        : yes<br>    fpu_exception    : yes<br>    cpuid level    : 15<br>    wp        : yes<br>    flags        : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx hypervisor lahf_lm epb cqm_llc cqm_occup_llc dtherm ida arat pln pts<br>    bugs        :<br>    bogomips    : 4589.37<br>    clflush size    : 64<br>    cache_alignment    : 64<br>    address sizes    : 40 bits physical, 48 bits virtual<br>    power management:<br>内存信息：<br>           total       used        free         shared     buff/cache  available<br>Mem:       99003780    52820972    28880564     1696800    17302244    43267624<br>Swap:      10485756           0    10485756</p>\n","site":{"data":{}},"excerpt":"","more":"<p>发行版本：CentOS Linux release 7.3.1611 (Core)<br>内核：Linux version 4.13.5-1.el7.elrepo.x86_64 (mockbuild@Build64R7) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)) #1 SMP Thu Oct 5 08:24:09 EDT 2017<br>机器节点数：4<br>CPU个数：双路<br>内核数：10<br>线程数：20<br>基础信息：<br>    processor    : 0<br>    vendor_id    : GenuineIntel<br>    cpu family    : 6<br>    model        : 63<br>    model name    : Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz<br>    stepping    : 2<br>    microcode    : 0x38<br>    cpu MHz        : 2294.686<br>    cache size    : 25600 KB<br>    physical id    : 0<br>    siblings    : 10<br>    core id        : 0<br>    cpu cores    : 10<br>    apicid        : 0<br>    initial apicid    : 0<br>    fpu        : yes<br>    fpu_exception    : yes<br>    cpuid level    : 15<br>    wp        : yes<br>    flags        : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx hypervisor lahf_lm epb cqm_llc cqm_occup_llc dtherm ida arat pln pts<br>    bugs        :<br>    bogomips    : 4589.37<br>    clflush size    : 64<br>    cache_alignment    : 64<br>    address sizes    : 40 bits physical, 48 bits virtual<br>    power management:<br>内存信息：<br>           total       used        free         shared     buff/cache  available<br>Mem:       99003780    52820972    28880564     1696800    17302244    43267624<br>Swap:      10485756           0    10485756</p>\n"},{"title":"Hadoop 基础教程[系列]","date":"2018-03-20T06:58:55.000Z","_content":"## 前言\n\n这一系列的文章主要介绍，Hadoop基础，说明各个工具的作用及用途，相互之间的关系。\n\n## 目录\n\n- #### [HDFS](/ai/hadoop-hdfs/)\n\n- #### [MapReduce](/ai/hadoop-mapreduce/)\n\n- #### [Zookeeper](/ai/hadoop-zookeeper/)\n\n- #### [关系架构](/ai/hadoop-relate/)\n\n<!--more-->\n\n- #### [Spark](/ai/hadoop-spark/)\n\n- #### [HBase](/ai/hadoop-hbase/)\n\n- #### [Jupiter](/ai/hadoop-jupiter/)\n\n\n","source":"_posts/hadoop-tutorial.md","raw":"---\ntitle: Hadoop 基础教程[系列]\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-03-20 14:58:55\n---\n## 前言\n\n这一系列的文章主要介绍，Hadoop基础，说明各个工具的作用及用途，相互之间的关系。\n\n## 目录\n\n- #### [HDFS](/ai/hadoop-hdfs/)\n\n- #### [MapReduce](/ai/hadoop-mapreduce/)\n\n- #### [Zookeeper](/ai/hadoop-zookeeper/)\n\n- #### [关系架构](/ai/hadoop-relate/)\n\n<!--more-->\n\n- #### [Spark](/ai/hadoop-spark/)\n\n- #### [HBase](/ai/hadoop-hbase/)\n\n- #### [Jupiter](/ai/hadoop-jupiter/)\n\n\n","slug":"hadoop-tutorial","published":1,"updated":"2018-03-30T09:52:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup8w00173knazf08wnm4","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>这一系列的文章主要介绍，Hadoop基础，说明各个工具的作用及用途，相互之间的关系。</p>\n<h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><ul>\n<li><h4 id=\"HDFS\"><a href=\"#HDFS\" class=\"headerlink\" title=\"HDFS\"></a><a href=\"/ai/hadoop-hdfs/\">HDFS</a></h4></li>\n<li><h4 id=\"MapReduce\"><a href=\"#MapReduce\" class=\"headerlink\" title=\"MapReduce\"></a><a href=\"/ai/hadoop-mapreduce/\">MapReduce</a></h4></li>\n<li><h4 id=\"Zookeeper\"><a href=\"#Zookeeper\" class=\"headerlink\" title=\"Zookeeper\"></a><a href=\"/ai/hadoop-zookeeper/\">Zookeeper</a></h4></li>\n<li><h4 id=\"关系架构\"><a href=\"#关系架构\" class=\"headerlink\" title=\"关系架构\"></a><a href=\"/ai/hadoop-relate/\">关系架构</a></h4></li>\n</ul>\n<a id=\"more\"></a>\n<ul>\n<li><h4 id=\"Spark\"><a href=\"#Spark\" class=\"headerlink\" title=\"Spark\"></a><a href=\"/ai/hadoop-spark/\">Spark</a></h4></li>\n<li><h4 id=\"HBase\"><a href=\"#HBase\" class=\"headerlink\" title=\"HBase\"></a><a href=\"/ai/hadoop-hbase/\">HBase</a></h4></li>\n<li><h4 id=\"Jupiter\"><a href=\"#Jupiter\" class=\"headerlink\" title=\"Jupiter\"></a><a href=\"/ai/hadoop-jupiter/\">Jupiter</a></h4></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>这一系列的文章主要介绍，Hadoop基础，说明各个工具的作用及用途，相互之间的关系。</p>\n<h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><ul>\n<li><h4 id=\"HDFS\"><a href=\"#HDFS\" class=\"headerlink\" title=\"HDFS\"></a><a href=\"/ai/hadoop-hdfs/\">HDFS</a></h4></li>\n<li><h4 id=\"MapReduce\"><a href=\"#MapReduce\" class=\"headerlink\" title=\"MapReduce\"></a><a href=\"/ai/hadoop-mapreduce/\">MapReduce</a></h4></li>\n<li><h4 id=\"Zookeeper\"><a href=\"#Zookeeper\" class=\"headerlink\" title=\"Zookeeper\"></a><a href=\"/ai/hadoop-zookeeper/\">Zookeeper</a></h4></li>\n<li><h4 id=\"关系架构\"><a href=\"#关系架构\" class=\"headerlink\" title=\"关系架构\"></a><a href=\"/ai/hadoop-relate/\">关系架构</a></h4></li>\n</ul>","more":"<ul>\n<li><h4 id=\"Spark\"><a href=\"#Spark\" class=\"headerlink\" title=\"Spark\"></a><a href=\"/ai/hadoop-spark/\">Spark</a></h4></li>\n<li><h4 id=\"HBase\"><a href=\"#HBase\" class=\"headerlink\" title=\"HBase\"></a><a href=\"/ai/hadoop-hbase/\">HBase</a></h4></li>\n<li><h4 id=\"Jupiter\"><a href=\"#Jupiter\" class=\"headerlink\" title=\"Jupiter\"></a><a href=\"/ai/hadoop-jupiter/\">Jupiter</a></h4></li>\n</ul>"},{"title":"YARN 部署","date":"2018-03-20T02:18:18.000Z","_content":"上一篇文章我们已经完成了HDFS系统的部署，接下来我们开始YARN的配置，它是资源调度很重要的部分。依然选择在node0节点上进行配置。\n\n# Quick Start\n\n## <font color=#c00>MapReduce 资源调度配置</font>\n\nHadoop中计算引擎的运行方式有很多，在企业级应用中我们选择yarn作为资源调度的方式。\n\n### 配置MapReduce的资源调度方式\n\n复制etc/hadoop/mapred-site.xml.template为mapred-site.xml，并添加如下配置项：\n\n<!--more-->\n\n``` xml\n<property>\n   <name>mapreduce.framework.name</name>\n   <value>yarn</value>\n</property>\n```\n\n## <font color=#c00>YARN 配置</font>\n\n在etc/hadoop/yarn-site.xml文件中，添加如下配置项：\n\n### 资源申请的主机\n\n``` xml\n<property>\n   <name>yarn.resourcemanager.hostname</name>\n   <value>node0的IP</value>\n</property>\n```\n\n### NodeManager 附属服务\n\n``` xml\n<property>\n   <name>yarn.nodemanager.aux-services</name>\n   <value>mapreduce_shuffle</value>\n</property>\n```\n\n### 服务类（固定配置）\n\n``` xml\n<property>\n   <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>\n   <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n</property>\n```\n\n<font color=#c00>注：下面打问号的6个配置项，需要计算，才能得出（依据自己机器的节点数，每个节点的具体硬件配置，以及各自的任务需要）。这也是yarn配置的重点。如果想了解YARN在不同数量及配置的服务器中该如何计算，请[点击此处](https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.1/bk_installing_manually_book/content/rpm-chap1-11.html)，进行查看。</font>\n\n### 内存总量\n\n``` xml\n<property>\n   <name>yarn.nodemanager.resource.memory-mb</name>\n   <value>?</value>\n</property>\n```\n\n### 最小可申请内存量\n\n``` xml\n<property>\n   <name>yarn.scheduler.minimum-allocation-mb</name>\n   <value>?</value>\n</property>\n```\n\n### yarn启动时分配给AppMaster的默认内存大小\n\n``` xml\n<property>\n   <name>yarn.app.mapreduce.am.resource.mb</name>\n   <value>?</value>\n</property>\n```\n\n### JVM参数\n\n``` xml\n<property>\n   <name>yarn.app.mapreduce.am.command-opts</name>\n   <value>?</value>\n</property>\n```\n\n### 可供调用的CPU线程数\n\n<font color=#999>这个配置项指你分配多少个CPU线程供yarn调度，可以全部，也可以分配一部分，主要看这个节点的想如何使用。</font>\n\n``` xml\n<property>\n   <name>yarn.nodemanager.resource.cpu-vcores</name>\n   <value>?</value>\n</property>\n```\n\n### 单个任务可申请的最多CPU线程数\n\n``` xml\n<property>\n   <name>yarn.scheduler.maximum-allocation-vcores</name>\n   <value>?</value>\n</property>\n```\n\n计算好数值，将问号处填写好后，yarn的配置就完成了。\n\n## <font color=#c00>启动服务</font>\n\n如果你之前已经启动了HDFS服务，这里只需系统yarn服务就可以了。\n\n``` bash\nsbin/start-yarn.sh \n```\n\n如果未启动，可以使用如下命令，启动Hadoop全部服务。\n\n``` bash\nsbin/start-all.sh \n```\n\n## <font color=#c00>测试</font>\n\n可以安装如下命令格式，提交编写好的jar包，及数据提交给MapReduce进行计算。\n\nbin/hadoop jar  [x.jar]  [hdfs://数据所在目录]  [hdfs://结果导出目录]\n\n结果返回到指定hdfs目录。结果集可以使用hdfs命令行查看，也可取回本地查看。\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://zookeeper.apache.org/doc/r3.4.10/)，文档版本3.4.10\n\n## <font color=#c00>小结</font>\n\n配置好YARN之后，我们就可以编写代码利用MapReduce完成基本的数据挖掘工作了，但MapReduce作为离线计算框架，在速度方面并不能让我们满意，我们需要更快速更灵活的计算框架。下篇文件我们开始[《Spark 部署》](/ai/hadoop-yrn/)\n\n本系列文章[《目录》](/ai/hadoop-start/)","source":"_posts/hadoop-yrn.md","raw":"---\ntitle: YARN 部署\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-03-20 10:18:18\n---\n上一篇文章我们已经完成了HDFS系统的部署，接下来我们开始YARN的配置，它是资源调度很重要的部分。依然选择在node0节点上进行配置。\n\n# Quick Start\n\n## <font color=#c00>MapReduce 资源调度配置</font>\n\nHadoop中计算引擎的运行方式有很多，在企业级应用中我们选择yarn作为资源调度的方式。\n\n### 配置MapReduce的资源调度方式\n\n复制etc/hadoop/mapred-site.xml.template为mapred-site.xml，并添加如下配置项：\n\n<!--more-->\n\n``` xml\n<property>\n   <name>mapreduce.framework.name</name>\n   <value>yarn</value>\n</property>\n```\n\n## <font color=#c00>YARN 配置</font>\n\n在etc/hadoop/yarn-site.xml文件中，添加如下配置项：\n\n### 资源申请的主机\n\n``` xml\n<property>\n   <name>yarn.resourcemanager.hostname</name>\n   <value>node0的IP</value>\n</property>\n```\n\n### NodeManager 附属服务\n\n``` xml\n<property>\n   <name>yarn.nodemanager.aux-services</name>\n   <value>mapreduce_shuffle</value>\n</property>\n```\n\n### 服务类（固定配置）\n\n``` xml\n<property>\n   <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>\n   <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n</property>\n```\n\n<font color=#c00>注：下面打问号的6个配置项，需要计算，才能得出（依据自己机器的节点数，每个节点的具体硬件配置，以及各自的任务需要）。这也是yarn配置的重点。如果想了解YARN在不同数量及配置的服务器中该如何计算，请[点击此处](https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.1/bk_installing_manually_book/content/rpm-chap1-11.html)，进行查看。</font>\n\n### 内存总量\n\n``` xml\n<property>\n   <name>yarn.nodemanager.resource.memory-mb</name>\n   <value>?</value>\n</property>\n```\n\n### 最小可申请内存量\n\n``` xml\n<property>\n   <name>yarn.scheduler.minimum-allocation-mb</name>\n   <value>?</value>\n</property>\n```\n\n### yarn启动时分配给AppMaster的默认内存大小\n\n``` xml\n<property>\n   <name>yarn.app.mapreduce.am.resource.mb</name>\n   <value>?</value>\n</property>\n```\n\n### JVM参数\n\n``` xml\n<property>\n   <name>yarn.app.mapreduce.am.command-opts</name>\n   <value>?</value>\n</property>\n```\n\n### 可供调用的CPU线程数\n\n<font color=#999>这个配置项指你分配多少个CPU线程供yarn调度，可以全部，也可以分配一部分，主要看这个节点的想如何使用。</font>\n\n``` xml\n<property>\n   <name>yarn.nodemanager.resource.cpu-vcores</name>\n   <value>?</value>\n</property>\n```\n\n### 单个任务可申请的最多CPU线程数\n\n``` xml\n<property>\n   <name>yarn.scheduler.maximum-allocation-vcores</name>\n   <value>?</value>\n</property>\n```\n\n计算好数值，将问号处填写好后，yarn的配置就完成了。\n\n## <font color=#c00>启动服务</font>\n\n如果你之前已经启动了HDFS服务，这里只需系统yarn服务就可以了。\n\n``` bash\nsbin/start-yarn.sh \n```\n\n如果未启动，可以使用如下命令，启动Hadoop全部服务。\n\n``` bash\nsbin/start-all.sh \n```\n\n## <font color=#c00>测试</font>\n\n可以安装如下命令格式，提交编写好的jar包，及数据提交给MapReduce进行计算。\n\nbin/hadoop jar  [x.jar]  [hdfs://数据所在目录]  [hdfs://结果导出目录]\n\n结果返回到指定hdfs目录。结果集可以使用hdfs命令行查看，也可取回本地查看。\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://zookeeper.apache.org/doc/r3.4.10/)，文档版本3.4.10\n\n## <font color=#c00>小结</font>\n\n配置好YARN之后，我们就可以编写代码利用MapReduce完成基本的数据挖掘工作了，但MapReduce作为离线计算框架，在速度方面并不能让我们满意，我们需要更快速更灵活的计算框架。下篇文件我们开始[《Spark 部署》](/ai/hadoop-yrn/)\n\n本系列文章[《目录》](/ai/hadoop-start/)","slug":"hadoop-yrn","published":1,"updated":"2018-03-30T09:52:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgup8x00183knadk59cpqz","content":"<p>上一篇文章我们已经完成了HDFS系统的部署，接下来我们开始YARN的配置，它是资源调度很重要的部分。依然选择在node0节点上进行配置。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"MapReduce-资源调度配置\"><a href=\"#MapReduce-资源调度配置\" class=\"headerlink\" title=\"MapReduce 资源调度配置\"></a><font color=\"#c00\">MapReduce 资源调度配置</font></h2><p>Hadoop中计算引擎的运行方式有很多，在企业级应用中我们选择yarn作为资源调度的方式。</p>\n<h3 id=\"配置MapReduce的资源调度方式\"><a href=\"#配置MapReduce的资源调度方式\" class=\"headerlink\" title=\"配置MapReduce的资源调度方式\"></a>配置MapReduce的资源调度方式</h3><p>复制etc/hadoop/mapred-site.xml.template为mapred-site.xml，并添加如下配置项：</p>\n<a id=\"more\"></a>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>mapreduce.framework.name<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>yarn<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"YARN-配置\"><a href=\"#YARN-配置\" class=\"headerlink\" title=\"YARN 配置\"></a><font color=\"#c00\">YARN 配置</font></h2><p>在etc/hadoop/yarn-site.xml文件中，添加如下配置项：</p>\n<h3 id=\"资源申请的主机\"><a href=\"#资源申请的主机\" class=\"headerlink\" title=\"资源申请的主机\"></a>资源申请的主机</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.resourcemanager.hostname<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node0的IP<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"NodeManager-附属服务\"><a href=\"#NodeManager-附属服务\" class=\"headerlink\" title=\"NodeManager 附属服务\"></a>NodeManager 附属服务</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.aux-services<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>mapreduce_shuffle<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"服务类（固定配置）\"><a href=\"#服务类（固定配置）\" class=\"headerlink\" title=\"服务类（固定配置）\"></a>服务类（固定配置）</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<font color=\"#c00\">注：下面打问号的6个配置项，需要计算，才能得出（依据自己机器的节点数，每个节点的具体硬件配置，以及各自的任务需要）。这也是yarn配置的重点。如果想了解YARN在不同数量及配置的服务器中该如何计算，请<a href=\"https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.1/bk_installing_manually_book/content/rpm-chap1-11.html\" target=\"_blank\" rel=\"noopener\">点击此处</a>，进行查看。</font>\n\n<h3 id=\"内存总量\"><a href=\"#内存总量\" class=\"headerlink\" title=\"内存总量\"></a>内存总量</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"最小可申请内存量\"><a href=\"#最小可申请内存量\" class=\"headerlink\" title=\"最小可申请内存量\"></a>最小可申请内存量</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"yarn启动时分配给AppMaster的默认内存大小\"><a href=\"#yarn启动时分配给AppMaster的默认内存大小\" class=\"headerlink\" title=\"yarn启动时分配给AppMaster的默认内存大小\"></a>yarn启动时分配给AppMaster的默认内存大小</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.app.mapreduce.am.resource.mb<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"JVM参数\"><a href=\"#JVM参数\" class=\"headerlink\" title=\"JVM参数\"></a>JVM参数</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.app.mapreduce.am.command-opts<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"可供调用的CPU线程数\"><a href=\"#可供调用的CPU线程数\" class=\"headerlink\" title=\"可供调用的CPU线程数\"></a>可供调用的CPU线程数</h3><font color=\"#999\">这个配置项指你分配多少个CPU线程供yarn调度，可以全部，也可以分配一部分，主要看这个节点的想如何使用。</font>\n\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"单个任务可申请的最多CPU线程数\"><a href=\"#单个任务可申请的最多CPU线程数\" class=\"headerlink\" title=\"单个任务可申请的最多CPU线程数\"></a>单个任务可申请的最多CPU线程数</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.scheduler.maximum-allocation-vcores<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>计算好数值，将问号处填写好后，yarn的配置就完成了。</p>\n<h2 id=\"启动服务\"><a href=\"#启动服务\" class=\"headerlink\" title=\"启动服务\"></a><font color=\"#c00\">启动服务</font></h2><p>如果你之前已经启动了HDFS服务，这里只需系统yarn服务就可以了。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>\n<p>如果未启动，可以使用如下命令，启动Hadoop全部服务。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/start-all.sh</span><br></pre></td></tr></table></figure>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a><font color=\"#c00\">测试</font></h2><p>可以安装如下命令格式，提交编写好的jar包，及数据提交给MapReduce进行计算。</p>\n<p>bin/hadoop jar  [x.jar]  [hdfs://数据所在目录]  [hdfs://结果导出目录]</p>\n<p>结果返回到指定hdfs目录。结果集可以使用hdfs命令行查看，也可取回本地查看。</p>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://zookeeper.apache.org/doc/r3.4.10/\" target=\"_blank\" rel=\"noopener\">官方文档</a>，文档版本3.4.10</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>配置好YARN之后，我们就可以编写代码利用MapReduce完成基本的数据挖掘工作了，但MapReduce作为离线计算框架，在速度方面并不能让我们满意，我们需要更快速更灵活的计算框架。下篇文件我们开始<a href=\"/ai/hadoop-yrn/\">《Spark 部署》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>\n","site":{"data":{}},"excerpt":"<p>上一篇文章我们已经完成了HDFS系统的部署，接下来我们开始YARN的配置，它是资源调度很重要的部分。依然选择在node0节点上进行配置。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"MapReduce-资源调度配置\"><a href=\"#MapReduce-资源调度配置\" class=\"headerlink\" title=\"MapReduce 资源调度配置\"></a><font color=\"#c00\">MapReduce 资源调度配置</font></h2><p>Hadoop中计算引擎的运行方式有很多，在企业级应用中我们选择yarn作为资源调度的方式。</p>\n<h3 id=\"配置MapReduce的资源调度方式\"><a href=\"#配置MapReduce的资源调度方式\" class=\"headerlink\" title=\"配置MapReduce的资源调度方式\"></a>配置MapReduce的资源调度方式</h3><p>复制etc/hadoop/mapred-site.xml.template为mapred-site.xml，并添加如下配置项：</p>","more":"<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>mapreduce.framework.name<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>yarn<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"YARN-配置\"><a href=\"#YARN-配置\" class=\"headerlink\" title=\"YARN 配置\"></a><font color=\"#c00\">YARN 配置</font></h2><p>在etc/hadoop/yarn-site.xml文件中，添加如下配置项：</p>\n<h3 id=\"资源申请的主机\"><a href=\"#资源申请的主机\" class=\"headerlink\" title=\"资源申请的主机\"></a>资源申请的主机</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.resourcemanager.hostname<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>node0的IP<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"NodeManager-附属服务\"><a href=\"#NodeManager-附属服务\" class=\"headerlink\" title=\"NodeManager 附属服务\"></a>NodeManager 附属服务</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.aux-services<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>mapreduce_shuffle<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"服务类（固定配置）\"><a href=\"#服务类（固定配置）\" class=\"headerlink\" title=\"服务类（固定配置）\"></a>服务类（固定配置）</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<font color=\"#c00\">注：下面打问号的6个配置项，需要计算，才能得出（依据自己机器的节点数，每个节点的具体硬件配置，以及各自的任务需要）。这也是yarn配置的重点。如果想了解YARN在不同数量及配置的服务器中该如何计算，请<a href=\"https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.1/bk_installing_manually_book/content/rpm-chap1-11.html\" target=\"_blank\" rel=\"noopener\">点击此处</a>，进行查看。</font>\n\n<h3 id=\"内存总量\"><a href=\"#内存总量\" class=\"headerlink\" title=\"内存总量\"></a>内存总量</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"最小可申请内存量\"><a href=\"#最小可申请内存量\" class=\"headerlink\" title=\"最小可申请内存量\"></a>最小可申请内存量</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"yarn启动时分配给AppMaster的默认内存大小\"><a href=\"#yarn启动时分配给AppMaster的默认内存大小\" class=\"headerlink\" title=\"yarn启动时分配给AppMaster的默认内存大小\"></a>yarn启动时分配给AppMaster的默认内存大小</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.app.mapreduce.am.resource.mb<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"JVM参数\"><a href=\"#JVM参数\" class=\"headerlink\" title=\"JVM参数\"></a>JVM参数</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.app.mapreduce.am.command-opts<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"可供调用的CPU线程数\"><a href=\"#可供调用的CPU线程数\" class=\"headerlink\" title=\"可供调用的CPU线程数\"></a>可供调用的CPU线程数</h3><font color=\"#999\">这个配置项指你分配多少个CPU线程供yarn调度，可以全部，也可以分配一部分，主要看这个节点的想如何使用。</font>\n\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"单个任务可申请的最多CPU线程数\"><a href=\"#单个任务可申请的最多CPU线程数\" class=\"headerlink\" title=\"单个任务可申请的最多CPU线程数\"></a>单个任务可申请的最多CPU线程数</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.scheduler.maximum-allocation-vcores<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>?<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>计算好数值，将问号处填写好后，yarn的配置就完成了。</p>\n<h2 id=\"启动服务\"><a href=\"#启动服务\" class=\"headerlink\" title=\"启动服务\"></a><font color=\"#c00\">启动服务</font></h2><p>如果你之前已经启动了HDFS服务，这里只需系统yarn服务就可以了。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>\n<p>如果未启动，可以使用如下命令，启动Hadoop全部服务。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sbin/start-all.sh</span><br></pre></td></tr></table></figure>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a><font color=\"#c00\">测试</font></h2><p>可以安装如下命令格式，提交编写好的jar包，及数据提交给MapReduce进行计算。</p>\n<p>bin/hadoop jar  [x.jar]  [hdfs://数据所在目录]  [hdfs://结果导出目录]</p>\n<p>结果返回到指定hdfs目录。结果集可以使用hdfs命令行查看，也可取回本地查看。</p>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://zookeeper.apache.org/doc/r3.4.10/\" target=\"_blank\" rel=\"noopener\">官方文档</a>，文档版本3.4.10</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>配置好YARN之后，我们就可以编写代码利用MapReduce完成基本的数据挖掘工作了，但MapReduce作为离线计算框架，在速度方面并不能让我们满意，我们需要更快速更灵活的计算框架。下篇文件我们开始<a href=\"/ai/hadoop-yrn/\">《Spark 部署》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>"},{"title":"Linux 硬件及系统信息查询","date":"2017-04-25T00:36:53.000Z","_content":"最近在做一些与服务器硬件相关的事情，总是需要查询服务器的硬件信息<font color=#999>（Linux上查询这些信息的确没有Windows上简单直观，且很多命令对我来说并不常用，完全记不住啊... - -!）</font>\n\n这文章，帮助自己下次查询，有用的上的朋友也可以look look ：）\n\n# Quick Start\n\n## <font color=#c00>主板</font>\n\n### 基础信息\n\n``` bash\ndmidecode | more\n```\n\n<!--more-->\n\n### 内存次插槽数，及每个槽位内存条大小\n\n``` bash\ndmidecode|grep -P -A5 \"Memory\\s+Device\"|grep Size|grep -v Range\n```\n\n### 查看最大支持内存容量\n\n``` bash\ndmidecode|grep -P 'Maximum\\s+Capacity'\n```\n\n## <font color=#c00>CPU</font>\n\n### 基础信息\n\n``` bash\ncat /proc/cpuinfo\n```\n\n![cpuinfo](/images/post/other/oth1.png)\n\n### 物理CPU个数\n\n``` bash\ncat /proc/cpuinfo| grep \"physical id\"| sort| uniq| wc -l\n```\n\n### 单个物理CPU的核数\n\n``` bash\ncat /proc/cpuinfo| grep \"cpu cores\"| uniq\n```\n\n### 单个物理CPU的线程数<font color=#999>（逻辑CPU）</font>\n\n``` bash\ncat /proc/cpuinfo| grep \"processor\"| wc -l\n```\n\n### 是否开启超线程\n\n- 逻辑CPU  >  物理CPU  x   CPU核数 <font color=#999>（已开启超线程）</font>\n- 逻辑CPU  =  物理CPU  x   CPU核数 <font color=#999>（未开启超线程或不支持超线程）</font>\n\n## <font color=#c00>内存</font>\n\n### 基础信息\n\n``` bash\ncat /proc/meminfo\n```\n\n\n### 内存使用及缓存信息\n\n``` bash\nfree\n```\n\n## <font color=#c00>硬盘</font>\n\n### 基础信息\n\n``` bash\nfdisk -l\n```\n\n### 磁盘分区\n\n``` bash\ndf\n```\n\n## <font color=#c00>外设</font>\n\n### 键盘鼠标\n\n``` bash\ncat /proc/bus/input/devices\n```\n\n## <font color=#c00>PCI</font>\n\n### 基础信息\n\n``` bash\nlspci\n```\n\n## <font color=#c00>查看系统版本</font>\n\n### 查看内核版本\n\n``` bash\ncat /proc/version\n```\n\n### 查看发行版本\n\n``` bash\ncat /etc/issue\n```\n\n查看issue有些系统返回为空，如果是redhat系列的版本可用如下命令查看：\n\n``` bash\ncat /etc/redhat-release\n```\n\n","source":"_posts/linux-info.md","raw":"---\ntitle: Linux 硬件及系统信息查询\ncategories:\n  - other\ntags:\n  - Linux\ndate: 2017-04-25 08:36:53\n---\n最近在做一些与服务器硬件相关的事情，总是需要查询服务器的硬件信息<font color=#999>（Linux上查询这些信息的确没有Windows上简单直观，且很多命令对我来说并不常用，完全记不住啊... - -!）</font>\n\n这文章，帮助自己下次查询，有用的上的朋友也可以look look ：）\n\n# Quick Start\n\n## <font color=#c00>主板</font>\n\n### 基础信息\n\n``` bash\ndmidecode | more\n```\n\n<!--more-->\n\n### 内存次插槽数，及每个槽位内存条大小\n\n``` bash\ndmidecode|grep -P -A5 \"Memory\\s+Device\"|grep Size|grep -v Range\n```\n\n### 查看最大支持内存容量\n\n``` bash\ndmidecode|grep -P 'Maximum\\s+Capacity'\n```\n\n## <font color=#c00>CPU</font>\n\n### 基础信息\n\n``` bash\ncat /proc/cpuinfo\n```\n\n![cpuinfo](/images/post/other/oth1.png)\n\n### 物理CPU个数\n\n``` bash\ncat /proc/cpuinfo| grep \"physical id\"| sort| uniq| wc -l\n```\n\n### 单个物理CPU的核数\n\n``` bash\ncat /proc/cpuinfo| grep \"cpu cores\"| uniq\n```\n\n### 单个物理CPU的线程数<font color=#999>（逻辑CPU）</font>\n\n``` bash\ncat /proc/cpuinfo| grep \"processor\"| wc -l\n```\n\n### 是否开启超线程\n\n- 逻辑CPU  >  物理CPU  x   CPU核数 <font color=#999>（已开启超线程）</font>\n- 逻辑CPU  =  物理CPU  x   CPU核数 <font color=#999>（未开启超线程或不支持超线程）</font>\n\n## <font color=#c00>内存</font>\n\n### 基础信息\n\n``` bash\ncat /proc/meminfo\n```\n\n\n### 内存使用及缓存信息\n\n``` bash\nfree\n```\n\n## <font color=#c00>硬盘</font>\n\n### 基础信息\n\n``` bash\nfdisk -l\n```\n\n### 磁盘分区\n\n``` bash\ndf\n```\n\n## <font color=#c00>外设</font>\n\n### 键盘鼠标\n\n``` bash\ncat /proc/bus/input/devices\n```\n\n## <font color=#c00>PCI</font>\n\n### 基础信息\n\n``` bash\nlspci\n```\n\n## <font color=#c00>查看系统版本</font>\n\n### 查看内核版本\n\n``` bash\ncat /proc/version\n```\n\n### 查看发行版本\n\n``` bash\ncat /etc/issue\n```\n\n查看issue有些系统返回为空，如果是redhat系列的版本可用如下命令查看：\n\n``` bash\ncat /etc/redhat-release\n```\n\n","slug":"linux-info","published":1,"updated":"2018-03-30T09:52:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgupdj001e3knavbeu4jwz","content":"<p>最近在做一些与服务器硬件相关的事情，总是需要查询服务器的硬件信息<font color=\"#999\">（Linux上查询这些信息的确没有Windows上简单直观，且很多命令对我来说并不常用，完全记不住啊… - -!）</font></p>\n<p>这文章，帮助自己下次查询，有用的上的朋友也可以look look ：）</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"主板\"><a href=\"#主板\" class=\"headerlink\" title=\"主板\"></a><font color=\"#c00\">主板</font></h2><h3 id=\"基础信息\"><a href=\"#基础信息\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dmidecode | more</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<h3 id=\"内存次插槽数，及每个槽位内存条大小\"><a href=\"#内存次插槽数，及每个槽位内存条大小\" class=\"headerlink\" title=\"内存次插槽数，及每个槽位内存条大小\"></a>内存次插槽数，及每个槽位内存条大小</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dmidecode|grep -P -A5 <span class=\"string\">\"Memory\\s+Device\"</span>|grep Size|grep -v Range</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看最大支持内存容量\"><a href=\"#查看最大支持内存容量\" class=\"headerlink\" title=\"查看最大支持内存容量\"></a>查看最大支持内存容量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dmidecode|grep -P <span class=\"string\">'Maximum\\s+Capacity'</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"CPU\"><a href=\"#CPU\" class=\"headerlink\" title=\"CPU\"></a><font color=\"#c00\">CPU</font></h2><h3 id=\"基础信息-1\"><a href=\"#基础信息-1\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/cpuinfo</span><br></pre></td></tr></table></figure>\n<p><img src=\"/images/post/other/oth1.png\" alt=\"cpuinfo\"></p>\n<h3 id=\"物理CPU个数\"><a href=\"#物理CPU个数\" class=\"headerlink\" title=\"物理CPU个数\"></a>物理CPU个数</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/cpuinfo| grep <span class=\"string\">\"physical id\"</span>| sort| uniq| wc -l</span><br></pre></td></tr></table></figure>\n<h3 id=\"单个物理CPU的核数\"><a href=\"#单个物理CPU的核数\" class=\"headerlink\" title=\"单个物理CPU的核数\"></a>单个物理CPU的核数</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/cpuinfo| grep <span class=\"string\">\"cpu cores\"</span>| uniq</span><br></pre></td></tr></table></figure>\n<h3 id=\"单个物理CPU的线程数（逻辑CPU）\"><a href=\"#单个物理CPU的线程数（逻辑CPU）\" class=\"headerlink\" title=\"单个物理CPU的线程数（逻辑CPU）\"></a>单个物理CPU的线程数<font color=\"#999\">（逻辑CPU）</font></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/cpuinfo| grep <span class=\"string\">\"processor\"</span>| wc -l</span><br></pre></td></tr></table></figure>\n<h3 id=\"是否开启超线程\"><a href=\"#是否开启超线程\" class=\"headerlink\" title=\"是否开启超线程\"></a>是否开启超线程</h3><ul>\n<li>逻辑CPU  &gt;  物理CPU  x   CPU核数 <font color=\"#999\">（已开启超线程）</font></li>\n<li>逻辑CPU  =  物理CPU  x   CPU核数 <font color=\"#999\">（未开启超线程或不支持超线程）</font></li>\n</ul>\n<h2 id=\"内存\"><a href=\"#内存\" class=\"headerlink\" title=\"内存\"></a><font color=\"#c00\">内存</font></h2><h3 id=\"基础信息-2\"><a href=\"#基础信息-2\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/meminfo</span><br></pre></td></tr></table></figure>\n<h3 id=\"内存使用及缓存信息\"><a href=\"#内存使用及缓存信息\" class=\"headerlink\" title=\"内存使用及缓存信息\"></a>内存使用及缓存信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">free</span><br></pre></td></tr></table></figure>\n<h2 id=\"硬盘\"><a href=\"#硬盘\" class=\"headerlink\" title=\"硬盘\"></a><font color=\"#c00\">硬盘</font></h2><h3 id=\"基础信息-3\"><a href=\"#基础信息-3\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fdisk -l</span><br></pre></td></tr></table></figure>\n<h3 id=\"磁盘分区\"><a href=\"#磁盘分区\" class=\"headerlink\" title=\"磁盘分区\"></a>磁盘分区</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df</span><br></pre></td></tr></table></figure>\n<h2 id=\"外设\"><a href=\"#外设\" class=\"headerlink\" title=\"外设\"></a><font color=\"#c00\">外设</font></h2><h3 id=\"键盘鼠标\"><a href=\"#键盘鼠标\" class=\"headerlink\" title=\"键盘鼠标\"></a>键盘鼠标</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/bus/input/devices</span><br></pre></td></tr></table></figure>\n<h2 id=\"PCI\"><a href=\"#PCI\" class=\"headerlink\" title=\"PCI\"></a><font color=\"#c00\">PCI</font></h2><h3 id=\"基础信息-4\"><a href=\"#基础信息-4\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lspci</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看系统版本\"><a href=\"#查看系统版本\" class=\"headerlink\" title=\"查看系统版本\"></a><font color=\"#c00\">查看系统版本</font></h2><h3 id=\"查看内核版本\"><a href=\"#查看内核版本\" class=\"headerlink\" title=\"查看内核版本\"></a>查看内核版本</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/version</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看发行版本\"><a href=\"#查看发行版本\" class=\"headerlink\" title=\"查看发行版本\"></a>查看发行版本</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /etc/issue</span><br></pre></td></tr></table></figure>\n<p>查看issue有些系统返回为空，如果是redhat系列的版本可用如下命令查看：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /etc/redhat-release</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>最近在做一些与服务器硬件相关的事情，总是需要查询服务器的硬件信息<font color=\"#999\">（Linux上查询这些信息的确没有Windows上简单直观，且很多命令对我来说并不常用，完全记不住啊… - -!）</font></p>\n<p>这文章，帮助自己下次查询，有用的上的朋友也可以look look ：）</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"主板\"><a href=\"#主板\" class=\"headerlink\" title=\"主板\"></a><font color=\"#c00\">主板</font></h2><h3 id=\"基础信息\"><a href=\"#基础信息\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dmidecode | more</span><br></pre></td></tr></table></figure>","more":"<h3 id=\"内存次插槽数，及每个槽位内存条大小\"><a href=\"#内存次插槽数，及每个槽位内存条大小\" class=\"headerlink\" title=\"内存次插槽数，及每个槽位内存条大小\"></a>内存次插槽数，及每个槽位内存条大小</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dmidecode|grep -P -A5 <span class=\"string\">\"Memory\\s+Device\"</span>|grep Size|grep -v Range</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看最大支持内存容量\"><a href=\"#查看最大支持内存容量\" class=\"headerlink\" title=\"查看最大支持内存容量\"></a>查看最大支持内存容量</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dmidecode|grep -P <span class=\"string\">'Maximum\\s+Capacity'</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"CPU\"><a href=\"#CPU\" class=\"headerlink\" title=\"CPU\"></a><font color=\"#c00\">CPU</font></h2><h3 id=\"基础信息-1\"><a href=\"#基础信息-1\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/cpuinfo</span><br></pre></td></tr></table></figure>\n<p><img src=\"/images/post/other/oth1.png\" alt=\"cpuinfo\"></p>\n<h3 id=\"物理CPU个数\"><a href=\"#物理CPU个数\" class=\"headerlink\" title=\"物理CPU个数\"></a>物理CPU个数</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/cpuinfo| grep <span class=\"string\">\"physical id\"</span>| sort| uniq| wc -l</span><br></pre></td></tr></table></figure>\n<h3 id=\"单个物理CPU的核数\"><a href=\"#单个物理CPU的核数\" class=\"headerlink\" title=\"单个物理CPU的核数\"></a>单个物理CPU的核数</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/cpuinfo| grep <span class=\"string\">\"cpu cores\"</span>| uniq</span><br></pre></td></tr></table></figure>\n<h3 id=\"单个物理CPU的线程数（逻辑CPU）\"><a href=\"#单个物理CPU的线程数（逻辑CPU）\" class=\"headerlink\" title=\"单个物理CPU的线程数（逻辑CPU）\"></a>单个物理CPU的线程数<font color=\"#999\">（逻辑CPU）</font></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/cpuinfo| grep <span class=\"string\">\"processor\"</span>| wc -l</span><br></pre></td></tr></table></figure>\n<h3 id=\"是否开启超线程\"><a href=\"#是否开启超线程\" class=\"headerlink\" title=\"是否开启超线程\"></a>是否开启超线程</h3><ul>\n<li>逻辑CPU  &gt;  物理CPU  x   CPU核数 <font color=\"#999\">（已开启超线程）</font></li>\n<li>逻辑CPU  =  物理CPU  x   CPU核数 <font color=\"#999\">（未开启超线程或不支持超线程）</font></li>\n</ul>\n<h2 id=\"内存\"><a href=\"#内存\" class=\"headerlink\" title=\"内存\"></a><font color=\"#c00\">内存</font></h2><h3 id=\"基础信息-2\"><a href=\"#基础信息-2\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/meminfo</span><br></pre></td></tr></table></figure>\n<h3 id=\"内存使用及缓存信息\"><a href=\"#内存使用及缓存信息\" class=\"headerlink\" title=\"内存使用及缓存信息\"></a>内存使用及缓存信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">free</span><br></pre></td></tr></table></figure>\n<h2 id=\"硬盘\"><a href=\"#硬盘\" class=\"headerlink\" title=\"硬盘\"></a><font color=\"#c00\">硬盘</font></h2><h3 id=\"基础信息-3\"><a href=\"#基础信息-3\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fdisk -l</span><br></pre></td></tr></table></figure>\n<h3 id=\"磁盘分区\"><a href=\"#磁盘分区\" class=\"headerlink\" title=\"磁盘分区\"></a>磁盘分区</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df</span><br></pre></td></tr></table></figure>\n<h2 id=\"外设\"><a href=\"#外设\" class=\"headerlink\" title=\"外设\"></a><font color=\"#c00\">外设</font></h2><h3 id=\"键盘鼠标\"><a href=\"#键盘鼠标\" class=\"headerlink\" title=\"键盘鼠标\"></a>键盘鼠标</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/bus/input/devices</span><br></pre></td></tr></table></figure>\n<h2 id=\"PCI\"><a href=\"#PCI\" class=\"headerlink\" title=\"PCI\"></a><font color=\"#c00\">PCI</font></h2><h3 id=\"基础信息-4\"><a href=\"#基础信息-4\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lspci</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看系统版本\"><a href=\"#查看系统版本\" class=\"headerlink\" title=\"查看系统版本\"></a><font color=\"#c00\">查看系统版本</font></h2><h3 id=\"查看内核版本\"><a href=\"#查看内核版本\" class=\"headerlink\" title=\"查看内核版本\"></a>查看内核版本</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/version</span><br></pre></td></tr></table></figure>\n<h3 id=\"查看发行版本\"><a href=\"#查看发行版本\" class=\"headerlink\" title=\"查看发行版本\"></a>查看发行版本</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /etc/issue</span><br></pre></td></tr></table></figure>\n<p>查看issue有些系统返回为空，如果是redhat系列的版本可用如下命令查看：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /etc/redhat-release</span><br></pre></td></tr></table></figure>"},{"title":"ZooKeeper 部署","date":"2018-03-19T10:01:58.000Z","_content":"[ZooKeeper](https://baike.baidu.com/item/zookeeper/4836397?fr=aladdin)是分布式应用程序协调服务，在分布式系统中必不可少。它是为分布式应用提供一致性服务的软件，所以我们首先来安装配置它。\n\n安装前，我们需要先准备好安装包，点击[官方下载地址](http://zookeeper.apache.org/releases.html)，本文所使用的版本是3.4.10\n\n# Quick Start\n\n## <font color=#c00>创建目录</font>\n\n1. 在解压后的文件夹中创建一个名为tmp文件夹，作为其工作目录。\n2. 再创建一个名为zk_data文件夹，作为其数据存储目录。\n\n<!--more-->\n\n## <font color=#c00>配置</font>\n\n1. 拷贝conf/zoo_sample.cfg文件，并重命名zoo.cfg <font color=#c00>（这里必须命名为zoo.cfg）</font>\n\n2. 修改zoo.cfg文件，内容如下：\n\t``` bash\n\ttickTime=2000\n\tdataDir=/opt/zookeeper-3.4.10/zk_data\n\tclientPort=2181\n\tinitLimit=5\n\tsyncLimit=2\n\tserver.1=node0的IP:2888:3888\n\tserver.2=node2的IP:2888:3888\n\tserver.3=node3的IP:2888:3888\n\t```\n\n3. 将此配置分别配置到 node0， node2， node3中\n\n4. 按照规划ZooKeeper会被部署在node0，node2，node3上，所以需要在这三台服务器中都拷贝一份。\n\t``` bash\n\tscp -r /opt/zookeeper-3.4.10 root@node2:/opt\n\tscp -r /opt/zookeeper-3.4.10 root@node3:/opt\n\t```\n\n5. 分别在这三个节点的dataDir指向的目录下创建myid文件，值分别为1，2，3\n\n6. 在node0，node2，node3中依次启动服务，命令如下：\n\t``` bash\n\tbin/zkServer.sh start\n\t```\n\n7. 查看服务是否已经启动\n\t``` bash\n\tzkserver.sh status\n\t```\n\n\t如果遇到Error contacting service. It is probably not running 此错误，请查看对应版本的官方文档重新配置zoo.cfg。\n\t如果是java.net.BindException: Address already in use 通过netstat -nltp | grep 2181检查是否该端口已被占用。\n\t如果，遇到防火墙原因，请继续往下看。\n\n## <font color=#c00>关闭防火墙​</font>\n\n关闭所有服务器的防火墙<font color=#c00>（重点）</font>\n\n- firewall\n\n\t查看防火墙状态\n\t``` bash\n\tfirewall-cmd --state\n\t```\n\n\t关闭防火墙\n\t``` bash\n\tsystemctl stop firewalld.service\n\t```\n\n\t禁止开机启动\n\t``` bash\n\tsystemctl disable firewalld.service\n\t```\n\n- 关闭iptables\n\n\t``` bash\n\tservice iptables stop\n\t```\n\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://zookeeper.apache.org/doc/r3.4.10/)，文档版本3.4.10\n\n## <font color=#c00>小结</font>\n\n完成上述配置后，ZooKeeper应该可以正常启动了，下篇文件我们开始[《部署 HDFS》](/ai/hadoop-dfs/)\n\n本系列文章[《目录》](/ai/hadoop-start/)\n\n","source":"_posts/hadoop-zkp.md","raw":"---\ntitle: ZooKeeper 部署\ncategories:\n  - ai\ntags:\n  - 大数据\ndate: 2018-03-19 18:01:58\n---\n[ZooKeeper](https://baike.baidu.com/item/zookeeper/4836397?fr=aladdin)是分布式应用程序协调服务，在分布式系统中必不可少。它是为分布式应用提供一致性服务的软件，所以我们首先来安装配置它。\n\n安装前，我们需要先准备好安装包，点击[官方下载地址](http://zookeeper.apache.org/releases.html)，本文所使用的版本是3.4.10\n\n# Quick Start\n\n## <font color=#c00>创建目录</font>\n\n1. 在解压后的文件夹中创建一个名为tmp文件夹，作为其工作目录。\n2. 再创建一个名为zk_data文件夹，作为其数据存储目录。\n\n<!--more-->\n\n## <font color=#c00>配置</font>\n\n1. 拷贝conf/zoo_sample.cfg文件，并重命名zoo.cfg <font color=#c00>（这里必须命名为zoo.cfg）</font>\n\n2. 修改zoo.cfg文件，内容如下：\n\t``` bash\n\ttickTime=2000\n\tdataDir=/opt/zookeeper-3.4.10/zk_data\n\tclientPort=2181\n\tinitLimit=5\n\tsyncLimit=2\n\tserver.1=node0的IP:2888:3888\n\tserver.2=node2的IP:2888:3888\n\tserver.3=node3的IP:2888:3888\n\t```\n\n3. 将此配置分别配置到 node0， node2， node3中\n\n4. 按照规划ZooKeeper会被部署在node0，node2，node3上，所以需要在这三台服务器中都拷贝一份。\n\t``` bash\n\tscp -r /opt/zookeeper-3.4.10 root@node2:/opt\n\tscp -r /opt/zookeeper-3.4.10 root@node3:/opt\n\t```\n\n5. 分别在这三个节点的dataDir指向的目录下创建myid文件，值分别为1，2，3\n\n6. 在node0，node2，node3中依次启动服务，命令如下：\n\t``` bash\n\tbin/zkServer.sh start\n\t```\n\n7. 查看服务是否已经启动\n\t``` bash\n\tzkserver.sh status\n\t```\n\n\t如果遇到Error contacting service. It is probably not running 此错误，请查看对应版本的官方文档重新配置zoo.cfg。\n\t如果是java.net.BindException: Address already in use 通过netstat -nltp | grep 2181检查是否该端口已被占用。\n\t如果，遇到防火墙原因，请继续往下看。\n\n## <font color=#c00>关闭防火墙​</font>\n\n关闭所有服务器的防火墙<font color=#c00>（重点）</font>\n\n- firewall\n\n\t查看防火墙状态\n\t``` bash\n\tfirewall-cmd --state\n\t```\n\n\t关闭防火墙\n\t``` bash\n\tsystemctl stop firewalld.service\n\t```\n\n\t禁止开机启动\n\t``` bash\n\tsystemctl disable firewalld.service\n\t```\n\n- 关闭iptables\n\n\t``` bash\n\tservice iptables stop\n\t```\n\n\n## <font color=#c00>官方文档</font>\n\n如果需要了解更详细的内容，请访问[官方文档](http://zookeeper.apache.org/doc/r3.4.10/)，文档版本3.4.10\n\n## <font color=#c00>小结</font>\n\n完成上述配置后，ZooKeeper应该可以正常启动了，下篇文件我们开始[《部署 HDFS》](/ai/hadoop-dfs/)\n\n本系列文章[《目录》](/ai/hadoop-start/)\n\n","slug":"hadoop-zkp","published":1,"updated":"2018-03-28T09:23:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgupdl001g3knaep4ek4co","content":"<p><a href=\"https://baike.baidu.com/item/zookeeper/4836397?fr=aladdin\" target=\"_blank\" rel=\"noopener\">ZooKeeper</a>是分布式应用程序协调服务，在分布式系统中必不可少。它是为分布式应用提供一致性服务的软件，所以我们首先来安装配置它。</p>\n<p>安装前，我们需要先准备好安装包，点击<a href=\"http://zookeeper.apache.org/releases.html\" target=\"_blank\" rel=\"noopener\">官方下载地址</a>，本文所使用的版本是3.4.10</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"创建目录\"><a href=\"#创建目录\" class=\"headerlink\" title=\"创建目录\"></a><font color=\"#c00\">创建目录</font></h2><ol>\n<li>在解压后的文件夹中创建一个名为tmp文件夹，作为其工作目录。</li>\n<li>再创建一个名为zk_data文件夹，作为其数据存储目录。</li>\n</ol>\n<a id=\"more\"></a>\n<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a><font color=\"#c00\">配置</font></h2><ol>\n<li><p>拷贝conf/zoo_sample.cfg文件，并重命名zoo.cfg <font color=\"#c00\">（这里必须命名为zoo.cfg）</font></p>\n</li>\n<li><p>修改zoo.cfg文件，内容如下：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tickTime=2000</span><br><span class=\"line\">dataDir=/opt/zookeeper-3.4.10/zk_data</span><br><span class=\"line\">clientPort=2181</span><br><span class=\"line\">initLimit=5</span><br><span class=\"line\">syncLimit=2</span><br><span class=\"line\">server.1=node0的IP:2888:3888</span><br><span class=\"line\">server.2=node2的IP:2888:3888</span><br><span class=\"line\">server.3=node3的IP:2888:3888</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>将此配置分别配置到 node0， node2， node3中</p>\n</li>\n<li><p>按照规划ZooKeeper会被部署在node0，node2，node3上，所以需要在这三台服务器中都拷贝一份。</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp -r /opt/zookeeper-3.4.10 root@node2:/opt</span><br><span class=\"line\">scp -r /opt/zookeeper-3.4.10 root@node3:/opt</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>分别在这三个节点的dataDir指向的目录下创建myid文件，值分别为1，2，3</p>\n</li>\n<li><p>在node0，node2，node3中依次启动服务，命令如下：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/zkServer.sh start</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查看服务是否已经启动</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zkserver.sh status</span><br></pre></td></tr></table></figure>\n<p> 如果遇到Error contacting service. It is probably not running 此错误，请查看对应版本的官方文档重新配置zoo.cfg。<br> 如果是java.net.BindException: Address already in use 通过netstat -nltp | grep 2181检查是否该端口已被占用。<br> 如果，遇到防火墙原因，请继续往下看。</p>\n</li>\n</ol>\n<h2 id=\"关闭防火墙​\"><a href=\"#关闭防火墙​\" class=\"headerlink\" title=\"关闭防火墙​\"></a><font color=\"#c00\">关闭防火墙​</font></h2><p>关闭所有服务器的防火墙<font color=\"#c00\">（重点）</font></p>\n<ul>\n<li><p>firewall</p>\n<p>  查看防火墙状态</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">firewall-cmd --state</span><br></pre></td></tr></table></figure>\n<p>  关闭防火墙</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>\n<p>  禁止开机启动</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl <span class=\"built_in\">disable</span> firewalld.service</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>关闭iptables</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">service iptables stop</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://zookeeper.apache.org/doc/r3.4.10/\" target=\"_blank\" rel=\"noopener\">官方文档</a>，文档版本3.4.10</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成上述配置后，ZooKeeper应该可以正常启动了，下篇文件我们开始<a href=\"/ai/hadoop-dfs/\">《部署 HDFS》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>\n","site":{"data":{}},"excerpt":"<p><a href=\"https://baike.baidu.com/item/zookeeper/4836397?fr=aladdin\" target=\"_blank\" rel=\"noopener\">ZooKeeper</a>是分布式应用程序协调服务，在分布式系统中必不可少。它是为分布式应用提供一致性服务的软件，所以我们首先来安装配置它。</p>\n<p>安装前，我们需要先准备好安装包，点击<a href=\"http://zookeeper.apache.org/releases.html\" target=\"_blank\" rel=\"noopener\">官方下载地址</a>，本文所使用的版本是3.4.10</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"创建目录\"><a href=\"#创建目录\" class=\"headerlink\" title=\"创建目录\"></a><font color=\"#c00\">创建目录</font></h2><ol>\n<li>在解压后的文件夹中创建一个名为tmp文件夹，作为其工作目录。</li>\n<li>再创建一个名为zk_data文件夹，作为其数据存储目录。</li>\n</ol>","more":"<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a><font color=\"#c00\">配置</font></h2><ol>\n<li><p>拷贝conf/zoo_sample.cfg文件，并重命名zoo.cfg <font color=\"#c00\">（这里必须命名为zoo.cfg）</font></p>\n</li>\n<li><p>修改zoo.cfg文件，内容如下：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tickTime=2000</span><br><span class=\"line\">dataDir=/opt/zookeeper-3.4.10/zk_data</span><br><span class=\"line\">clientPort=2181</span><br><span class=\"line\">initLimit=5</span><br><span class=\"line\">syncLimit=2</span><br><span class=\"line\">server.1=node0的IP:2888:3888</span><br><span class=\"line\">server.2=node2的IP:2888:3888</span><br><span class=\"line\">server.3=node3的IP:2888:3888</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>将此配置分别配置到 node0， node2， node3中</p>\n</li>\n<li><p>按照规划ZooKeeper会被部署在node0，node2，node3上，所以需要在这三台服务器中都拷贝一份。</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scp -r /opt/zookeeper-3.4.10 root@node2:/opt</span><br><span class=\"line\">scp -r /opt/zookeeper-3.4.10 root@node3:/opt</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>分别在这三个节点的dataDir指向的目录下创建myid文件，值分别为1，2，3</p>\n</li>\n<li><p>在node0，node2，node3中依次启动服务，命令如下：</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/zkServer.sh start</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查看服务是否已经启动</p>\n <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">zkserver.sh status</span><br></pre></td></tr></table></figure>\n<p> 如果遇到Error contacting service. It is probably not running 此错误，请查看对应版本的官方文档重新配置zoo.cfg。<br> 如果是java.net.BindException: Address already in use 通过netstat -nltp | grep 2181检查是否该端口已被占用。<br> 如果，遇到防火墙原因，请继续往下看。</p>\n</li>\n</ol>\n<h2 id=\"关闭防火墙​\"><a href=\"#关闭防火墙​\" class=\"headerlink\" title=\"关闭防火墙​\"></a><font color=\"#c00\">关闭防火墙​</font></h2><p>关闭所有服务器的防火墙<font color=\"#c00\">（重点）</font></p>\n<ul>\n<li><p>firewall</p>\n<p>  查看防火墙状态</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">firewall-cmd --state</span><br></pre></td></tr></table></figure>\n<p>  关闭防火墙</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>\n<p>  禁止开机启动</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl <span class=\"built_in\">disable</span> firewalld.service</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>关闭iptables</p>\n  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">service iptables stop</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"官方文档\"><a href=\"#官方文档\" class=\"headerlink\" title=\"官方文档\"></a><font color=\"#c00\">官方文档</font></h2><p>如果需要了解更详细的内容，请访问<a href=\"http://zookeeper.apache.org/doc/r3.4.10/\" target=\"_blank\" rel=\"noopener\">官方文档</a>，文档版本3.4.10</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a><font color=\"#c00\">小结</font></h2><p>完成上述配置后，ZooKeeper应该可以正常启动了，下篇文件我们开始<a href=\"/ai/hadoop-dfs/\">《部署 HDFS》</a></p>\n<p>本系列文章<a href=\"/ai/hadoop-start/\">《目录》</a></p>"},{"title":"Linux 使用监控","date":"2017-04-27T10:56:09.000Z","_content":"知道程序在服务器中运行时，对硬件的使用率有多少，尤其是长时间，大规模的运算任务，还是一件很重要的事。这篇文章简单介绍几个性能分析工具。\n\n# Quick Start\n\n## <font color=#c00>CPU及内存监控</font>\n\ntop命令是Linux下常用的性能分析工具，能够实时显示CPU的使用率及系统中各个进程的资源占用状况。以每秒更新的方式显示实时情况。\n\n### 基础信息\n \n``` bash\ntop\n```\n\n<!--more-->\n\n### 基础操纵\n\n点击下面的健会显示相应信息，点击ESC返回主界面\n\nh: 帮助\n1: 显示CPU详细信息，每行代表一个线程\nf: 查看列信息\nn: 按下n键后，再按相应的数字，表示现实进程前几行\nz: 颜色模式\nq: 退出。或Ctrl+C\n\n### 显示与隐藏\n\nl: 第一行负载信息\nt: CPU线程信息\nm: 内存信息\n\n## <font color=#c00>显卡监控</font>\n\n如下命令主要适用于NVIDIA产品\n\n``` bash\nnvidia-msi\n```\n\n## <font color=#c00>IO监控</font>\n\n### 基础方法\n\n每隔1秒采样一次，以KB的方式显示。\n\n``` bash\niostat -d -x -k 1\n```\n\n如果显示有限次数，则在命令最后增加一个次数，下面命令显示5次\n\n``` bash\niostat -d -x -k 1 5\n```\n\n### 参数说明\n\nd: 采样\nx: 详细信息，使用率\nc: CPU状态\n","source":"_posts/linux-monitor.md","raw":"---\ntitle: Linux 使用监控\ncategories:\n  - other\ntags:\n  - Linux\ndate: 2017-04-27 18:56:09\n---\n知道程序在服务器中运行时，对硬件的使用率有多少，尤其是长时间，大规模的运算任务，还是一件很重要的事。这篇文章简单介绍几个性能分析工具。\n\n# Quick Start\n\n## <font color=#c00>CPU及内存监控</font>\n\ntop命令是Linux下常用的性能分析工具，能够实时显示CPU的使用率及系统中各个进程的资源占用状况。以每秒更新的方式显示实时情况。\n\n### 基础信息\n \n``` bash\ntop\n```\n\n<!--more-->\n\n### 基础操纵\n\n点击下面的健会显示相应信息，点击ESC返回主界面\n\nh: 帮助\n1: 显示CPU详细信息，每行代表一个线程\nf: 查看列信息\nn: 按下n键后，再按相应的数字，表示现实进程前几行\nz: 颜色模式\nq: 退出。或Ctrl+C\n\n### 显示与隐藏\n\nl: 第一行负载信息\nt: CPU线程信息\nm: 内存信息\n\n## <font color=#c00>显卡监控</font>\n\n如下命令主要适用于NVIDIA产品\n\n``` bash\nnvidia-msi\n```\n\n## <font color=#c00>IO监控</font>\n\n### 基础方法\n\n每隔1秒采样一次，以KB的方式显示。\n\n``` bash\niostat -d -x -k 1\n```\n\n如果显示有限次数，则在命令最后增加一个次数，下面命令显示5次\n\n``` bash\niostat -d -x -k 1 5\n```\n\n### 参数说明\n\nd: 采样\nx: 详细信息，使用率\nc: CPU状态\n","slug":"linux-monitor","published":1,"updated":"2018-03-30T09:52:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgupdo001k3knazz4m2khs","content":"<p>知道程序在服务器中运行时，对硬件的使用率有多少，尤其是长时间，大规模的运算任务，还是一件很重要的事。这篇文章简单介绍几个性能分析工具。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"CPU及内存监控\"><a href=\"#CPU及内存监控\" class=\"headerlink\" title=\"CPU及内存监控\"></a><font color=\"#c00\">CPU及内存监控</font></h2><p>top命令是Linux下常用的性能分析工具，能够实时显示CPU的使用率及系统中各个进程的资源占用状况。以每秒更新的方式显示实时情况。</p>\n<h3 id=\"基础信息\"><a href=\"#基础信息\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<h3 id=\"基础操纵\"><a href=\"#基础操纵\" class=\"headerlink\" title=\"基础操纵\"></a>基础操纵</h3><p>点击下面的健会显示相应信息，点击ESC返回主界面</p>\n<p>h: 帮助<br>1: 显示CPU详细信息，每行代表一个线程<br>f: 查看列信息<br>n: 按下n键后，再按相应的数字，表示现实进程前几行<br>z: 颜色模式<br>q: 退出。或Ctrl+C</p>\n<h3 id=\"显示与隐藏\"><a href=\"#显示与隐藏\" class=\"headerlink\" title=\"显示与隐藏\"></a>显示与隐藏</h3><p>l: 第一行负载信息<br>t: CPU线程信息<br>m: 内存信息</p>\n<h2 id=\"显卡监控\"><a href=\"#显卡监控\" class=\"headerlink\" title=\"显卡监控\"></a><font color=\"#c00\">显卡监控</font></h2><p>如下命令主要适用于NVIDIA产品</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nvidia-msi</span><br></pre></td></tr></table></figure>\n<h2 id=\"IO监控\"><a href=\"#IO监控\" class=\"headerlink\" title=\"IO监控\"></a><font color=\"#c00\">IO监控</font></h2><h3 id=\"基础方法\"><a href=\"#基础方法\" class=\"headerlink\" title=\"基础方法\"></a>基础方法</h3><p>每隔1秒采样一次，以KB的方式显示。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iostat -d -x -k 1</span><br></pre></td></tr></table></figure>\n<p>如果显示有限次数，则在命令最后增加一个次数，下面命令显示5次</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iostat -d -x -k 1 5</span><br></pre></td></tr></table></figure>\n<h3 id=\"参数说明\"><a href=\"#参数说明\" class=\"headerlink\" title=\"参数说明\"></a>参数说明</h3><p>d: 采样<br>x: 详细信息，使用率<br>c: CPU状态</p>\n","site":{"data":{}},"excerpt":"<p>知道程序在服务器中运行时，对硬件的使用率有多少，尤其是长时间，大规模的运算任务，还是一件很重要的事。这篇文章简单介绍几个性能分析工具。</p>\n<h1 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h1><h2 id=\"CPU及内存监控\"><a href=\"#CPU及内存监控\" class=\"headerlink\" title=\"CPU及内存监控\"></a><font color=\"#c00\">CPU及内存监控</font></h2><p>top命令是Linux下常用的性能分析工具，能够实时显示CPU的使用率及系统中各个进程的资源占用状况。以每秒更新的方式显示实时情况。</p>\n<h3 id=\"基础信息\"><a href=\"#基础信息\" class=\"headerlink\" title=\"基础信息\"></a>基础信息</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top</span><br></pre></td></tr></table></figure>","more":"<h3 id=\"基础操纵\"><a href=\"#基础操纵\" class=\"headerlink\" title=\"基础操纵\"></a>基础操纵</h3><p>点击下面的健会显示相应信息，点击ESC返回主界面</p>\n<p>h: 帮助<br>1: 显示CPU详细信息，每行代表一个线程<br>f: 查看列信息<br>n: 按下n键后，再按相应的数字，表示现实进程前几行<br>z: 颜色模式<br>q: 退出。或Ctrl+C</p>\n<h3 id=\"显示与隐藏\"><a href=\"#显示与隐藏\" class=\"headerlink\" title=\"显示与隐藏\"></a>显示与隐藏</h3><p>l: 第一行负载信息<br>t: CPU线程信息<br>m: 内存信息</p>\n<h2 id=\"显卡监控\"><a href=\"#显卡监控\" class=\"headerlink\" title=\"显卡监控\"></a><font color=\"#c00\">显卡监控</font></h2><p>如下命令主要适用于NVIDIA产品</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nvidia-msi</span><br></pre></td></tr></table></figure>\n<h2 id=\"IO监控\"><a href=\"#IO监控\" class=\"headerlink\" title=\"IO监控\"></a><font color=\"#c00\">IO监控</font></h2><h3 id=\"基础方法\"><a href=\"#基础方法\" class=\"headerlink\" title=\"基础方法\"></a>基础方法</h3><p>每隔1秒采样一次，以KB的方式显示。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iostat -d -x -k 1</span><br></pre></td></tr></table></figure>\n<p>如果显示有限次数，则在命令最后增加一个次数，下面命令显示5次</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iostat -d -x -k 1 5</span><br></pre></td></tr></table></figure>\n<h3 id=\"参数说明\"><a href=\"#参数说明\" class=\"headerlink\" title=\"参数说明\"></a>参数说明</h3><p>d: 采样<br>x: 详细信息，使用率<br>c: CPU状态</p>"},{"title":"KOA 开始","date":"2018-03-16T05:56:17.000Z","_content":"更新中...\n","source":"_posts/koa-start.md","raw":"---\ntitle: KOA 开始\ncategories:\n  - koa\ntags:\n  - NodeJS\n  - 全栈\ndate: 2018-03-16 13:56:17\n---\n更新中...\n","slug":"koa-start","published":1,"updated":"2018-03-20T08:13:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgupdp001n3knas86mwr5o","content":"<p>更新中…</p>\n","site":{"data":{}},"excerpt":"","more":"<p>更新中…</p>\n"},{"title":"ReactJS 开始","date":"2016-06-16T07:35:00.000Z","_content":"更新中...","source":"_posts/reactjs-start.md","raw":"---\ntitle: ReactJS 开始\ncategories:\n  - react\ntags:\n  - 前端\n  - SPA\ndate: 2016-06-16 15:35:00\n---\n更新中...","slug":"reactjs-start","published":1,"updated":"2018-03-28T09:23:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgupdq001o3knaixckwypo","content":"<p>更新中…</p>\n","site":{"data":{}},"excerpt":"","more":"<p>更新中…</p>\n"},{"title":"NBatis 开始","date":"2017-02-16T01:00:00.000Z","_content":"更新中...\n","source":"_posts/nbatis-start.md","raw":"---\ntitle: NBatis 开始\ncategories:\n\t- nbatis\ntags:\n\t- 数据库\n\t- NodeJS\ndate: 2017-02-16 09:00:00\n---\n更新中...\n","slug":"nbatis-start","published":1,"updated":"2018-03-20T08:13:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgupdr001t3kna04zivd52","content":"<p>更新中…</p>\n","site":{"data":{}},"excerpt":"","more":"<p>更新中…</p>\n"},{"title":"React Native 开始","date":"2018-01-10T08:57:49.000Z","_content":"更新中...","source":"_posts/rn-start.md","raw":"---\ntitle: React Native 开始\ncategories:\n  - react\ntags:\n  - 前端\n  - App\ndate: 2018-01-10 16:57:49\n---\n更新中...","slug":"rn-start","published":1,"updated":"2018-03-28T09:23:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjfjgupds001u3knacvrpphoq","content":"<p>更新中…</p>\n","site":{"data":{}},"excerpt":"","more":"<p>更新中…</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjfjgup8100053kna1tak3b6z","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup87000d3knadoi83oin"},{"post_id":"cjfjgup7t00003kna46j6fv12","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup89000i3knat9lf99uy"},{"post_id":"cjfjgup8200063knal8ockigx","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8b000l3knaf95kqxrd"},{"post_id":"cjfjgup85000a3knac5gus4cx","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8d000o3knac8mrm18q"},{"post_id":"cjfjgup7x00013knau1y3mjhz","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8f000s3knalne7tdqa"},{"post_id":"cjfjgup86000c3knagaw6sy59","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8g000u3kna3trl0ypb"},{"post_id":"cjfjgup88000h3knac1u8gahc","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8g000w3knal9f0906m"},{"post_id":"cjfjgup8000043knaw1ri86rf","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8g000y3kna13zdbnkh"},{"post_id":"cjfjgup8a000k3kna6qqiogdv","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8h00103knaat4wk4wl"},{"post_id":"cjfjgup8c000n3knar9v3drdv","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8h00123kna0to7a6vy"},{"post_id":"cjfjgup8e000r3knaywn9xh01","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8h00133knauewoos3e"},{"post_id":"cjfjgup8t00143knacz7klp3u","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8y00193knarss770d5"},{"post_id":"cjfjgup8w00173knazf08wnm4","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8z001c3knazi27wa3z"},{"post_id":"cjfjgup8x00183knadk59cpqz","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgup8z001d3kna34ykf6c4"},{"post_id":"cjfjgupdl001g3knaep4ek4co","category_id":"cjfjgup7y00023kna09399afb","_id":"cjfjgupdq001p3knaie7ysfsw"},{"post_id":"cjfjgupdj001e3knavbeu4jwz","category_id":"cjfjgupdo001i3knay2o8msfv","_id":"cjfjgupdt001w3knal2ahpydv"},{"post_id":"cjfjgupdo001k3knazz4m2khs","category_id":"cjfjgupdo001i3knay2o8msfv","_id":"cjfjgupdu001z3knajjrwvy9o"},{"post_id":"cjfjgupdp001n3knas86mwr5o","category_id":"cjfjgupdt001v3kna5iusuqof","_id":"cjfjgupdv00223knagcb70438"},{"post_id":"cjfjgupdq001o3knaixckwypo","category_id":"cjfjgupdu00203knahembqlb3","_id":"cjfjgupdw00273kna48amz1md"},{"post_id":"cjfjgupdr001t3kna04zivd52","category_id":"cjfjgupdv00233knan9o46xws","_id":"cjfjgupdw002a3kna33ev301b"},{"post_id":"cjfjgupds001u3knacvrpphoq","category_id":"cjfjgupdu00203knahembqlb3","_id":"cjfjgupdx002d3kna1g24qz0k"}],"PostTag":[{"post_id":"cjfjgup8100053kna1tak3b6z","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8500093kna5do273ve"},{"post_id":"cjfjgup7t00003kna46j6fv12","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup86000b3knahs8yuqqo"},{"post_id":"cjfjgup8200063knal8ockigx","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup88000g3knakmutv3j1"},{"post_id":"cjfjgup85000a3knac5gus4cx","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8a000j3knam367fwzt"},{"post_id":"cjfjgup7x00013knau1y3mjhz","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8c000m3kna4g2rhawu"},{"post_id":"cjfjgup86000c3knagaw6sy59","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8d000q3kna13om282h"},{"post_id":"cjfjgup88000h3knac1u8gahc","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8g000t3knank7fmbug"},{"post_id":"cjfjgup8000043knaw1ri86rf","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8g000v3knay9up4djy"},{"post_id":"cjfjgup8c000n3knar9v3drdv","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8g000x3knadk0s3q4a"},{"post_id":"cjfjgup8e000r3knaywn9xh01","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8h000z3knayxzo7ibg"},{"post_id":"cjfjgup8a000k3kna6qqiogdv","tag_id":"cjfjgup8d000p3kna9yws4jzh","_id":"cjfjgup8h00113knaps7wcpst"},{"post_id":"cjfjgup8t00143knacz7klp3u","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8v00163knayt1g1fic"},{"post_id":"cjfjgup8w00173knazf08wnm4","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8y001a3knasnqvyt6t"},{"post_id":"cjfjgup8x00183knadk59cpqz","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgup8z001b3kna6hl2l5up"},{"post_id":"cjfjgupdl001g3knaep4ek4co","tag_id":"cjfjgup8000033knadqb8443y","_id":"cjfjgupdp001m3knayesppcbk"},{"post_id":"cjfjgupdj001e3knavbeu4jwz","tag_id":"cjfjgupdo001j3knamlfxwe1f","_id":"cjfjgupdr001s3knau6mofbat"},{"post_id":"cjfjgupdo001k3knazz4m2khs","tag_id":"cjfjgupdo001j3knamlfxwe1f","_id":"cjfjgupdu001y3knablt9o6k9"},{"post_id":"cjfjgupdp001n3knas86mwr5o","tag_id":"cjfjgupdt001x3kna06rcnnx2","_id":"cjfjgupdw00253knaptysy8ho"},{"post_id":"cjfjgupdp001n3knas86mwr5o","tag_id":"cjfjgupdu00213knag81qnl71","_id":"cjfjgupdw00263knaewuhfe98"},{"post_id":"cjfjgupdq001o3knaixckwypo","tag_id":"cjfjgupdv00243knaghmsqy98","_id":"cjfjgupdx002c3kna861x3q0w"},{"post_id":"cjfjgupdq001o3knaixckwypo","tag_id":"cjfjgupdw00293kna7j246wki","_id":"cjfjgupdx002e3knap2fp3oaf"},{"post_id":"cjfjgupdr001t3kna04zivd52","tag_id":"cjfjgupdx002b3kna9cvzd7pl","_id":"cjfjgupdy002h3knaz3wtfsff"},{"post_id":"cjfjgupdr001t3kna04zivd52","tag_id":"cjfjgupdt001x3kna06rcnnx2","_id":"cjfjgupdy002i3knaqiffmt4l"},{"post_id":"cjfjgupds001u3knacvrpphoq","tag_id":"cjfjgupdv00243knaghmsqy98","_id":"cjfjgupdy002k3knaby1ndbz6"},{"post_id":"cjfjgupds001u3knacvrpphoq","tag_id":"cjfjgupdy002j3kna1rioz094","_id":"cjfjgupdz002l3knatqqfc6k8"}],"Tag":[{"name":"大数据","_id":"cjfjgup8000033knadqb8443y"},{"name":"深度学习","_id":"cjfjgup8d000p3kna9yws4jzh"},{"name":"Linux","_id":"cjfjgupdo001j3knamlfxwe1f"},{"name":"NodeJS","_id":"cjfjgupdt001x3kna06rcnnx2"},{"name":"全栈","_id":"cjfjgupdu00213knag81qnl71"},{"name":"前端","_id":"cjfjgupdv00243knaghmsqy98"},{"name":"SPA","_id":"cjfjgupdw00293kna7j246wki"},{"name":"数据库","_id":"cjfjgupdx002b3kna9cvzd7pl"},{"name":"App","_id":"cjfjgupdy002j3kna1rioz094"}]}}